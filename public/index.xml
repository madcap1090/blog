<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bad to the code</title>
    <link>/</link>
    <description>Recent content on bad to the code</description>
    <generator>Hugo - gohugo.io</generator>
    <language>en</language>
    <contact>madcap1090@gmail.com</contact>
    <copyright>&copy; <a href="https://github.com/madcap1090">William Bourgeois</a> 2019</copyright>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Metallica rules the world</title>
      <link>/post/metallica-rules-the-world/</link>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/metallica-rules-the-world/</guid>
      <description></description>
      
      <content>


&lt;p&gt;23 days till Metallica hits the Koning Boudewijnstadion in Belgium. High time to get loaded with some Metallica data. There is an interesting site called &lt;a href=&#34;https://www.setlist.fm&#34;&gt;setlist&lt;/a&gt; that publishes setlists of loads of bands and indeed also of Metallica. It also lists the name of the tour, the venues and the dates. Pretty cool stuff that can be scraped and analysed. And it even says it cares about our privacy, perfect!&lt;/p&gt;
&lt;center&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/FtUptw2ZmDM&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/center&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;rbokeh&amp;quot;) # install.packages(&amp;quot;rbokeh&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;maps&amp;quot;)
library(&amp;quot;lubridate&amp;quot;)
library(&amp;quot;rvest&amp;quot;)
library(&amp;quot;httr&amp;quot;)
library(&amp;quot;glue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to scrape the pages we want, a tibble of urls can be constructed in this manner:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;quot;https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the first page showing the latests concerts of Metallica. On that page there is one element that can be used, the total number of Metallica pages on the website (today a whopping 202!).&lt;/p&gt;
&lt;p&gt;We read the page and get that element.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;selector &amp;lt;- &amp;quot;body &amp;gt; div.body &amp;gt; div.container &amp;gt; div.row.main &amp;gt; div.mainColumn.col-xs-12.col-md-8 &amp;gt; div:nth-child(2) &amp;gt; div &amp;gt; div &amp;gt; div.col-xs-12.noTopBorder.noTopPadding.hidden-print.text-center.listPager-lg &amp;gt; ul &amp;gt; li:nth-child(9) &amp;gt; a&amp;quot;
page &amp;lt;- read_html(url)

n_pages &amp;lt;- page %&amp;gt;% 
  html_node(selector) %&amp;gt;% 
  html_text
n_pages #number of pages&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;202&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our object will have 202 rows. It‚Äôs also a nifty trick using the function glue.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pages &amp;lt;- c(1:n_pages) # the vector of the pages
urls &amp;lt;-  glue(&amp;quot;https://www.setlist.fm/setlists/metallica-3bd680c8.html?page={pages}&amp;quot;) %&amp;gt;% 
  enframe(name = NULL)
head(urls)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   value                                                         
##   &amp;lt;S3: glue&amp;gt;                                                    
## 1 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=1
## 2 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=2
## 3 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=3
## 4 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=4
## 5 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=5
## 6 https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also might want to use this code in the future not to scrape the 202 pages again, but just the latest concerts. So going back to the future we can look for a file where we stored our results from the latest scraping and extract the latest date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(file.exists(&amp;quot;./data/20190524/scraping.rds&amp;quot;)){
  max_date &amp;lt;- readRDS(&amp;quot;./data/20190524/scraping.rds&amp;quot;) %&amp;gt;% 
    select(&amp;quot;date&amp;quot;) %&amp;gt;% 
    filter(date == max(date)) %&amp;gt;%
    unique() %&amp;gt;% 
    &amp;#39;[[&amp;#39;(1) # funky ;-)
    } else{
  max_date &amp;lt;- ymd(&amp;quot;1966-01-01&amp;quot;)
  }
max_date&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2019-05-10&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we can continue to prepare the scraping by getting the pages we need to download.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# selector
#selector_url_concert &amp;lt;- &amp;quot;.url&amp;quot;

# function
get_urls &amp;lt;- function(x){
  read_html(x) %&amp;gt;% 
  html_nodes(&amp;quot;.url&amp;quot;)
  }
concert_urls &amp;lt;- tibble() # empty tibble to be filled

for(i in urls$value){
    # evaluate if we already have the data
  selector &amp;lt;- &amp;quot;body &amp;gt; div.body &amp;gt; div.container &amp;gt; div.row.main &amp;gt; div.mainColumn.col-xs-12.col-md-8 &amp;gt; div:nth-child(2) &amp;gt; div &amp;gt; div &amp;gt; div:nth-child(1) &amp;gt; div:nth-child(1) &amp;gt; div&amp;quot;
  date &amp;lt;- read_html(i) %&amp;gt;% 
    html_node(selector) %&amp;gt;% 
    html_text
  date &amp;lt;- str_replace_all(date, &amp;quot;\\\n&amp;quot;, &amp;quot; &amp;quot;) %&amp;gt;% 
    mdy()
  
  if (date &amp;lt; max_date) break # break here if we have it, continue if we don&amp;#39;t
  
  print(i)
  new_url_nodes &amp;lt;- get_urls(i) 
  print(new_url_nodes)
  
  urls &amp;lt;- tibble() # empty tibble to be filled
  
  for (j in (1:length(new_url_nodes))) {
    url &amp;lt;- xml_attrs(new_url_nodes[[j]])[[&amp;quot;href&amp;quot;]] %&amp;gt;% 
    as_tibble()  
    urls &amp;lt;- rbind(urls, url)
  }
  concert_urls &amp;lt;- rbind(concert_urls, urls)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;https://www.setlist.fm/setlists/metallica-3bd680c8.html?page=1&amp;quot;
## {xml_nodeset (10)}
##  [1] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/stade-de-france-saint-denis-fran ...
##  [2] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/letzigrund-stadion-zurich-switze ...
##  [3] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/ippodromo-del-galoppo-di-san-sir ...
##  [4] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/estadi-olimpic-lluis-companys-ba ...
##  [5] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/valdebebas-ifema-madrid-spain-43 ...
##  [6] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/estadio-do-restelo-lisbon-portug ...
##  [7] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/van-andel-arena-grand-rapids-mi- ...
##  [8] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/bankers-life-fieldhouse-indianap ...
##  [9] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/kfc-yum-center-louisville-ky-7b9 ...
## [10] &amp;lt;a href=&amp;quot;../setlist/metallica/2019/sprint-center-kansas-city-mo-1b9 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `enframe(name = NULL)` instead.
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point ‚Äòconcert_url‚Äô contains the urls of the concert we did not have in the data since our latest future scraping. We need to suffix it with ‚Äú&lt;a href=&#34;https://www.setlist.fm&#34; class=&#34;uri&#34;&gt;https://www.setlist.fm&lt;/a&gt;‚Äù.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;concert_urls &amp;lt;- concert_urls %&amp;gt;% 
  mutate(url = str_replace(value,&amp;quot;..&amp;quot;,&amp;quot;https://www.setlist.fm&amp;quot;)) %&amp;gt;% 
  select(-value)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Getting there. All systems are go.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;concert_urls &amp;lt;- add_column(concert_urls, date = &amp;quot;&amp;quot;, tour =&amp;quot;&amp;quot;, venue =&amp;quot;&amp;quot;,
                           setlist =&amp;quot;&amp;quot;) # create space to add to the df&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- nrow(concert_urls)

for(i in (1:n)) {
  
  # download page
  url &amp;lt;- concert_urls$url[i]
  page &amp;lt;- read_html(url)

  # get tour
  tour &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;p &amp;gt; span:nth-child(2)&amp;quot;) %&amp;gt;%
    html_text()
  
  concert_urls$tour[i] &amp;lt;- tour

  # get date
  year &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;.year&amp;quot;) %&amp;gt;%
    html_text
  
  month &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;.month&amp;quot;) %&amp;gt;%
    html_text
  
  day &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;.day&amp;quot;) %&amp;gt;%
    html_text
  
  date &amp;lt;- mdy(paste(month, day, year))

  print(date)

 concert_urls$date[i] &amp;lt;- date

  # get venue
  venue &amp;lt;- page %&amp;gt;%
    html_nodes(&amp;quot;div.infoContainer &amp;gt; div &amp;gt; h1 &amp;gt; span &amp;gt; span &amp;gt; a &amp;gt; span&amp;quot;) %&amp;gt;%
    html_text()
  
  concert_urls$venue[i] &amp;lt;- venue
  
  # get setlist
  setlist &amp;lt;- page %&amp;gt;%
      html_nodes(&amp;quot;.songLabel&amp;quot;) %&amp;gt;%
      html_text()
    
  concert_urls$setlist[i] &amp;lt;- list(setlist)
  
  Sys.sleep(1) # do not stress the website, we have time
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2019-05-12&amp;quot;
## [1] &amp;quot;2019-05-10&amp;quot;
## [1] &amp;quot;2019-05-08&amp;quot;
## [1] &amp;quot;2019-05-05&amp;quot;
## [1] &amp;quot;2019-05-03&amp;quot;
## [1] &amp;quot;2019-05-01&amp;quot;
## [1] &amp;quot;2019-03-13&amp;quot;
## [1] &amp;quot;2019-03-11&amp;quot;
## [1] &amp;quot;2019-03-09&amp;quot;
## [1] &amp;quot;2019-03-06&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, we can now do some data cleaning. And add the new data to the older data if we are not scaping in this way for the first time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;concert_urls$date &amp;lt;- as.numeric(concert_urls$date)
concert_urls$date &amp;lt;- as.Date(concert_urls$date, origin = &amp;quot;1969-12-30&amp;quot;)
concert_urls_new &amp;lt;- concert_urls

if(file.exists(&amp;quot;./data/20190524/scraping.rds&amp;quot;)){
  concert_urls_old &amp;lt;- readRDS(&amp;quot;./data/20190524/scraping.rds&amp;quot;) %&amp;gt;% 
    filter(!date %in% concert_urls_new$date)
    } else{
  concert_urls_old &amp;lt;- data.frame()
  }

concert_urls &amp;lt;- rbind(concert_urls_new,concert_urls_old)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Happy me I am. We tanked data on the 2K concerts of Metallica. And we know some more are coming. ü§ò&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(concert_urls, &amp;quot;./data/20190524/scraping.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
</content>
      
    </item>
    
    <item>
      <title>tests with paws on aws</title>
      <link>/post/tests-with-paws-on-aws/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/tests-with-paws-on-aws/</guid>
      <description></description>
      
      <content>


&lt;p&gt;When trying to find an interface between AWS and Rekognition in a previous post, I was unsuccessful in finding a suitable R library. But today I (partially) caught up with my email backlog and was excited to find in the newsletter from &lt;a href=&#34;https://rweekly.org/&#34;&gt;rweekly&lt;/a&gt;, that a number of interesting R packages just came out at the beginning of the month.&lt;/p&gt;
&lt;p&gt;As far as I understand at the moment, there are 11 packages bundled in a &lt;a href=&#34;https://cran.r-project.org/web/packages/paws/index.html&#34;&gt;kit&lt;/a&gt; published three days ago‚Ä¶&lt;/p&gt;
&lt;p&gt;So my intent in this post is to take these for a ride, using our parliamentarian‚Äôs tweets, and see what I can get out of different AWS services through R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;paws.machine.learning&amp;quot;) # install.packages(&amp;quot;paws.machine.learning&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Authentication information for AWS:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# s3 bucket
AWSAccessKeyId &amp;lt;- &amp;quot;&amp;quot;
AWSSecretKey &amp;lt;- &amp;quot;&amp;quot;
region &amp;lt;- &amp;quot;eu-west-1&amp;quot;

Sys.setenv(&amp;quot;AWS_ACCESS_KEY_ID&amp;quot; = AWSAccessKeyId,
           &amp;quot;AWS_SECRET_ACCESS_KEY&amp;quot; = AWSSecretKey,
           &amp;quot;AWS_DEFAULT_REGION&amp;quot; = region,
           &amp;quot;AWS_REGION&amp;quot; = region,
           &amp;quot;AWS_SESSION_TOKEN&amp;quot; = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Detecting languages with Amazon Comprehend:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc &amp;lt;- comprehend()
svc$batch_detect_dominant_language(
  &amp;quot;ik voelde me zo angstig als een jong dier onder vuur genomen door jagers&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ResultList
## $ResultList[[1]]
## $ResultList[[1]]$Index
## [1] 0
## 
## $ResultList[[1]]$Languages
## $ResultList[[1]]$Languages[[1]]
## $ResultList[[1]]$Languages[[1]]$LanguageCode
## [1] &amp;quot;nl&amp;quot;
## 
## $ResultList[[1]]$Languages[[1]]$Score
## [1] 0.9996376
## 
## 
## 
## 
## 
## $ErrorList
## list()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice! Indeed Dutch. This returns 0.9996 confidence score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc$batch_detect_sentiment(
  &amp;quot;ik voelde me zo angstig als een jong dier onder vuur genomen door jagers&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns an error. It needs to know which language it would be in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc$batch_detect_sentiment(
  &amp;quot;ik voelde me zo angstig als een jong dier onder vuur genomen door jagers&amp;quot;,
  LanguageCode = &amp;quot;nl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Aw shoot does not do Dutch yet.&lt;/p&gt;
&lt;p&gt;But can we translate Dutch to French?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc &amp;lt;- translate()
svc$translate_text(&amp;quot;ik voelde me zo angstig als een jong dier onder vuur genomen door jagers&amp;quot;, 
                   SourceLanguageCode = &amp;quot;nl&amp;quot;, 
                   TargetLanguageCode =&amp;quot;fr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $TranslatedText
## [1] &amp;quot;Je me sentais aussi anxieux qu&amp;#39;un jeune animal mis sous le feu par des chasseurs&amp;quot;
## 
## $SourceLanguageCode
## [1] &amp;quot;nl&amp;quot;
## 
## $TargetLanguageCode
## [1] &amp;quot;fr&amp;quot;
## 
## $AppliedTerminologies
## list()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not perfect, but pretty close.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;text &amp;lt;- svc$translate_text(&amp;quot;ik voelde me zo angstig als een jong dier onder vuur genomen door jagers&amp;quot;,
                           SourceLanguageCode = &amp;quot;nl&amp;quot;, 
                           TargetLanguageCode =&amp;quot;fr&amp;quot;) 

sentiment_text &amp;lt;- text$TranslatedText

svc &amp;lt;- comprehend()
svc$batch_detect_sentiment(sentiment_text,
  LanguageCode = &amp;quot;fr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ResultList
## $ResultList[[1]]
## $ResultList[[1]]$Index
## [1] 0
## 
## $ResultList[[1]]$Sentiment
## [1] &amp;quot;NEUTRAL&amp;quot;
## 
## $ResultList[[1]]$SentimentScore
## $ResultList[[1]]$SentimentScore$Positive
## [1] 0.1202592
## 
## $ResultList[[1]]$SentimentScore$Negative
## [1] 0.01508467
## 
## $ResultList[[1]]$SentimentScore$Neutral
## [1] 0.864205
## 
## $ResultList[[1]]$SentimentScore$Mixed
## [1] 0.0004511347
## 
## 
## 
## 
## $ErrorList
## list()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hmm. Not really neutral this text.&lt;/p&gt;
&lt;p&gt;Let‚Äôs get some tweets. But just the texts for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets &amp;lt;- readRDS(&amp;quot;~/R/blogs/content/post/data/20190503/tweets.rds&amp;quot;) %&amp;gt;% 
  select(text)

nrow(tweets)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 264466&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have 264K tweets. The text is still not cleaned. Let‚Äôs see what we can get out of a small sample of them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
sample &amp;lt;- sample_n(tweets, 20)
sample&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 1
##    text                                                                    
##    &amp;lt;chr&amp;gt;                                                                   
##  1 De winsten bij de bedrijven, de miserie bij de mensen. Totaalverbod op ~
##  2 De stilte is voorbij, de storm van alle politieke partijen begint weer.~
##  3 Het kantoor van Vlaams Belang Antwerpen werd vannacht besmeurd met eier~
##  4 &amp;quot;Toekomstig Premier van Oostenrijk. \n\nHet discours is onvoorstelbaar ~
##  5 La Chambre a adopt√© jeudi soir le budget 2018, majorit√© contre oppositi~
##  6 Omdat we wie ziek is beter kunnen helpen als anderen geen misbruik make~
##  7 Op bezoek bij MM&amp;#39;se jeugdverenigingen op kamp : fier op onze vereniging~
##  8 Le gouvernement @CharlesMichel a t-il fait mieux que le gouvernement @D~
##  9 &amp;quot;Un #begov op√©rationnel, en situation de relever les d√©fis prioritaires~
## 10 Proficiat @PolitieLokeren met geslaagde deelname aan @vokavzw openbedri~
## 11 Maintenant en direct de la #ClimateMarch pour ce qui s&amp;#39;annonce la plus ~
## 12 N-VA-fractieleider @PeterDeRoover1 uit ernstige bedenkingen bij verklar~
## 13 @ValentinoBresc6 @ThomasVanwing @RuttenGwendolyn Alweer is uw kennis va~
## 14 #INFO #EAU VIVAQUA&amp;lt;U+200B&amp;gt; propose une facturation mensuelle https://t.co/Li67~ 
## 15 Nog √©√©n keer meezingen met #Bobbejaan op @canvastv #lichtjesvandescheld~
## 16 @kamisolf @MarcoG_01 @de_NVA @jvanovertveldt @FranckenTheo Vergelijk da~
## 17 @IJsboerke Echt een aanrader! Moet je echt geproefd hebben, heel fijn. ~
## 18 Que le #begov veuille voter la &amp;lt;U+2198&amp;gt;&amp;lt;U+FE0F&amp;gt; de l&amp;#39;#ISOC pour les PME avt le 31/12 ~ 
## 19 Le Groupe PS se r√©jouit de l&amp;#39;adoption en commission de la proposition d~
## 20 laat de zon maar veel schijnen in #brugge #terrasjes #sant√© Horecazaken~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Language detection on the sample.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc &amp;lt;- comprehend()
languages &amp;lt;- svc$batch_detect_dominant_language(sample$text)
list &amp;lt;- languages$ResultList

lang &amp;lt;- vector()
for (i in (1:length(list))){
  print(list[[i]][[&amp;quot;Languages&amp;quot;]][[1]][[&amp;quot;LanguageCode&amp;quot;]])
  lang_tweet &amp;lt;- list[[i]][[&amp;quot;Languages&amp;quot;]][[1]][[&amp;quot;LanguageCode&amp;quot;]]
  lang &amp;lt;- append(lang, lang_tweet)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;nl&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;fr&amp;quot;
## [1] &amp;quot;nl&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let‚Äôs look at the results compared to the tweets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- as.data.frame(lang) %&amp;gt;% 
  cbind(sample) %&amp;gt;% 
  mutate(text = substr(text, 0, 50))

x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    lang                                                             text
## 1    nl               De winsten bij de bedrijven, de miserie bij de men
## 2    nl               De stilte is voorbij, de storm van alle politieke 
## 3    nl               Het kantoor van Vlaams Belang Antwerpen werd vanna
## 4    nl             Toekomstig Premier van Oostenrijk. \n\nHet discours 
## 5    fr               La Chambre a adopt√© jeudi soir le budget 2018, maj
## 6    nl               Omdat we wie ziek is beter kunnen helpen als ander
## 7    nl               Op bezoek bij MM&amp;#39;se jeugdverenigingen op kamp : fi
## 8    fr               Le gouvernement @CharlesMichel a t-il fait mieux q
## 9    fr               Un #begov op√©rationnel, en situation de relever le
## 10   nl               Proficiat @PolitieLokeren met geslaagde deelname a
## 11   fr               Maintenant en direct de la #ClimateMarch pour ce q
## 12   nl               N-VA-fractieleider @PeterDeRoover1 uit ernstige be
## 13   nl               @ValentinoBresc6 @ThomasVanwing @RuttenGwendolyn A
## 14   fr        #INFO #EAU VIVAQUA&amp;lt;U+200B&amp;gt; propose une facturation mensue
## 15   nl               Nog √©√©n keer meezingen met #Bobbejaan op @canvastv
## 16   nl               @kamisolf @MarcoG_01 @de_NVA @jvanovertveldt @Fran
## 17   nl               @IJsboerke Echt een aanrader! Moet je echt geproef
## 18   fr Que le #begov veuille voter la &amp;lt;U+2198&amp;gt;&amp;lt;U+FE0F&amp;gt; de l&amp;#39;#ISOC pour 
## 19   fr               Le Groupe PS se r√©jouit de l&amp;#39;adoption en commissio
## 20   nl               laat de zon maar veel schijnen in #brugge #terrasj&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that is more than good. Happy with this proof of concept.&lt;/p&gt;
&lt;p&gt;Before calling it a day I wanted to test the detect_entities function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc$detect_entities(tweets$text[200011], LanguageCode = &amp;quot;fr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Entities
## $Entities[[1]]
## $Entities[[1]]$Score
## [1] 0.6681724
## 
## $Entities[[1]]$Type
## [1] &amp;quot;ORGANIZATION&amp;quot;
## 
## $Entities[[1]]$Text
## [1] &amp;quot;@BeeuwsaertEric&amp;quot;
## 
## $Entities[[1]]$BeginOffset
## [1] 0
## 
## $Entities[[1]]$EndOffset
## [1] 15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets$text[200011]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;@BeeuwsaertEric heeft u het over Huts, de mensen op de foto, de heftruckchauffeurs,...? Het zal geheel aan mezelf liggen, mr begrijp u niet&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It detected the handle, can be useful, but there are other ways to extract the handles from a tweet.&lt;/p&gt;
&lt;p&gt;What about this tweet:&lt;/p&gt;
&lt;p&gt;Damn does not seem to work in Dutch.&lt;/p&gt;
&lt;p&gt;So what about this one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc$detect_entities(tweets$text[264000], LanguageCode = &amp;quot;fr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Entities
## $Entities[[1]]
## $Entities[[1]]$Score
## [1] 0.9685722
## 
## $Entities[[1]]$Type
## [1] &amp;quot;QUANTITY&amp;quot;
## 
## $Entities[[1]]$Text
## [1] &amp;quot;10%&amp;quot;
## 
## $Entities[[1]]$BeginOffset
## [1] 53
## 
## $Entities[[1]]$EndOffset
## [1] 56
## 
## 
## $Entities[[2]]
## $Entities[[2]]$Score
## [1] 0.9842716
## 
## $Entities[[2]]$Type
## [1] &amp;quot;PERSON&amp;quot;
## 
## $Entities[[2]]$Text
## [1] &amp;quot;John Crombez&amp;quot;
## 
## $Entities[[2]]$BeginOffset
## [1] 95
## 
## $Entities[[2]]$EndOffset
## [1] 107
## 
## 
## $Entities[[3]]
## $Entities[[3]]$Score
## [1] 0.9677431
## 
## $Entities[[3]]$Type
## [1] &amp;quot;OTHER&amp;quot;
## 
## $Entities[[3]]$Text
## [1] &amp;quot;https://t.co/JyILveDaMw&amp;quot;
## 
## $Entities[[3]]$BeginOffset
## [1] 114
## 
## $Entities[[3]]$EndOffset
## [1] 137&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets$text[264000]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Onterecht uitbetaalde uitkeringen? Terugvorderingen +10%. #eerlijkerisbeter? Probeer het eens, John Crombez. #dmd https://t.co/JyILveDaMw&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So saying that it is in French resulted in a correct output (that might be an exceptional though, let‚Äôs see)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svc$detect_entities(tweets$text[260725], LanguageCode = &amp;quot;fr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Entities
## $Entities[[1]]
## $Entities[[1]]$Score
## [1] 0.993213
## 
## $Entities[[1]]$Type
## [1] &amp;quot;PERSON&amp;quot;
## 
## $Entities[[1]]$Text
## [1] &amp;quot;Zakia Khattabi&amp;quot;
## 
## $Entities[[1]]$BeginOffset
## [1] 14
## 
## $Entities[[1]]$EndOffset
## [1] 28
## 
## 
## $Entities[[2]]
## $Entities[[2]]$Score
## [1] 0.82321
## 
## $Entities[[2]]$Type
## [1] &amp;quot;OTHER&amp;quot;
## 
## $Entities[[2]]$Text
## [1] &amp;quot;https://t.co/lOkItFXEER&amp;quot;
## 
## $Entities[[2]]$BeginOffset
## [1] 88
## 
## $Entities[[2]]$EndOffset
## [1] 111
## 
## 
## $Entities[[3]]
## $Entities[[3]]$Score
## [1] 0.9617769
## 
## $Entities[[3]]$Type
## [1] &amp;quot;OTHER&amp;quot;
## 
## $Entities[[3]]$Text
## [1] &amp;quot;https://t.co/YwRcO5VyPA&amp;quot;
## 
## $Entities[[3]]$BeginOffset
## [1] 112
## 
## $Entities[[3]]$EndOffset
## [1] 135&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets$text[260725]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;#CarteBlanche Zakia Khattabi: ¬´L‚Äô√©tat d‚Äôexception doit se soumettre √† l‚Äô√âtat de droit¬ª \nhttps://t.co/lOkItFXEER https://t.co/YwRcO5VyPA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly identified ‚ÄúZakia Khattabi‚Äù in the tweet. Nice. Looking forward to test some more.&lt;/p&gt;
&lt;p&gt;But for now will see an episode of Collateral on Netflix and hope not to get to bed too late.&lt;/p&gt;
&lt;p&gt;Thank you for your attention.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>I second that emotion</title>
      <link>/post/i-second-that-emotion/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/i-second-that-emotion/</guid>
      <description></description>
      
      <content>


&lt;p&gt;In an earlier &lt;a href=&#34;https://badtothecode.netlify.com/post/happy-faces-in-a-bucket/&#34;&gt;post&lt;/a&gt; we scraped the pictures of parliamentarians and used Recognition to analyses their faces. It‚Äôs time to look a little bit closer at the data, test the usage of the ‚Äògather‚Äô and ‚Äòspread‚Äô function and get to know ggplot a little bit more.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;magick&amp;quot;)
library(&amp;quot;ggthemes&amp;quot;)
library(&amp;quot;extrafont&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the different features we now have available. On the side of the observations (rows), it might be best to take a snapshot (at the end of the legislation) in order to have a slightly more objective representation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces &amp;lt;- readRDS(&amp;quot;~/R/dev_blog/faces.rds&amp;quot;)
names(faces)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;BoundingBox.Width&amp;quot;     &amp;quot;BoundingBox.Height&amp;quot;   
##   [3] &amp;quot;BoundingBox.Left&amp;quot;      &amp;quot;BoundingBox.Top&amp;quot;      
##   [5] &amp;quot;AgeRange.Low&amp;quot;          &amp;quot;AgeRange.High&amp;quot;        
##   [7] &amp;quot;Smile.Value&amp;quot;           &amp;quot;Smile.Confidence&amp;quot;     
##   [9] &amp;quot;Eyeglasses.Value&amp;quot;      &amp;quot;Eyeglasses.Confidence&amp;quot;
##  [11] &amp;quot;Sunglasses.Value&amp;quot;      &amp;quot;Sunglasses.Confidence&amp;quot;
##  [13] &amp;quot;Gender.Value&amp;quot;          &amp;quot;Gender.Confidence&amp;quot;    
##  [15] &amp;quot;Beard.Value&amp;quot;           &amp;quot;Beard.Confidence&amp;quot;     
##  [17] &amp;quot;Mustache.Value&amp;quot;        &amp;quot;Mustache.Confidence&amp;quot;  
##  [19] &amp;quot;EyesOpen.Value&amp;quot;        &amp;quot;EyesOpen.Confidence&amp;quot;  
##  [21] &amp;quot;MouthOpen.Value&amp;quot;       &amp;quot;MouthOpen.Confidence&amp;quot; 
##  [23] &amp;quot;Emotions.Type&amp;quot;         &amp;quot;Emotions.Confidence&amp;quot;  
##  [25] &amp;quot;Emotions.Type.1&amp;quot;       &amp;quot;Emotions.Confidence.1&amp;quot;
##  [27] &amp;quot;Emotions.Type.2&amp;quot;       &amp;quot;Emotions.Confidence.2&amp;quot;
##  [29] &amp;quot;Emotions.Type.3&amp;quot;       &amp;quot;Emotions.Confidence.3&amp;quot;
##  [31] &amp;quot;Emotions.Type.4&amp;quot;       &amp;quot;Emotions.Confidence.4&amp;quot;
##  [33] &amp;quot;Emotions.Type.5&amp;quot;       &amp;quot;Emotions.Confidence.5&amp;quot;
##  [35] &amp;quot;Emotions.Type.6&amp;quot;       &amp;quot;Emotions.Confidence.6&amp;quot;
##  [37] &amp;quot;Landmarks.Type&amp;quot;        &amp;quot;Landmarks.X&amp;quot;          
##  [39] &amp;quot;Landmarks.Y&amp;quot;           &amp;quot;Landmarks.Type.1&amp;quot;     
##  [41] &amp;quot;Landmarks.X.1&amp;quot;         &amp;quot;Landmarks.Y.1&amp;quot;        
##  [43] &amp;quot;Landmarks.Type.2&amp;quot;      &amp;quot;Landmarks.X.2&amp;quot;        
##  [45] &amp;quot;Landmarks.Y.2&amp;quot;         &amp;quot;Landmarks.Type.3&amp;quot;     
##  [47] &amp;quot;Landmarks.X.3&amp;quot;         &amp;quot;Landmarks.Y.3&amp;quot;        
##  [49] &amp;quot;Landmarks.Type.4&amp;quot;      &amp;quot;Landmarks.X.4&amp;quot;        
##  [51] &amp;quot;Landmarks.Y.4&amp;quot;         &amp;quot;Landmarks.Type.5&amp;quot;     
##  [53] &amp;quot;Landmarks.X.5&amp;quot;         &amp;quot;Landmarks.Y.5&amp;quot;        
##  [55] &amp;quot;Landmarks.Type.6&amp;quot;      &amp;quot;Landmarks.X.6&amp;quot;        
##  [57] &amp;quot;Landmarks.Y.6&amp;quot;         &amp;quot;Landmarks.Type.7&amp;quot;     
##  [59] &amp;quot;Landmarks.X.7&amp;quot;         &amp;quot;Landmarks.Y.7&amp;quot;        
##  [61] &amp;quot;Landmarks.Type.8&amp;quot;      &amp;quot;Landmarks.X.8&amp;quot;        
##  [63] &amp;quot;Landmarks.Y.8&amp;quot;         &amp;quot;Landmarks.Type.9&amp;quot;     
##  [65] &amp;quot;Landmarks.X.9&amp;quot;         &amp;quot;Landmarks.Y.9&amp;quot;        
##  [67] &amp;quot;Landmarks.Type.10&amp;quot;     &amp;quot;Landmarks.X.10&amp;quot;       
##  [69] &amp;quot;Landmarks.Y.10&amp;quot;        &amp;quot;Landmarks.Type.11&amp;quot;    
##  [71] &amp;quot;Landmarks.X.11&amp;quot;        &amp;quot;Landmarks.Y.11&amp;quot;       
##  [73] &amp;quot;Landmarks.Type.12&amp;quot;     &amp;quot;Landmarks.X.12&amp;quot;       
##  [75] &amp;quot;Landmarks.Y.12&amp;quot;        &amp;quot;Landmarks.Type.13&amp;quot;    
##  [77] &amp;quot;Landmarks.X.13&amp;quot;        &amp;quot;Landmarks.Y.13&amp;quot;       
##  [79] &amp;quot;Landmarks.Type.14&amp;quot;     &amp;quot;Landmarks.X.14&amp;quot;       
##  [81] &amp;quot;Landmarks.Y.14&amp;quot;        &amp;quot;Landmarks.Type.15&amp;quot;    
##  [83] &amp;quot;Landmarks.X.15&amp;quot;        &amp;quot;Landmarks.Y.15&amp;quot;       
##  [85] &amp;quot;Landmarks.Type.16&amp;quot;     &amp;quot;Landmarks.X.16&amp;quot;       
##  [87] &amp;quot;Landmarks.Y.16&amp;quot;        &amp;quot;Landmarks.Type.17&amp;quot;    
##  [89] &amp;quot;Landmarks.X.17&amp;quot;        &amp;quot;Landmarks.Y.17&amp;quot;       
##  [91] &amp;quot;Landmarks.Type.18&amp;quot;     &amp;quot;Landmarks.X.18&amp;quot;       
##  [93] &amp;quot;Landmarks.Y.18&amp;quot;        &amp;quot;Landmarks.Type.19&amp;quot;    
##  [95] &amp;quot;Landmarks.X.19&amp;quot;        &amp;quot;Landmarks.Y.19&amp;quot;       
##  [97] &amp;quot;Landmarks.Type.20&amp;quot;     &amp;quot;Landmarks.X.20&amp;quot;       
##  [99] &amp;quot;Landmarks.Y.20&amp;quot;        &amp;quot;Landmarks.Type.21&amp;quot;    
## [101] &amp;quot;Landmarks.X.21&amp;quot;        &amp;quot;Landmarks.Y.21&amp;quot;       
## [103] &amp;quot;Landmarks.Type.22&amp;quot;     &amp;quot;Landmarks.X.22&amp;quot;       
## [105] &amp;quot;Landmarks.Y.22&amp;quot;        &amp;quot;Landmarks.Type.23&amp;quot;    
## [107] &amp;quot;Landmarks.X.23&amp;quot;        &amp;quot;Landmarks.Y.23&amp;quot;       
## [109] &amp;quot;Landmarks.Type.24&amp;quot;     &amp;quot;Landmarks.X.24&amp;quot;       
## [111] &amp;quot;Landmarks.Y.24&amp;quot;        &amp;quot;Landmarks.Type.25&amp;quot;    
## [113] &amp;quot;Landmarks.X.25&amp;quot;        &amp;quot;Landmarks.Y.25&amp;quot;       
## [115] &amp;quot;Landmarks.Type.26&amp;quot;     &amp;quot;Landmarks.X.26&amp;quot;       
## [117] &amp;quot;Landmarks.Y.26&amp;quot;        &amp;quot;Landmarks.Type.27&amp;quot;    
## [119] &amp;quot;Landmarks.X.27&amp;quot;        &amp;quot;Landmarks.Y.27&amp;quot;       
## [121] &amp;quot;Landmarks.Type.28&amp;quot;     &amp;quot;Landmarks.X.28&amp;quot;       
## [123] &amp;quot;Landmarks.Y.28&amp;quot;        &amp;quot;Landmarks.Type.29&amp;quot;    
## [125] &amp;quot;Landmarks.X.29&amp;quot;        &amp;quot;Landmarks.Y.29&amp;quot;       
## [127] &amp;quot;Pose.Roll&amp;quot;             &amp;quot;Pose.Yaw&amp;quot;             
## [129] &amp;quot;Pose.Pitch&amp;quot;            &amp;quot;Quality.Brightness&amp;quot;   
## [131] &amp;quot;Quality.Sharpness&amp;quot;     &amp;quot;Confidence&amp;quot;           
## [133] &amp;quot;number&amp;quot;                &amp;quot;ln_fn&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have this data to play with. There are some basic statistics that could be interesting. But we can first add the political parties of the members to make it yeah well, a bit more political.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54_after_cleaning &amp;lt;- readRDS(&amp;quot;./data/20190503/reps54_after_cleaning.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Slicing to the last date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps_end &amp;lt;- reps54_after_cleaning %&amp;gt;% 
  filter(end_date == &amp;quot;2019-05-31&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adding party:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces &amp;lt;- faces %&amp;gt;% 
  inner_join(reps_end %&amp;gt;% 
              select(ln_fn, &amp;quot;party&amp;quot; = Fractie)) # you can rename in a select&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;ln_fn&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Column `ln_fn` joining factor and character vector, coercing into
## character vector&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is our gender balence here?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces %&amp;gt;% group_by(Gender.Value) %&amp;gt;% 
  summarise(n = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   Gender.Value     n
##   &amp;lt;fct&amp;gt;        &amp;lt;int&amp;gt;
## 1 Female          56
## 2 Male            94&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;37% female, that‚Äôs about 14% short. Meaning there should be about 34% more women in parliament to achieve a better representation. If of course Rekognize correctly identifies gender. What are the lowest confidence values on gender?&lt;/p&gt;
&lt;p&gt;First Mr.¬†Scourneau does not really have a mug shot, and maybe therefore all his emotional values are off so it is better to get rid of his values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces&amp;lt;- faces %&amp;gt;% 
  filter(number != 130)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What are the lowest confidence values on gender?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces %&amp;gt;% 
  arrange(Gender.Confidence) %&amp;gt;% 
  select(ln_fn,Gender.Value, Gender.Confidence, number) %&amp;gt;% 
  slice(1:3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      ln_fn Gender.Value Gender.Confidence number
## 1 Van Vaerenbergh Kristien       Female          50.09950    159
## 2               Dedry Anne       Female          64.48689     45
## 3            Calvo Kristof         Male          75.73949     15&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190519/159.jpg&#34; alt=&#34;Mrs Van Vaerenbergh&#34; /&gt; &lt;img src=&#34;/img/20190519/45.jpg&#34; alt=&#34;Mrs Dedry&#34; /&gt; &lt;img src=&#34;/img/20190519/15.jpg&#34; alt=&#34;Mr Calvo&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;And the highest confidence values for gender:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces %&amp;gt;% 
  arrange(desc(Gender.Confidence)) %&amp;gt;% 
  select(ln_fn,Gender.Value, Gender.Confidence) %&amp;gt;% 
  slice(1:3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       ln_fn Gender.Value Gender.Confidence
## 1 Fernandez Fernandez Julie       Female          99.98109
## 2               Lijnen Nele       Female          99.97976
## 3   Goffinet Anne-Catherine       Female          99.96049&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190519/63.jpg&#34; alt=&#34;Mrs Frenandez&#34; /&gt; &lt;img src=&#34;/img/20190519/104.jpg&#34; alt=&#34;Mrs Lijnen&#34; /&gt; &lt;img src=&#34;/img/20190519/80.jpg&#34; alt=&#34;Mrs Goffinet&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Looking at the confidence values Rekognition is pretty sure about the results and seems to be very accurate. But how accurate? A mosaic of the pictures identified as women will create a quick visual and will enable us to have a fast visual check.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(faces$Gender.Value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Female Male  
## Levels: Female Male&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;women &amp;lt;- faces %&amp;gt;% 
  filter(Gender.Value == &amp;quot;Female&amp;quot;) %&amp;gt;% 
  select(number) %&amp;gt;% 
  mutate(file = paste0(number,&amp;quot;.jpg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(women)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 56&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seems good.&lt;/p&gt;
&lt;p&gt;The image sizes of the source files can be made equal.&lt;/p&gt;
&lt;p&gt;We can use a data frame with the files names and full path of the pictures of female reps.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;files &amp;lt;- dir(&amp;quot;./data/20190511/jpg&amp;quot;, full.names = TRUE) %&amp;gt;%
  cbind(dir(&amp;quot;./data/20190511/jpg&amp;quot;, full.names = FALSE)) %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  rename(&amp;quot;long_name&amp;quot; = &amp;quot;.&amp;quot;, &amp;quot;short_name&amp;quot; = &amp;quot;V2&amp;quot;) %&amp;gt;% 
  filter(short_name %in% women$file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make columns of our picture patch work.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;no_rows &amp;lt;- 9
no_cols &amp;lt;- 6
files &amp;lt;- as.character(files$long_name)
dir.create(&amp;quot;./data/20190519/&amp;quot;, showWarnings = FALSE)
dir.create(&amp;quot;./data/20190519/women/&amp;quot;, showWarnings = FALSE)


fun &amp;lt;- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %&amp;gt;%
  image_append(stack = TRUE) %&amp;gt;%
    image_write(paste0(&amp;quot;./data/20190519/women/&amp;quot;, i, &amp;quot;.jpg&amp;quot;))
}

 for(i in (0:(no_cols-1))) {
 fun(i, files, no_rows)
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bind columns&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;img &amp;lt;- image_read(dir(&amp;quot;data/20190519/women/&amp;quot;, full.names = TRUE)) %&amp;gt;%
image_append(stack = FALSE) 

image_write(img,&amp;quot;~/R/blogs/static/img/20190519/women_reps.jpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rekognize seems to have calculated correctly:&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/20190519/women_reps.jpg&#34; alt=&#34;women&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;women&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;And we can do the same with the men (well 88 out of the 93):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;men &amp;lt;- faces %&amp;gt;% 
  filter(Gender.Value == &amp;quot;Male&amp;quot;) %&amp;gt;% 
  select(number) %&amp;gt;% 
  mutate(file = paste0(number,&amp;quot;.jpg&amp;quot;))

files &amp;lt;- dir(&amp;quot;./data/20190511/jpg&amp;quot;, full.names = TRUE) %&amp;gt;%
  cbind(dir(&amp;quot;./data/20190511/jpg&amp;quot;, full.names = FALSE)) %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  rename(&amp;quot;long_name&amp;quot; = &amp;quot;.&amp;quot;, &amp;quot;short_name&amp;quot; = &amp;quot;V2&amp;quot;) %&amp;gt;% 
  filter(short_name %in% men$file)

no_rows &amp;lt;- 11
no_cols &amp;lt;- 8
files &amp;lt;- as.character(files$long_name)

dir.create(&amp;quot;./data/20190519/men/&amp;quot;, showWarnings = FALSE)

fun &amp;lt;- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %&amp;gt;%
  image_append(stack = TRUE) %&amp;gt;%
    image_write(paste0(&amp;quot;./data/20190519/men/&amp;quot;, i, &amp;quot;.jpg&amp;quot;))
}

 for(i in (0:(no_cols-1))) {
 fun(i, files, no_rows)
 }

img &amp;lt;- image_read(dir(&amp;quot;data/20190519/men&amp;quot;, full.names = TRUE)) %&amp;gt;%
image_append(stack = FALSE) 

image_write(img,&amp;quot;~/R/blogs/static/img/20190519/men_reps.jpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rekognize seems to have calculated correctly:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190519/men_reps.jpg&#34; alt=&#34;men&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Oh, wait top right. One false positive.&lt;/p&gt;
&lt;p&gt;Probably with low confidence for gender value then(?) :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces %&amp;gt;% 
  filter(Gender.Value == &amp;quot;Male&amp;quot;) %&amp;gt;% 
  arrange(Gender.Confidence) %&amp;gt;% 
  select(ln_fn, Gender.Confidence) %&amp;gt;% 
  slice(1:5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 ln_fn Gender.Confidence
## 1       Calvo Kristof          75.73949
## 2        Gantois Rita          77.39245
## 3        Di Rupo Elio          85.54747
## 4 Brotcorne Christian          87.08642
## 5          Jambon Jan          92.63754&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seems to be Mrs &lt;a href=&#34;https://www.n-va.be/wie-is-wie/rita-gantois&#34;&gt;Gantois&lt;/a&gt;. So good news, parliament is slightly less unbalanced.&lt;/p&gt;
&lt;p&gt;Rekognition also gave us data that was the results of estimating the emotions shown by the person on the picture. For each of them we have these types of estimations:&lt;/p&gt;
&lt;p&gt;‚ÄúEmotions‚Äù:
[
{‚ÄúType‚Äù: ‚ÄúDISGUSTED‚Äù, ‚ÄúConfidence‚Äù: 1.3769829273223877},
{‚ÄúType‚Äù: ‚ÄúSURPRISED‚Äù, ‚ÄúConfidence‚Äù: 1.2581121921539307},
{‚ÄúType‚Äù: ‚ÄúCALM‚Äù, ‚ÄúConfidence‚Äù: 83.50717163085938},
{‚ÄúType‚Äù: ‚ÄúHAPPY‚Äù, ‚ÄúConfidence‚Äù: 0.663156270980835},
{‚ÄúType‚Äù: ‚ÄúSAD‚Äù, ‚ÄúConfidence‚Äù: 2.5097835063934326},
{‚ÄúType‚Äù: ‚ÄúCONFUSED‚Äù, ‚ÄúConfidence‚Äù: 8.314539909362793},
{‚ÄúType‚Äù: ‚ÄúANGRY‚Äù, ‚ÄúConfidence‚Äù: 2.370262384414673}]&lt;/p&gt;
&lt;p&gt;So the emotions are a bit more complicated here. They usually are. This time we have some more emotions.confidence though.&lt;/p&gt;
&lt;p&gt;I have not used the ‚Äòspread‚Äô function before.&lt;/p&gt;
&lt;p&gt;It puts the different values of ‚ÄòEmotion.Type‚Äô into columns, with as row values ‚ÄòEmotions.Confidence‚Äô and fills with 0 where there are missing values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y.0 &amp;lt;- faces %&amp;gt;% 
  select(134:135,23:24) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type&amp;quot;, value = &amp;quot;Emotions.Confidence&amp;quot;, fill = 0)

y.1 &amp;lt;- faces %&amp;gt;% 
  select(134:135,25:26) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.1&amp;quot;, value = &amp;quot;Emotions.Confidence.1&amp;quot;, fill = 0) 

y.2 &amp;lt;- faces %&amp;gt;% 
  select(134:135,27:28) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.2&amp;quot;, value = &amp;quot;Emotions.Confidence.2&amp;quot;, fill = 0)

y.3 &amp;lt;- faces %&amp;gt;% 
  select(134:135,29:30) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.3&amp;quot;, value = &amp;quot;Emotions.Confidence.3&amp;quot;, fill = 0)

y.4 &amp;lt;- faces %&amp;gt;% 
  select(134:135,31:32) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.4&amp;quot;, value = &amp;quot;Emotions.Confidence.4&amp;quot;, fill = 0)

y.5 &amp;lt;- faces %&amp;gt;% 
  select(134:135,33:34) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.5&amp;quot;, value = &amp;quot;Emotions.Confidence.5&amp;quot;, fill = 0)

y.6 &amp;lt;- faces %&amp;gt;% 
  select(134:135,35:36) %&amp;gt;% 
  spread(key = &amp;quot;Emotions.Type.6&amp;quot;, value = &amp;quot;Emotions.Confidence.6&amp;quot;, fill = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotions &amp;lt;- rbind(y.0, y.1, y.2, y.3, y.4, y.5, y.6)
head(emotions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                ln_fn party SURPRISED DISGUSTED HAPPY     ANGRY CALM
## 1      Almaci Meyrem Groen  1.634811         0     0 0.0000000    0
## 2         Becq Sonja  CD&amp;amp;V  0.000000         0     0 0.5985800    0
## 3        Beke Wouter  CD&amp;amp;V  1.269888         0     0 0.0000000    0
## 4       Bellens Rita  N-VA  0.000000         0     0 0.1302407    0
## 5    Ben Hamou Nawal    PS  0.000000         0     0 1.3519702    0
## 6 Blanchart Philippe    PS 18.822914         0     0 0.0000000    0
##   CONFUSED SAD
## 1        0   0
## 2        0   0
## 3        0   0
## 4        0   0
## 5        0   0
## 6        0   0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(emotions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1043&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So ‚Äòspread‚Äô has made the data frame wider and created 0 values, and we can now group them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps_emotions &amp;lt;- emotions %&amp;gt;% 
  group_by(ln_fn, party) %&amp;gt;% 
  summarise(surprised = sum(SURPRISED),
            disgusted = sum(DISGUSTED),
            happy = sum(HAPPY),
            angry = sum(ANGRY),
            calm = sum(CALM),
            confused = sum(CONFUSED),
            sad = sum(SAD))

party_emotions &amp;lt;- emotions %&amp;gt;% 
   group_by(party) %&amp;gt;% 
   summarise(surprised = sum(SURPRISED),
             disgusted = sum(DISGUSTED),
             happy = sum(HAPPY),
             angry = sum(ANGRY),
             calm = sum(CALM),
             confused = sum(CONFUSED),
             sad = sum(SAD),
             count = (n()/7))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;charts.data &amp;lt;- party_emotions %&amp;gt;% 
  mutate(surprised = surprised/count,
         disgusted = disgusted/count,
         happy = happy/count,
         angry = angry/count,
         calm = calm/count,
         confused = confused/count,
         sad = sad/count)

head(charts.data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 9
##   party surprised disgusted happy angry  calm confused   sad count
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 CD&amp;amp;V       2.30     1.82   72.0 1.80  18.6      2.57 0.952    17
## 2 cdH        1.89     4.23   84.5 2.19   4.16     2.39 0.616     9
## 3 D√©fi       1.31     0.625  93.5 0.379  2.49     1.38 0.264     2
## 4 Ecolo      2.13     3.19   84.8 1.66   2.93     3.83 1.44      6
## 5 Groen      4.81     2.92   69.9 1.74  15.4      4.02 1.21      6
## 6 MR         4.37     3.27   76.6 4.53   6.74     3.22 1.25     19&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now use ‚Äògather‚Äô to get our data in shape for a stacked bar chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;charts.data &amp;lt;- gather(charts.data, &amp;quot;emotion&amp;quot;, &amp;quot;score&amp;quot;, 2:8)
head(charts.data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   party count emotion   score
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 CD&amp;amp;V     17 surprised  2.30
## 2 cdH       9 surprised  1.89
## 3 D√©fi      2 surprised  1.31
## 4 Ecolo     6 surprised  2.13
## 5 Groen     6 surprised  4.81
## 6 MR       19 surprised  4.37&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bar_chart &amp;lt;- ggplot() + theme_economist() + scale_fill_economist() +
  theme(plot.title=element_text(family=&amp;quot;OfficinaSanITC-Book&amp;quot;),
        text=element_text(family=&amp;quot;OfficinaSanITC-Book&amp;quot;)) +
  geom_bar(aes(y = score, x = party, fill = emotion), data = charts.data,
                           stat=&amp;quot;identity&amp;quot;) +
    theme(legend.position=&amp;quot;top&amp;quot;, legend.direction=&amp;quot;horizontal&amp;quot;,
        legend.title = element_blank(), 
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
    labs(x= NULL, y=&amp;quot;Percentage&amp;quot;) +
  ggtitle(&amp;quot;Composition of emotions in party (% confidence)&amp;quot;)

bar_chart&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-19-i-second-that-emotion_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the more disgusted are Vuye&amp;amp;Wouters and Vlaams Belang. The happiest party is the Parti Populaire. But these are the smaller parties.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;party_emotions %&amp;gt;% select(party, count) %&amp;gt;% 
  arrange(count) %&amp;gt;% 
  slice(1:6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   party           count
##   &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 ONAFH               1
## 2 Parti Populaire     1
## 3 D√©fi                2
## 4 PTB-go!             2
## 5 Vuye&amp;amp;Wouters        2
## 6 Vlaams Belang       3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The majority of the bigger ones are mostly happy with some calmness spread around too. And yes, I know the sample bias is huge. This is indeed just for fun. And I had some.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>RAMMSTEIN by Rammstein</title>
      <link>/post/rammstein-by-rammstein/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/rammstein-by-rammstein/</guid>
      <description></description>
      
      <content>


&lt;p&gt;Today Rammstein released ‚ÄòRAMMSTEIN‚Äô, first studio album since 10 years.&lt;/p&gt;
&lt;center&gt;
&lt;strong&gt;Jetzt geht es mir gut, ja!&lt;/strong&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190517/rammstein.jpg&#34; alt=&#34;album cover - RAMMSTEIN&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;I love it. Gave me a lot of pleasure today.&lt;/p&gt;
&lt;p&gt;Time for a small analysis. I got the code from &lt;a href=&#34;https://peerchristensen.netlify.com/post/clustering-springsteen-albums-with-spotifyr/&#34;&gt;Peer&lt;/a&gt;. And from &lt;a href=&#34;https://twitter.com/plzbeemyfriend/status/1028080281323036678&#34;&gt;plzbeemyfriend&lt;/a&gt; who is a cool dude, and made some insightful graphs based on Spotify data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(spotifyr) # install.packages(&amp;quot;spotifyr&amp;quot;)
library(tidyverse)
library(factoextra)
library(viridisLite)
library(ggiraphExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spotify also has an API and some interesting information can be downloaded from it.&lt;/p&gt;
&lt;p&gt;Spotify authentication:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;secrets &amp;lt;- readRDS(&amp;quot;~/R/geo/secret/secrets.rds&amp;quot;) %&amp;gt;% 
  filter(name == &amp;quot;spotify&amp;quot;)

clientId &amp;lt;- secrets$id
clientSecret &amp;lt;- secrets$key

Sys.setenv(SPOTIFY_CLIENT_ID = clientId)
Sys.setenv(SPOTIFY_CLIENT_SECRET = clientSecret)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Downloading data in a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_df &amp;lt;- get_artist_audio_features(&amp;#39;Rammstein&amp;#39;)

names(spotify_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;artist_name&amp;quot;                  &amp;quot;artist_id&amp;quot;                   
##  [3] &amp;quot;album_id&amp;quot;                     &amp;quot;album_type&amp;quot;                  
##  [5] &amp;quot;album_images&amp;quot;                 &amp;quot;album_release_date&amp;quot;          
##  [7] &amp;quot;album_release_year&amp;quot;           &amp;quot;album_release_date_precision&amp;quot;
##  [9] &amp;quot;danceability&amp;quot;                 &amp;quot;energy&amp;quot;                      
## [11] &amp;quot;key&amp;quot;                          &amp;quot;loudness&amp;quot;                    
## [13] &amp;quot;mode&amp;quot;                         &amp;quot;speechiness&amp;quot;                 
## [15] &amp;quot;acousticness&amp;quot;                 &amp;quot;instrumentalness&amp;quot;            
## [17] &amp;quot;liveness&amp;quot;                     &amp;quot;valence&amp;quot;                     
## [19] &amp;quot;tempo&amp;quot;                        &amp;quot;track_id&amp;quot;                    
## [21] &amp;quot;analysis_url&amp;quot;                 &amp;quot;time_signature&amp;quot;              
## [23] &amp;quot;artists&amp;quot;                      &amp;quot;available_markets&amp;quot;           
## [25] &amp;quot;disc_number&amp;quot;                  &amp;quot;duration_ms&amp;quot;                 
## [27] &amp;quot;explicit&amp;quot;                     &amp;quot;track_href&amp;quot;                  
## [29] &amp;quot;is_local&amp;quot;                     &amp;quot;track_name&amp;quot;                  
## [31] &amp;quot;track_preview_url&amp;quot;            &amp;quot;track_number&amp;quot;                
## [33] &amp;quot;type&amp;quot;                         &amp;quot;track_uri&amp;quot;                   
## [35] &amp;quot;external_urls.spotify&amp;quot;        &amp;quot;album_name&amp;quot;                  
## [37] &amp;quot;key_name&amp;quot;                     &amp;quot;mode_name&amp;quot;                   
## [39] &amp;quot;key_mode&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It has for instance links to three different sizes of the album images.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_df[[5]][[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   height                                                              url
## 1    640 https://i.scdn.co/image/1cfbb1da99c6259b43e1b53cf695c8850adc0241
## 2    300 https://i.scdn.co/image/389c1df3f21fa93570dde0b75332e75ab91bd878
## 3     64 https://i.scdn.co/image/2afdabd6b6318481fdb7e8288a170e8623d06ff7
##   width
## 1   640
## 2   300
## 3    64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And of course the albums.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(spotify_df$album_name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;RAMMSTEIN&amp;quot;               &amp;quot;XXI - Klavier&amp;quot;          
##  [3] &amp;quot;RARIT√ÑTEN (1994 - 2012)&amp;quot; &amp;quot;LIEBE IST F√úR ALLE DA&amp;quot;  
##  [5] &amp;quot;ROSENROT&amp;quot;                &amp;quot;REISE, REISE&amp;quot;           
##  [7] &amp;quot;Mutter&amp;quot;                  &amp;quot;Live aus Berlin&amp;quot;        
##  [9] &amp;quot;Sehnsucht&amp;quot;               &amp;quot;Herzeleid&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can focus on the studio albums.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studio_albums &amp;lt;- spotify_df %&amp;gt;% 
  filter(album_name != &amp;quot;XXI - Klavier&amp;quot;) %&amp;gt;% 
  filter(album_name != &amp;quot;RARIT√ÑTEN (1994 - 2012)&amp;quot;) %&amp;gt;% 
  filter(album_name != &amp;quot;Live aus Berlin&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check if we got them all&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(studio_albums$album_name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;RAMMSTEIN&amp;quot;             &amp;quot;LIEBE IST F√úR ALLE DA&amp;quot; &amp;quot;ROSENROT&amp;quot;             
## [4] &amp;quot;REISE, REISE&amp;quot;          &amp;quot;Mutter&amp;quot;                &amp;quot;Sehnsucht&amp;quot;            
## [7] &amp;quot;Herzeleid&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Every song gets scored by Spotify algorithms on:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(spotify_df)[12:19]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;loudness&amp;quot;         &amp;quot;mode&amp;quot;             &amp;quot;speechiness&amp;quot;     
## [4] &amp;quot;acousticness&amp;quot;     &amp;quot;instrumentalness&amp;quot; &amp;quot;liveness&amp;quot;        
## [7] &amp;quot;valence&amp;quot;          &amp;quot;tempo&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So with the code by plzbeemyfriend that builds a graphical album representation by song we can get this graph of their first album:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_spotify &amp;lt;- studio_albums %&amp;gt;%
  mutate(date = album_release_date %&amp;gt;% 
           str_extract(&amp;#39;(?&amp;lt;=^\\d{2})\\d{2}&amp;#39;) %&amp;gt;%
           {paste0(&amp;quot;&amp;#39;&amp;quot;, .)} ,
         album_name = album_name %&amp;gt;%
           str_to_title() %&amp;gt;%
           {paste0(., &amp;#39; | &amp;#39;, date)}) %&amp;gt;%
  select(album_name,
         track_name,
         danceability,
         energy,
         loudness,
         speechiness,
         acousticness,
         valence,
         instrumentalness,
         tempo) %&amp;gt;%
  mutate(loudness = (loudness + 60 )/ 60,
         tempo = tempo/200,
         end = danceability) %&amp;gt;%
  gather(key = key, value = value, -album_name, -track_name) %&amp;gt;%
  mutate(key = factor(key, levels = unique(key)),
         angle = as.numeric(key)/length(unique(key)) * 2 * pi,
         album_name = factor(album_name, levels = unique(album_name))) %&amp;gt;% 
  filter(album_name == &amp;quot;Herzeleid | &amp;#39;95&amp;quot;)

ggplot(polar_spotify, aes(x = angle, 
                          y = value, 
                          group = track_name)) +
  geom_point() +
  scale_x_continuous(breaks = unique(polar_spotify$angle) %&amp;gt;% .[-length(.)],
                     labels = levels(polar_spotify$key) %&amp;gt;% .[-length(.)],
                     name = &amp;#39;&amp;#39;,
                     minor_breaks = NULL)  +
  scale_y_continuous(name = &amp;#39;&amp;#39;) +
  coord_polar(theta = &amp;#39;x&amp;#39;) +
  geom_path()  + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = seq(0, -315, by = -45),
                                   size = 7)) +
  labs(title = &amp;quot;Rammstein | Herzeleid | &amp;#39;95&amp;quot;,
       subtitle = &amp;quot;Spotify Metrics&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And then compare their latest six albums:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_spotify &amp;lt;- studio_albums %&amp;gt;%
  mutate(date = album_release_date %&amp;gt;% 
           str_extract(&amp;#39;(?&amp;lt;=^\\d{2})\\d{2}&amp;#39;) %&amp;gt;%
           {paste0(&amp;quot;&amp;#39;&amp;quot;, .)} ,
         album_name = album_name %&amp;gt;%
           str_to_title() %&amp;gt;%
           {paste0(., &amp;#39; | &amp;#39;, date)}) %&amp;gt;%
  select(album_name,
         track_name,
         danceability,
         energy,
         loudness,
         speechiness,
         acousticness,
         valence,
         instrumentalness,
         tempo) %&amp;gt;%
  mutate(loudness = (loudness + 60 )/ 60,
         tempo = tempo/200,
         end = danceability) %&amp;gt;%
  gather(key = key, value = value, -album_name, -track_name) %&amp;gt;%
  mutate(key = factor(key, levels = unique(key)),
         angle = as.numeric(key)/length(unique(key)) * 2 * pi,
         album_name = factor(album_name, levels = unique(album_name))) %&amp;gt;% 
  filter(album_name != &amp;quot;Herzeleid | &amp;#39;95&amp;quot;)

ggplot(polar_spotify, aes(x = angle, 
                          y = value, 
                          group = track_name)) +
  geom_point() +
  scale_x_continuous(breaks = unique(polar_spotify$angle) %&amp;gt;% .[-length(.)],
                     labels = levels(polar_spotify$key) %&amp;gt;% .[-length(.)],
                     name = &amp;#39;&amp;#39;,
                     minor_breaks = NULL)  +
  scale_y_continuous(name = &amp;#39;&amp;#39;) +
  coord_polar(theta = &amp;#39;x&amp;#39;) +
  geom_path()  + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = seq(0, -315, by = -45),
                                   size = 7)) +
  facet_wrap(~album_name) + 
  labs(title = &amp;quot;Rammstein | Latest Studio Albums&amp;quot;,
       subtitle = &amp;quot;Spotify Metrics&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;
The different albums compared here. Does the ‚ÄòRAMMSTEIN‚Äô look different to you from the other albums?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfScale &amp;lt;- studio_albums %&amp;gt;%
  select(album_name,acousticness,danceability,energy,loudness,tempo,valence) %&amp;gt;%
  group_by(album_name) %&amp;gt;%
  summarise(acousticness = mean(scale(acousticness)),
            danceability = mean(scale(danceability)),
            energy       = mean(scale(energy)),
            loudness     = mean(scale(loudness)),
            tempo        = mean(scale(tempo)),
            valence      = mean(scale(valence))) %&amp;gt;%
  data.frame()

row.names(dfScale) &amp;lt;- dfScale$album_name

dfScale %&amp;lt;&amp;gt;% 
  select(-album_name) %&amp;gt;%
  data.frame()

df_dist &amp;lt;- get_dist(dfScale, stand = TRUE)

fviz_dist(df_dist,gradient = list(low = gray(0)[1], mid = &amp;quot;white&amp;quot;, high = gray(1)[0])) +
  theme_minimal() +
  ggtitle(&amp;quot;Distance matrix&amp;quot;,
          subtitle  = &amp;quot;Similarity between albums based on all features&amp;quot;) +
  theme(axis.text.x = element_text(hjust = 1,angle = 45),
        axis.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The new album would be more similar to ‚ÄòROSENROT‚Äô and most disimilar to their first ‚ÄòHerzeleid‚Äô.&lt;/p&gt;
&lt;p&gt;Only based on the Spotify metrics of course.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfScale %&amp;gt;%
  mutate(albums = row.names(dfScale)) %&amp;gt;%
  filter(albums != &amp;quot;Herzeleid&amp;quot;) %&amp;gt;% 
  ggRadar(aes(group = albums), 
        rescale = FALSE, legend.position = &amp;quot;none&amp;quot;,
        size = 1, interactive = FALSE, use.label = TRUE) +
  facet_wrap(~albums) + 
  scale_y_discrete(breaks = NULL) +
  theme(axis.text.x = element_text(size = 10)) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  scale_fill_grey() +
  scale_colour_grey()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also group the albums into groups using k-means and hierarchical clustering. Here in 3 hierachical clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.hc &amp;lt;- hclust(dist(scale(dfScale)))

fviz_dend(df.hc, k = 3,
          cex = .9,
          k_colors = gray(1)[c(4,7)],
          color_labels_by_k = TRUE, 
          rect = TRUE) +
  ggtitle(&amp;quot;Hierachical Clustering&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The new album is again closer to ‚ÄúLIEBE IST F√úR ALLE DA‚Äù and ‚ÄúROSENROT‚Äù.&lt;/p&gt;
&lt;p&gt;Now for k-mens clustering:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
km.res &amp;lt;- kmeans(dfScale, 3, nstart = 25)

fviz_cluster(km.res, data = dfScale,
             ellipse.type = &amp;quot;convex&amp;quot;,
             repel = T,
             palette = gray.colors(10)[c(1,2,3)],
             ggtheme = theme_minimal(),
             main = &amp;quot;K-means Clustering&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-17-rammstein-by-rammstein_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Consistant.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190517/Deutschland.jpg&#34; alt=&#34;album cover - RAMMSTEIN&#34; /&gt;
&lt;/center&gt;
</content>
      
    </item>
    
    <item>
      <title>happy faces in a bucket</title>
      <link>/post/happy-faces-in-a-bucket/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/happy-faces-in-a-bucket/</guid>
      <description></description>
      
      <content>


&lt;p&gt;Remember we downloaded the pictures of our parliamentarians and made a patchwork with them? I looked for a while how to analyse them for gender, age and skin color. One obvious candidate was Rekognition from AWS if only because the instances at my workplace decided to use AWS services. Getting a little bit more familiar with using these seemed therefore like a good choice.&lt;/p&gt;
&lt;p&gt;I searched for R packages to use Rekognition with, but did not find any. So I tried Python‚Äôs Boto3 but could not get the authorisation working. So with a little (a very little ‚Äì promised) help from the new consultants (thank you Fabien üëç) I set out to use my first scripts on the cloud.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# libraries
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;aws.s3&amp;quot;)
library(&amp;quot;magick&amp;quot;)
library(&amp;quot;jsonlite&amp;quot;)
options(Encoding=&amp;quot;UTF-8&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the process I found out Rekognition did not treat gifs, so the pictures need to be converted first to jpgs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_move &amp;lt;- list.files(&amp;quot;./data/190417&amp;quot;, pattern = &amp;quot;*.gif&amp;quot;)
file.copy(file.path(&amp;quot;./data/190417&amp;quot;, to_move), &amp;quot;./data/20190511&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns TRUE and TRUE is good. TRUE will set you free. We can convert them with the magick package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convert_ye &amp;lt;- function(gif){
  pic &amp;lt;- image_read(gif)
  name &amp;lt;- str_remove(gif,&amp;quot;.gif&amp;quot;)
  
  image_write(pic, path = paste0(&amp;quot;./jpg/&amp;quot;,name,&amp;quot;.jpg&amp;quot;), format = &amp;quot;jpg&amp;quot;)
}

heathens &amp;lt;- list.files(&amp;quot;./data/20190511&amp;quot;, pattern = &amp;quot;*.gif&amp;quot;, full.names = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convert_ye(heathens)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns;
Error in magick_image_readpath(path, density, depth, strip) : Magick: UnableToOpenBlob `C:\20190511V√É¬©ronique.gif‚Äô: No such file or directory @ error/blob.c/OpenBlob/2701&lt;/p&gt;
&lt;p&gt;In encoding hell again. Magick cannot read the filename‚Ä¶√É¬©√É¬©√É¬©√É¬©! The heathens cannot be converted. Can‚Äôt really find a way to solve this. Last time we just gave the files numbers. We can do that again, but now we will keep the names for future use. Or we can try to replace it just for the magick package and change it again once we have the jpgs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heathens &amp;lt;- list.files(&amp;quot;./data/20190511&amp;quot;)

setwd(&amp;quot;./data/20190511&amp;quot;)
dir.create(file.path(&amp;quot;jpg&amp;quot;), showWarnings = FALSE)
for(i in (1:length(heathens))){
  # print(headens[i])
  file.rename(from = heathens[i], paste0(i,&amp;quot;.gif&amp;quot;))
  pic &amp;lt;- image_read(paste0(i, &amp;quot;.gif&amp;quot;))
  name &amp;lt;- str_remove(heathens[i],&amp;quot;.gif&amp;quot;)
  image_write(pic, path = paste0(&amp;quot;./jpg/&amp;quot;,name,&amp;quot;.jpg&amp;quot;), format = &amp;quot;jpg&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That seemed to work.&lt;/p&gt;
&lt;p&gt;In comes AWS. We will upload these to a bucket S3. It is important that the bucket is in the same Amazon Region as your Sagemaker instance. I wrote ‚Äòinstance‚Äô because it sounds good, I don‚Äôt know if it really means something though. But it sounds like a cloud computing word to use.&lt;/p&gt;
&lt;p&gt;The authentication can be done like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AWSAccessKeyId &amp;lt;- &amp;quot;secret&amp;quot;
AWSSecretKey &amp;lt;- &amp;quot;secret&amp;quot;
region &amp;lt;- &amp;quot;eu-west-3&amp;quot;

Sys.setenv(&amp;quot;AWS_ACCESS_KEY_ID&amp;quot; = AWSAccessKeyId,
           &amp;quot;AWS_SECRET_ACCESS_KEY&amp;quot; = AWSSecretKey,
           &amp;quot;AWS_DEFAULT_REGION&amp;quot; = region,
           &amp;quot;AWS_SESSION_TOKEN&amp;quot; = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a bucket (in Ireland).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put_bucket(&amp;quot;reps666&amp;quot;, region = &amp;quot;eu-west-1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then uploading the pictures to a bucket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;put_object(&amp;quot;./data/20190511/jpg/Almaci Meyrem.jpg&amp;quot;, bucket = &amp;quot;reps666&amp;quot;, 
           object = &amp;quot;Almaci Meyrem.jpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns TRUE. TRUE is good, it will set you free.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;delete_object(object = &amp;quot;Almaci Meyrem.jpg&amp;quot;,bucket = &amp;quot;reps666&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns TRUE. Repeat after me, TRUE is‚Ä¶&lt;/p&gt;
&lt;p&gt;I‚Äôm still having problems with encodings, hope you have not, but will change the names to digits and convert them back to names later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;files &amp;lt;- list.files(&amp;quot;./data/20190511/jpg&amp;quot;)
files_full &amp;lt;- list.files(&amp;quot;./data/20190511/jpg&amp;quot;,full.names = TRUE )
for(i in (1:length(files))){
    file.rename(from = files_full[i], paste0(&amp;quot;./data/20190511/jpg/&amp;quot;,i,&amp;quot;.jpg&amp;quot;))
  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now uploading the files to the bucket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;files_full &amp;lt;- list.files(&amp;quot;./data/20190511/jpg&amp;quot;,full.names = TRUE )
for(i in (1:length(files))){
    put_object(files_full[i], bucket = &amp;quot;reps666&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have the pictures in a bucket s3 with digits instead of names, or as names, but at least they are there, on our cloud.&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/20190511/Management%20Console.jpg&#34; alt=&#34;aws console&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;aws console&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;Next we can create a notebook instance on Sagemaker and start it up.&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/20190511/Amazon%20SageMaker.jpg&#34; alt=&#34;aws sagemaker&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;aws sagemaker&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;We can use boto3 to apply Rekognition to our files (boto3 is üêç) :&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import boto3
import json
s3 = boto3.resource(&amp;#39;s3&amp;#39;)
rekognition = boto3.client(&amp;quot;rekognition&amp;quot;, &amp;quot;eu-west-1&amp;quot;)
my_bucket = s3.Bucket(&amp;#39;reps666&amp;#39;)
for object in my_bucket.objects.all():
    name = object.key[0:-4] 
    print(object.key[0:-4])
    print(name)
    BUCKET = &amp;#39;reps666&amp;#39;
    KEY = object.key
    response = rekognition.detect_faces(
    Image={
        
        &amp;#39;S3Object&amp;#39;: {
            &amp;#39;Bucket&amp;#39;: BUCKET,
            &amp;#39;Name&amp;#39;: KEY,
        }
    },
    Attributes=[
        &amp;#39;ALL&amp;#39;,
    ]
    )
    with open(object.key[0:-4]+&amp;quot;.json&amp;quot;, &amp;#39;w&amp;#39;) as json_file:
        json.dump(response, json_file)
    boto3.Session().resource(&amp;#39;s3&amp;#39;)\
    .Bucket(&amp;#39;jsonmad&amp;#39;).Object(object.key[0:-4]+&amp;quot;.json&amp;quot;)\
    .upload_file(object.key[0:-4]+&amp;quot;.json&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pardon my python.&lt;/p&gt;
&lt;p&gt;The code goes through the files in the bucket, applies ‚Äòdetect_faces‚Äô from Rekognition through boto3, saves the output
(in json) and sends it to another bucket.&lt;/p&gt;
&lt;p&gt;Next we can check that the json files safely arrived in their bucket (jsonmad), commit and push the latest changes to the code and stop the notebook instance on Sagemaker.&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/20190511/JupyterLab.jpg&#34; alt=&#34;jupyterlab&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;jupyterlab&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bucket_content &amp;lt;- get_bucket_df(bucket = &amp;quot;jsonmad&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(bucket_content, &amp;quot;./data/20190511/bucket_content.rds&amp;quot;)
bucket_content &amp;lt;-readRDS(&amp;quot;./data/20190511/bucket_content.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(bucket_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    179 obs. of  8 variables:
##  $ Key              : chr  &amp;quot;1.json&amp;quot; &amp;quot;10.json&amp;quot; &amp;quot;100.json&amp;quot; &amp;quot;101.json&amp;quot; ...
##  $ LastModified     : chr  &amp;quot;2019-05-12T11:45:07.000Z&amp;quot; &amp;quot;2019-05-12T11:45:07.000Z&amp;quot; &amp;quot;2019-05-12T11:45:08.000Z&amp;quot; &amp;quot;2019-05-12T11:45:08.000Z&amp;quot; ...
##  $ ETag             : chr  &amp;quot;\&amp;quot;6a7cb098674c1d5ab5fd66e66a031877\&amp;quot;&amp;quot; &amp;quot;\&amp;quot;36dd7f55e1db511dc3f4fabaf517492f\&amp;quot;&amp;quot; &amp;quot;\&amp;quot;0afacabc6c5ae4bea7da8116285bfb88\&amp;quot;&amp;quot; &amp;quot;\&amp;quot;42b33b346a37a50a8e832d6f0e875531\&amp;quot;&amp;quot; ...
##  $ Size             : chr  &amp;quot;3886&amp;quot; &amp;quot;3886&amp;quot; &amp;quot;3902&amp;quot; &amp;quot;3891&amp;quot; ...
##  $ Owner_ID         : chr  &amp;quot;5c61b42d25c8ca6f8e818c7f78a69aaf2b99c91751b1d155178b5f72a88b84fd&amp;quot; &amp;quot;5c61b42d25c8ca6f8e818c7f78a69aaf2b99c91751b1d155178b5f72a88b84fd&amp;quot; &amp;quot;5c61b42d25c8ca6f8e818c7f78a69aaf2b99c91751b1d155178b5f72a88b84fd&amp;quot; &amp;quot;5c61b42d25c8ca6f8e818c7f78a69aaf2b99c91751b1d155178b5f72a88b84fd&amp;quot; ...
##  $ Owner_DisplayName: chr  &amp;quot;madcap1090&amp;quot; &amp;quot;madcap1090&amp;quot; &amp;quot;madcap1090&amp;quot; &amp;quot;madcap1090&amp;quot; ...
##  $ StorageClass     : chr  &amp;quot;STANDARD&amp;quot; &amp;quot;STANDARD&amp;quot; &amp;quot;STANDARD&amp;quot; &amp;quot;STANDARD&amp;quot; ...
##  $ Bucket           : chr  &amp;quot;jsonmad&amp;quot; &amp;quot;jsonmad&amp;quot; &amp;quot;jsonmad&amp;quot; &amp;quot;jsonmad&amp;quot; ...
##  - attr(*, &amp;quot;Marker&amp;quot;)= list()
##  - attr(*, &amp;quot;IsTruncated&amp;quot;)= chr &amp;quot;false&amp;quot;
##  - attr(*, &amp;quot;MaxKeys&amp;quot;)= chr &amp;quot;1000&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in (1:nrow(bucket_content))){
  name &amp;lt;- str_remove(bucket_content$Key[i], &amp;quot;.json&amp;quot;) 
  #print(name)
  #print(bucket_content$Key[i])
  save_object(bucket_content$Key[i], bucket = &amp;quot;jsonmad&amp;quot;, 
              file = paste0(&amp;quot;./data/20190511/json/&amp;quot;,
                            bucket_content$Key[i]))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So they landed safely at home on my hard drive. Let‚Äôs look at one. Hi there Mr N¬∞50.&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/20190511/50.gif&#34; alt=&#34;Mr N¬∞50&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Mr N¬∞50&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;And here is his face analysis data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;json_file_sample &amp;lt;- read_json(&amp;quot;./data/20190511/json/50.json&amp;quot;)
str(json_file_sample[[&amp;quot;FaceDetails&amp;quot;]][[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 15
##  $ BoundingBox:List of 4
##   ..$ Width : num 0.6
##   ..$ Height: num 0.629
##   ..$ Left  : num 0.217
##   ..$ Top   : num 0.191
##  $ AgeRange   :List of 2
##   ..$ Low : int 45
##   ..$ High: int 66
##  $ Smile      :List of 2
##   ..$ Value     : logi FALSE
##   ..$ Confidence: num 67
##  $ Eyeglasses :List of 2
##   ..$ Value     : logi TRUE
##   ..$ Confidence: num 95.2
##  $ Sunglasses :List of 2
##   ..$ Value     : logi FALSE
##   ..$ Confidence: num 93
##  $ Gender     :List of 2
##   ..$ Value     : chr &amp;quot;Male&amp;quot;
##   ..$ Confidence: num 96.8
##  $ Beard      :List of 2
##   ..$ Value     : logi FALSE
##   ..$ Confidence: num 96.7
##  $ Mustache   :List of 2
##   ..$ Value     : logi FALSE
##   ..$ Confidence: num 99.5
##  $ EyesOpen   :List of 2
##   ..$ Value     : logi TRUE
##   ..$ Confidence: num 100
##  $ MouthOpen  :List of 2
##   ..$ Value     : logi TRUE
##   ..$ Confidence: num 95.1
##  $ Emotions   :List of 7
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;ANGRY&amp;quot;
##   .. ..$ Confidence: num 27.6
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;DISGUSTED&amp;quot;
##   .. ..$ Confidence: num 21.5
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;SURPRISED&amp;quot;
##   .. ..$ Confidence: num 11.2
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;SAD&amp;quot;
##   .. ..$ Confidence: num 2.28
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;CALM&amp;quot;
##   .. ..$ Confidence: num 10.9
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;CONFUSED&amp;quot;
##   .. ..$ Confidence: num 17.6
##   ..$ :List of 2
##   .. ..$ Type      : chr &amp;quot;HAPPY&amp;quot;
##   .. ..$ Confidence: num 8.97
##  $ Landmarks  :List of 30
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;eyeLeft&amp;quot;
##   .. ..$ X   : num 0.402
##   .. ..$ Y   : num 0.423
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;eyeRight&amp;quot;
##   .. ..$ X   : num 0.667
##   .. ..$ Y   : num 0.438
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;mouthLeft&amp;quot;
##   .. ..$ X   : num 0.406
##   .. ..$ Y   : num 0.635
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;mouthRight&amp;quot;
##   .. ..$ X   : num 0.626
##   .. ..$ Y   : num 0.648
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;nose&amp;quot;
##   .. ..$ X   : num 0.531
##   .. ..$ Y   : num 0.539
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeBrowLeft&amp;quot;
##   .. ..$ X   : num 0.301
##   .. ..$ Y   : num 0.37
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeBrowRight&amp;quot;
##   .. ..$ X   : num 0.465
##   .. ..$ Y   : num 0.362
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeBrowUp&amp;quot;
##   .. ..$ X   : num 0.386
##   .. ..$ Y   : num 0.347
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeBrowLeft&amp;quot;
##   .. ..$ X   : num 0.621
##   .. ..$ Y   : num 0.371
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeBrowRight&amp;quot;
##   .. ..$ X   : num 0.774
##   .. ..$ Y   : num 0.397
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeBrowUp&amp;quot;
##   .. ..$ X   : num 0.7
##   .. ..$ Y   : num 0.365
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeLeft&amp;quot;
##   .. ..$ X   : num 0.354
##   .. ..$ Y   : num 0.419
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeRight&amp;quot;
##   .. ..$ X   : num 0.453
##   .. ..$ Y   : num 0.427
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeUp&amp;quot;
##   .. ..$ X   : num 0.402
##   .. ..$ Y   : num 0.412
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftEyeDown&amp;quot;
##   .. ..$ X   : num 0.402
##   .. ..$ Y   : num 0.431
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeLeft&amp;quot;
##   .. ..$ X   : num 0.61
##   .. ..$ Y   : num 0.436
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeRight&amp;quot;
##   .. ..$ X   : num 0.707
##   .. ..$ Y   : num 0.439
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeUp&amp;quot;
##   .. ..$ X   : num 0.664
##   .. ..$ Y   : num 0.427
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightEyeDown&amp;quot;
##   .. ..$ X   : num 0.66
##   .. ..$ Y   : num 0.446
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;noseLeft&amp;quot;
##   .. ..$ X   : num 0.475
##   .. ..$ Y   : num 0.562
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;noseRight&amp;quot;
##   .. ..$ X   : num 0.572
##   .. ..$ Y   : num 0.567
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;mouthUp&amp;quot;
##   .. ..$ X   : num 0.519
##   .. ..$ Y   : num 0.615
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;mouthDown&amp;quot;
##   .. ..$ X   : num 0.512
##   .. ..$ Y   : num 0.678
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;leftPupil&amp;quot;
##   .. ..$ X   : num 0.402
##   .. ..$ Y   : num 0.423
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;rightPupil&amp;quot;
##   .. ..$ X   : num 0.667
##   .. ..$ Y   : num 0.438
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;upperJawlineLeft&amp;quot;
##   .. ..$ X   : num 0.22
##   .. ..$ Y   : num 0.423
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;midJawlineLeft&amp;quot;
##   .. ..$ X   : num 0.26
##   .. ..$ Y   : num 0.654
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;chinBottom&amp;quot;
##   .. ..$ X   : num 0.498
##   .. ..$ Y   : num 0.789
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;midJawlineRight&amp;quot;
##   .. ..$ X   : num 0.736
##   .. ..$ Y   : num 0.68
##   ..$ :List of 3
##   .. ..$ Type: chr &amp;quot;upperJawlineRight&amp;quot;
##   .. ..$ X   : num 0.813
##   .. ..$ Y   : num 0.456
##  $ Pose       :List of 3
##   ..$ Roll : num 2.95
##   ..$ Yaw  : num 2.22
##   ..$ Pitch: num -8.8
##  $ Quality    :List of 2
##   ..$ Brightness: num 81.1
##   ..$ Sharpness : num 83.1
##  $ Confidence : num 100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs put all of the json files in a data frame and first download them from the bucket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setwd(&amp;quot;./data/20190511/json/&amp;quot;)
files &amp;lt;- list.files()
faces_reps &amp;lt;- data.frame()
for (i in (1: length(files))){
x &amp;lt;- read_json(files[i])
#print(files[i])
y &amp;lt;- as.data.frame(x$FaceDetails)
number &amp;lt;- str_remove(as.character(files[i]),&amp;quot;.json&amp;quot;)
y &amp;lt;- cbind(y, number)
faces_reps &amp;lt;- rbind(faces_reps, y)
}

dim(faces_reps)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179 133&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like they are all there, but we lost their names along the way.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_name &amp;lt;- list.files(&amp;quot;./data/190417&amp;quot;, pattern = &amp;quot;*.gif&amp;quot;) %&amp;gt;% 
  str_remove(&amp;quot;.gif&amp;quot;)
ln_fn &amp;lt;- data.frame(&amp;quot;number&amp;quot; = 1:179,
                    &amp;quot;ln_fn&amp;quot; = to_name)

faces_reps$number &amp;lt;- as.integer(as.character(faces_reps$number))
faces_reps &amp;lt;- faces_reps %&amp;gt;% 
  left_join(ln_fn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;number&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# saveRDS(faces_reps,&amp;quot;./data/20190511/faces.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Et voil√†. A nice data frame to have fun with. üòÑ For instance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;faces_reps %&amp;gt;% group_by(Smile.Value)%&amp;gt;% 
  summarise(count = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   Smile.Value count
##   &amp;lt;lgl&amp;gt;       &amp;lt;int&amp;gt;
## 1 FALSE          21
## 2 TRUE          158&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That‚Äôs 88% smiling faces in a bucket S3.&lt;/p&gt;
&lt;p&gt;More soon.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>Belgian parliamentarians tweets</title>
      <link>/post/belgian-parliamentarians-tweets/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/belgian-parliamentarians-tweets/</guid>
      <description></description>
      
      <content>


&lt;p&gt;In the last post we were pretty successful in getting our parliamentarians Twitter handles. We can now use these to download their tweets.&lt;/p&gt;
&lt;p&gt;The twitter API allows to download 3200 tweets per handle. This means that we will not be able to download all tweets of all parliamentarians from the last five years, because some of them tweeted more than 3200 during that time period. But there will be a fair amount.&lt;/p&gt;
&lt;p&gt;These tweets will also have to be ‚Äòcleaned‚Äô of special characters like emojis and links in order to analyse them further without the different packages choking on them.&lt;/p&gt;
&lt;p&gt;As usually first the libraries and options:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;gmp&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;rtweet&amp;quot;)
library(&amp;quot;cld2&amp;quot;) 
library(&amp;quot;textcat&amp;quot;)
library(&amp;quot;qdapRegex&amp;quot;)
library(&amp;quot;xml2&amp;quot;)
library(&amp;quot;rvest&amp;quot;)
library(&amp;quot;lubridate&amp;quot;)

# options 

options(scipen=999)
stringAsFactors = FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here is the function to get the tweets (for now just 1 for testing, because 3200 tweets takes a while):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_handle_tweets &amp;lt;- function(handle) {
  tweets_handle &amp;lt;&amp;lt;- get_timeline(handle, n=1)
  n &amp;lt;- nrow(tweets_handle)
    print(glue(&amp;quot;{handle} {n} tweets added&amp;quot;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And a function to clean the tweets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_byte &amp;lt;- function (x) {
  Encoding(x) &amp;lt;- &amp;quot;latin1&amp;quot;
  iconv(x, &amp;quot;latin1&amp;quot;, &amp;quot;ASCII&amp;quot;, &amp;quot;byte&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the handles:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- readRDS(&amp;quot;~/R/blogs/content/post/data/20190502/twitter_users.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A test&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users$screen_name[3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;SonjaBecq&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It‚Äôs not strictly needed since we already know the correspondence between name and handle (‚Äòscreen_name‚Äô), but it‚Äôs fun to try map2_df. A test with two tweets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_handle_tweets &amp;lt;- function(screen_name, ln_fn) {
  get_timeline(screen_name, n=2) %&amp;gt;% 
    mutate(ln_fn = ln_fn)
}

tweets &amp;lt;- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL))
dim(tweets)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#saveRDS(tweets, &amp;quot;./data/20190503/tweets1.rds&amp;quot;)
tweets &amp;lt;- readRDS(&amp;quot;./data/20190503/tweets1.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now might be a good time to talk about rate limits. We are limited to go 3200 tweets in the past per handle, but we have also temporary limits to the calls we can do with the API.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;limits &amp;lt;- rate_limits()
head(limits)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   query limit remaining reset reset_at            timestamp           app  
##   &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;tim&amp;gt; &amp;lt;dttm&amp;gt;              &amp;lt;dttm&amp;gt;              &amp;lt;chr&amp;gt;
## 1 list~    15        15 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~
## 2 list~    75        75 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~
## 3 list~    15        15 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~
## 4 list~   900       900 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~
## 5 list~    15        15 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~
## 6 list~    75        75 15.0~ 2019-05-17 23:12:22 2019-05-17 22:57:22 madc~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In total there are 149 limits, we can access, among other things, how much remains and when the limit will be reset. Here are some of the limits:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(limits$query, 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;lists/list&amp;quot;                    &amp;quot;lists/memberships&amp;quot;            
##  [3] &amp;quot;lists/subscribers/show&amp;quot;        &amp;quot;lists/members&amp;quot;                
##  [5] &amp;quot;lists/subscriptions&amp;quot;           &amp;quot;lists/show&amp;quot;                   
##  [7] &amp;quot;lists/ownerships&amp;quot;              &amp;quot;lists/subscribers&amp;quot;            
##  [9] &amp;quot;lists/members/show&amp;quot;            &amp;quot;lists/statuses&amp;quot;               
## [11] &amp;quot;application/rate_limit_status&amp;quot; &amp;quot;mutes/users/list&amp;quot;             
## [13] &amp;quot;mutes/users/ids&amp;quot;               &amp;quot;live_video_stream/status/:id&amp;quot; 
## [15] &amp;quot;friendships/outgoing&amp;quot;          &amp;quot;friendships/list&amp;quot;             
## [17] &amp;quot;friendships/no_retweets/ids&amp;quot;   &amp;quot;friendships/lookup&amp;quot;           
## [19] &amp;quot;friendships/incoming&amp;quot;          &amp;quot;friendships/show&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point we need to keep an eye on limits tweets (#49) and limits queries (#11).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;limits %&amp;gt;% select(limit, query, remaining, reset) %&amp;gt;% 
  filter(query ==  &amp;quot;application/rate_limit_status&amp;quot;|
          query ==  &amp;quot;statuses/user_timeline&amp;quot;) %&amp;gt;% 
  mutate(reset = round(reset, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 4
##   limit query                         remaining reset     
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                             &amp;lt;int&amp;gt; &amp;lt;time&amp;gt;    
## 1   180 application/rate_limit_status       179 15.01 mins
## 2   900 statuses/user_timeline              900 15.01 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are searching 160 users and the rate limit for searching user timelines is 900, so we should be fine. But be aware that your limit searches are limited also (180 searches counted by individual limit in batches of 15 minutes).&lt;/p&gt;
&lt;p&gt;At a certain point in time it might be useful to periodically query certain limits and to then pause the code in order not to produce interruptions.&lt;/p&gt;
&lt;p&gt;How well did our test go? Did we get tweets from everyone?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(twitter_users$ln_fn, tweets$ln_fn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice. The results look ok too. Will now launch the bigger batch (3200) while out playing some üè∏ and after having waited fifteen minutes to be sure all rate limits were reset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- twitter_users %&amp;gt;% 
  arrange(screen_name) %&amp;gt;% 
  distinct(screen_name, .keep_all = TRUE) # removing doubles if present

get_handle_tweets &amp;lt;- function(screen_name, ln_fn) {
  print(screen_name) # this can be used to see the advancement
  get_timeline(screen_name, n=3200) %&amp;gt;% 
    mutate(ln_fn = ln_fn)
}

system.time(tweets &amp;lt;- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL)))
dim(tweets)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cool, so about 265K tweets.&lt;/p&gt;
&lt;p&gt;But as already mentioned these are some of the tweets from people who at some time were in the 54th legislature. They are not always a tweet from a person actually seating in parliament.&lt;/p&gt;
&lt;p&gt;This Wikipedia page &lt;a href=&#34;https://nl.Wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019)&#34; class=&#34;uri&#34;&gt;https://nl.Wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019)&lt;/a&gt; has a good overview of the changes that occurred since May 2014.&lt;/p&gt;
&lt;p&gt;A few have also changed party or became independent. The table that was used to obtain the list of parliamentarian‚Äôs names, language and party, can be transformed into a reference table that we can join to the tweets for further analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names &amp;lt;- readRDS(&amp;quot;./data/190417/names.rds&amp;quot;)
party_less &amp;lt;- names %&amp;gt;% 
  filter(is.na(party))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The text on the Wikipedia page contains the information that is needed, but I wonder how easy it will be to use. We can try, let‚Äôs see what we get.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;quot;https://nl.Wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019)&amp;quot; 

wiki_table_source&amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;%
  html_node(xpath = &amp;#39;//*[@id=&amp;quot;mw-content-text&amp;quot;]/div/table[4]&amp;#39;)  %&amp;gt;%
  html_table(fill = TRUE)

head(wiki_table_source)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 Volksvertegenwoordiger Fractie Kieskring  Taalgroep
## 1         Almaci, Meyrem Meyrem Almaci   Groen Antwerpen Nederlands
## 2           Bellens, Rita Rita Bellens    N-VA Antwerpen Nederlands
## 3         Calvo, Kristof Kristof Calvo   Groen Antwerpen Nederlands
## 4 De Coninck, Monica Monica De Coninck    sp.a Antwerpen Nederlands
## 5             Demir, Zuhal Zuhal Demir    N-VA Antwerpen Nederlands
## 6     De Roover, Peter Peter De Roover    N-VA Antwerpen Nederlands
##                                                                                                                          Opmerkingen
## 1                                                                                                                               &amp;lt;NA&amp;gt;
## 2                                                                                                                               &amp;lt;NA&amp;gt;
## 3                                                                                                                               &amp;lt;NA&amp;gt;
## 4                                                                                                                               &amp;lt;NA&amp;gt;
## 5 Werd van 9 maart 2017 tot 9 december 2018 als staatssecretaris in de federale regering-Michel I vervangen door Wim Van der Donckt.
## 6                                                                                                                               &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The nice thing is that additional information like the voting district was obtained. Using the comments (‚ÄúOpmerkingen‚Äù), will probably be more time consuming than hard coding the changes, but I think it will be more fun ;-)&lt;/p&gt;
&lt;p&gt;That is if you are interested in data cleaning. If not no need to continue reading this post, because it will be all spring cleaning from now till the end.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table_source %&amp;gt;% 
  filter(!is.na(Opmerkingen)) %&amp;gt;%
  mutate(Opmerkingen = substr(Opmerkingen,0,100)) %&amp;gt;% 
  select(Opmerkingen) %&amp;gt;% 
  slice(1:7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                            Opmerkingen
## 1 Werd van 9 maart 2017 tot 9 december 2018 als staatssecretaris in de federale regering-Michel I verv
## 2 Werd van 14 oktober 2014 tot 9 december 2018 als minister in de federale regering-Michel I vervangen
## 3                          Vervangt vanaf 19 juni 2014 Marijke Dillen, die beslist om niet te zetelen.
## 4 Vervangt sinds 3 mei 2018 Annemie Turtelboom, die lid wordt van de Europese Rekenkamer. Eerder vervi
## 5                                                       Voorzitter van de Kamer vanaf 14 oktober 2014.
## 6 Vervangt vanaf 10 november 2016 Sarah Claerhout, die uit CD&amp;amp;V stapt en haar zetel aan haar partij te
## 7 Vervangt vanaf 14 oktober 2014 Alexander De Croo, die minister in de federale regering-Michel I werd&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;‚ÄòVervangt‚Äô means ‚Äòreplaces‚Äô, so these are members that replaced someone who took on another mandate. ‚ÄòWerd‚Äô means ‚Äòwas‚Äô, so these were replaced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table &amp;lt;- wiki_table_source %&amp;gt;% 
  filter(!is.na(Opmerkingen)) %&amp;gt;% 
  mutate(first_word = str_extract(Opmerkingen,&amp;quot;(\\w+)&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the comments (Opmerkingen) there are up to three dates that we need. A first step would be to change the month names in numbers. And then extract all the numbers into a list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table &amp;lt;- wiki_table %&amp;gt;% 
  mutate(Opmerkingen = gsub(&amp;quot;januari&amp;quot;, 1, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;februari&amp;quot;, 2, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;maart&amp;quot;, 3, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;april&amp;quot;, 4, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;mei&amp;quot;, 5, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;juni&amp;quot;, 6, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;juli&amp;quot;, 7, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;augustus&amp;quot;, 8, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;september&amp;quot;, 9, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;oktober&amp;quot;, 10, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;november&amp;quot;, 11, Opmerkingen),
         Opmerkingen = gsub(&amp;quot;december&amp;quot;, 12, Opmerkingen)) %&amp;gt;%
    mutate(digits = str_extract_all(Opmerkingen,&amp;quot;([0-9]+)&amp;quot;)) %&amp;gt;% #&amp;#39;+&amp;#39; keeps them together
  filter(first_word != &amp;quot;De&amp;quot;) # this one has no date 



inspect &amp;lt;-wiki_table$digits
inspect[[20]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;22&amp;quot;   &amp;quot;9&amp;quot;    &amp;quot;2015&amp;quot; &amp;quot;11&amp;quot;   &amp;quot;10&amp;quot;   &amp;quot;2014&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It will be more difficult to handle the digits if days and months smaller than 10 do not have a leading 0. So one needs to be added, before concatenating all the numbers&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in (1:length(inspect))){
  for (j in (1:length(inspect[[i]]))){
    if (nchar(inspect[[i]][j]) == 1) {inspect[[i]][j] &amp;lt;- paste0(&amp;quot;0&amp;quot;,inspect[[i]][j])}
  }
  inspect[[i]] &amp;lt;- paste0(inspect[[i]], collapse = &amp;quot;&amp;quot;)
  print(inspect[[i]])
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;0903201709122018&amp;quot;
## [1] &amp;quot;1410201409122018&amp;quot;
## [1] &amp;quot;19062014&amp;quot;
## [1] &amp;quot;030520183007201429042016&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;1011201614102014&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;14032019&amp;quot;
## [1] &amp;quot;24082017&amp;quot;
## [1] &amp;quot;24052018&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;06122018&amp;quot;
## [1] &amp;quot;12012017&amp;quot;
## [1] &amp;quot;13122017&amp;quot;
## [1] &amp;quot;19112015&amp;quot;
## [1] &amp;quot;30072014&amp;quot;
## [1] &amp;quot;06122018&amp;quot;
## [1] &amp;quot;28052015&amp;quot;
## [1] &amp;quot;19112015&amp;quot;
## [1] &amp;quot;2209201511102014&amp;quot;
## [1] &amp;quot;09112017&amp;quot;
## [1] &amp;quot;18102018&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;23042015&amp;quot;
## [1] &amp;quot;1410201409122018&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;22092710201627102016&amp;quot;
## [1] &amp;quot;300614102014&amp;quot;
## [1] &amp;quot;1410201412112018&amp;quot;
## [1] &amp;quot;22092710201627102016&amp;quot;
## [1] &amp;quot;0410201830072014&amp;quot;
## [1] &amp;quot;14102014&amp;quot;
## [1] &amp;quot;20092018&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pure poetry if you ask me

con_dates &amp;lt;- data.frame(&amp;quot;condate&amp;quot; = unlist(inspect))
wiki_table &amp;lt;- wiki_table %&amp;gt;% 
  cbind(con_dates) %&amp;gt;% 
  select(-digits)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can extrat the dates, but one problem still remains, on wikipedia some years are not repeated for certain time periods (so there are only 4 digits for a date):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table$Opmerkingen[28]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Zetelt van 22 9 tot 27 10 2016 als onafhankelijke en vanaf 27 10 2016 in de Vuye&amp;amp;Wouters-fractie.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.character(wiki_table$condate[28])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;22092710201627102016&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A little bit more work is needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table &amp;lt;- wiki_table %&amp;gt;% 
  mutate(date_1 = 
           ifelse(substr(condate,5,6) == &amp;quot;20&amp;quot;,
                  substr(condate,1,8),
                  paste0(substr(condate,1,4),
                    substr(condate,str_locate(condate, &amp;quot;201&amp;quot;),
                            str_locate(condate, &amp;quot;201&amp;quot;) + 3))
                  )
         ) %&amp;gt;% 
   mutate(date_2 = 
           ifelse(substr(condate,5,6) == &amp;quot;20&amp;quot;,
                  substr(condate,9,16),
                  paste0(
                    substr(condate,str_locate(condate, &amp;quot;201&amp;quot;)-4,
                            str_locate(condate, &amp;quot;201&amp;quot;) + 3))
                  )
         ) %&amp;gt;% 
   mutate(date_3 = 
           ifelse(substr(condate,5,6) == &amp;quot;20&amp;quot;,
                  substr(condate,17,24),
                  &amp;quot;&amp;quot;)
         ) %&amp;gt;% 
  select(-condate)


wiki_table &amp;lt;- wiki_table %&amp;gt;% 
  mutate(date_1 = dmy(as.numeric(date_1)),
         date_2 = dmy(as.numeric(date_2)),
         date_3 = dmy(as.numeric(date_3)),
                )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok that looks fine now.&lt;/p&gt;
&lt;p&gt;There are other possibilities, but here we will use a table with one line per period a person seated for a party. To later use in the analysis of the tweets collected. In that table there will be one start date and one end date. A good start is assuming everyone started at ‚Äú2014-06-19‚Äù and ended at ‚Äú2019-05-31‚Äù, and then making corrections afterwards.&lt;/p&gt;
&lt;p&gt;We can start by consolidating our tables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(names(wiki_table),names(wiki_table_source))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;first_word&amp;quot; &amp;quot;date_1&amp;quot;     &amp;quot;date_2&amp;quot;     &amp;quot;date_3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wiki_table &amp;lt;- wiki_table %&amp;gt;% 
  rbind(wiki_table_source %&amp;gt;% 
          filter(is.na(Opmerkingen) 
                 | Volksvertegenwoordiger == &amp;quot;Jadin, Kattrin Kattrin Jadin&amp;quot;) %&amp;gt;%
          mutate(first_word = &amp;quot;&amp;quot;,
                 date_1 = as.Date(&amp;quot;2001-01-01&amp;quot;),
                 date_2 = as.Date(&amp;quot;2001-01-01&amp;quot;),
                 date_3 = as.Date(&amp;quot;2001-01-01&amp;quot;))
                              )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Aw, shoot did not see the names are funky.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(wiki_table$Volksvertegenwoordiger)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Demir, Zuhal Zuhal Demir&amp;quot;                  
## [2] &amp;quot;Jambon, Jan Jan Jambon&amp;quot;                    
## [3] &amp;quot;Penris, Jan Jan Penris&amp;quot;                    
## [4] &amp;quot;Wilrycx, Frank Frank Wilrycx&amp;quot;              
## [5] &amp;quot;Bracke, Siegfried Siegfried Bracke&amp;quot;        
## [6] &amp;quot;Van Peteghem, Vincent Vincent Van Peteghem&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maybe we can join on the concatenation of letters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- wiki_table %&amp;gt;% 
  mutate(join = str_remove_all(Volksvertegenwoordiger,&amp;quot; &amp;quot;),
         join = str_remove_all(join,&amp;quot;,&amp;quot;),
         join = substr(join,1, nchar(join)/2))

y &amp;lt;- names %&amp;gt;% 
  mutate(join = str_remove_all(ln_fn,&amp;quot; &amp;quot;))

z &amp;lt;- y %&amp;gt;% 
  left_join(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;join&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- z %&amp;gt;% 
  filter(!is.na(Volksvertegenwoordiger)) %&amp;gt;% 
  mutate(test = &amp;quot;test&amp;quot;)
  
missing &amp;lt;- wiki_table %&amp;gt;% 
  left_join(test %&amp;gt;% 
              select(Volksvertegenwoordiger, test)) %&amp;gt;% 
  filter(is.na(test))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;Volksvertegenwoordiger&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;missing$Volksvertegenwoordiger&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Van de Velde, Rob Rob Van de Velde&amp;quot;                  
## [2] &amp;quot;Fernandez-Fernandez, Julie Julie Fernandez-Fernandez&amp;quot;
## [3] &amp;quot;Jirofl√©e, Karine Karine Jirofl√©e&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes I‚Äôve got myself in a pickle again. Three missing. The join field for them should be VandeVeldeRobert, Jirofl√©eKarin and, FernandezFernandezJulie. Instead of VandeVeldeRob, Jirofl√©eKarine and Fernandez-FernandezJulie.&lt;/p&gt;
&lt;p&gt;We can follow how they are spelled on dekamer.be: Robert Van de Velde, Karin Jirofl√©e, Julie Fernandez Fernandez&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x[x$join == &amp;quot;VandeVeldeRob&amp;quot;,]$join &amp;lt;- &amp;quot;VandeVeldeRobert&amp;quot;
x[x$join == &amp;quot;Jirofl√©eKarine&amp;quot;,]$join &amp;lt;- &amp;quot;Jirofl√©eKarin&amp;quot;
x[x$join == &amp;quot;Fernandez-FernandezJulie&amp;quot;,]$join &amp;lt;- &amp;quot;FernandezFernandezJulie&amp;quot;

y &amp;lt;- names %&amp;gt;% 
  mutate(join = str_remove_all(ln_fn,&amp;quot; &amp;quot;))

z &amp;lt;- y %&amp;gt;% 
  left_join(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;join&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- z %&amp;gt;% 
  filter(!is.na(Volksvertegenwoordiger)) %&amp;gt;% 
  mutate(test = &amp;quot;test&amp;quot;)
  
missing &amp;lt;- wiki_table %&amp;gt;% 
  left_join(test %&amp;gt;% 
              select(Volksvertegenwoordiger, test)) %&amp;gt;% 
  filter(is.na(test))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;Volksvertegenwoordiger&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;missing$Volksvertegenwoordiger&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yeah! So now we have em all we can give em a default start date and a default end date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54 &amp;lt;- z %&amp;gt;% 
  mutate(start_date = as.Date(&amp;quot;2014-06-19&amp;quot;),
         end_date = as.Date(&amp;quot;2019-05-31&amp;quot;)) %&amp;gt;% 
  mutate(fn_ln = trimws(fn_ln, c(&amp;quot;both&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maybe we can start with those who only have one ‚Äòdate_1‚Äô? Let‚Äôs have a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_date &amp;lt;- reps54 %&amp;gt;% 
  filter(!is.na(date_1) &amp;amp;
           is.na(date_2))

unique(one_date$first_word)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Voorzitter&amp;quot; &amp;quot;Vanaf&amp;quot;      &amp;quot;Vervangt&amp;quot;   &amp;quot;Zetelt&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;‚ÄúVoorzitter‚Äù is the president of the chamber. Not interested in this for now, so no change to be made. ‚ÄúVanaf‚Äù seems to indicate a change of party and/or party name. What happened to the &lt;a href=&#34;https://en.wikipedia.org/wiki/D%C3%A9FI&#34;&gt;FDF&lt;/a&gt;? Seems to have been a name change.&lt;/p&gt;
&lt;p&gt;In the data that come from the official website these members are already ‚ÄòD√©fi‚Äô in the field ‚ÄòParty‚Äô. We can work on the field ‚Äòfractie‚Äô (party) but I doubt it will be needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fdf &amp;lt;- one_date %&amp;gt;% 
  filter(first_word == &amp;quot;Vanaf&amp;quot;) %&amp;gt;% 
  mutate(end_date = ymd(date_1) -days(1)) %&amp;gt;% 
  rbind(one_date %&amp;gt;% 
          filter(first_word == &amp;quot;Vanaf&amp;quot;) %&amp;gt;% 
          mutate(start_date = date_1,
                 Fractie = &amp;quot;D√©fi&amp;quot;))

one_date &amp;lt;- one_date %&amp;gt;% 
  filter(first_word != &amp;quot;Vanaf&amp;quot;) %&amp;gt;% 
  rbind(fdf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that takes care of ‚ÄòVanaf‚Äô, now for ‚ÄúVervangt‚Äù (replaces). Which looks pretty straightforward. The date_1 just needs to replace the start date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;replaces &amp;lt;- one_date %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;% 
  mutate(start_date = date_1)

one_date &amp;lt;- one_date %&amp;gt;% 
  filter(first_word != &amp;quot;Vervangt&amp;quot;) %&amp;gt;% 
  rbind(replaces)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case ‚ÄòZetelt‚Äô means the person became independent. I doubt it will make a big difference to make the change for one person, but for the sake of precision, here is the correction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zetelt &amp;lt;- one_date %&amp;gt;% 
  filter(first_word == &amp;quot;Zetelt&amp;quot;) %&amp;gt;% 
  mutate(end_date = ymd(date_1) -days(1)) %&amp;gt;% 
  rbind(one_date %&amp;gt;% 
          filter(first_word == &amp;quot;Zetelt&amp;quot;) %&amp;gt;% 
          mutate(start_date = date_1,
                 Fractie = &amp;quot;ONAFH&amp;quot;))

one_date &amp;lt;- one_date %&amp;gt;% 
  filter(first_word != &amp;quot;Zetelt&amp;quot;) %&amp;gt;% 
  rbind(zetelt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now just need to bind them and go to the next batch.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54 &amp;lt;- reps54 %&amp;gt;% 
  filter(is.na(date_1) | date_1 == &amp;quot;2001-01-01&amp;quot;
         | (date_1 != &amp;quot;2001-01-01&amp;quot; &amp;amp; date_2 != &amp;quot;2001-01-01&amp;quot;))%&amp;gt;% 
  rbind(one_date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;two_dates&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;two_dates &amp;lt;- reps54 %&amp;gt;% 
  filter(!is.na(date_1) &amp;amp;
           !is.na(date_2) &amp;amp;
           is.na(date_3))

unique(two_dates$first_word)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Vervangt&amp;quot;   &amp;quot;Werd&amp;quot;       &amp;quot;Voorzitter&amp;quot; &amp;quot;Zetelt&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are now three replacements (Vervangt) with two dates in the comment phrase. It is getting complicated, but fortunately they seem to be structured the same way.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;two_dates %&amp;gt;% filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  mutate(Opmerkingen = substr(Opmerkingen, 0, 100)) %&amp;gt;% 
  select(Opmerkingen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                            Opmerkingen
## 1 Vervangt vanaf 22 9 2015 Sophie Wilm√®s, die minister wordt in de federale regering-Michel I. Wilm√®s 
## 2 Vervangt vanaf 4 10 2018 St√©phane Crusni√®re, die financieel en administratief directeur van de R√©gie
## 3 Vervangt vanaf 10 11 2016 Sarah Claerhout, die uit CD&amp;amp;V stapt en haar zetel aan haar partij teruggee&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we are looking at these parliamentarians:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;two_dates %&amp;gt;% filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;% 
  select(fn_ln)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  fn_ln
## 1      Gautier Calomne
## 2     Michel Corthouts
## 3 Vincent Van Peteghem&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They just enter the parliament at date_1, that is easy, but there is more information in the remarks. Easy part first (EPF), low hanging fruits, quick impacts and what have you.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vervangt &amp;lt;- two_dates %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;% 
  mutate(start_date = date_1)

two_dates &amp;lt;- two_dates %&amp;gt;% 
  filter(first_word != &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  rbind(vervangt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those with ‚Äúwerd‚Äù were replaced during a period, so end_date is date_1-1 for their first period, and date_2+1 is the start date of their second period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;werd_1 &amp;lt;- two_dates %&amp;gt;% 
  filter(first_word == &amp;quot;Werd&amp;quot;) %&amp;gt;% 
  mutate(end_date = ymd(date_1) - days(1))

werd_2 &amp;lt;- two_dates %&amp;gt;% 
  filter(first_word == &amp;quot;Werd&amp;quot;) %&amp;gt;% 
  mutate(start_date = ymd(date_2) + days(1))

werd &amp;lt;- rbind(werd_1, werd_2)

two_dates &amp;lt;- two_dates %&amp;gt;%
  filter(first_word != &amp;quot;Werd&amp;quot;) %&amp;gt;%
  rbind(werd)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those with ‚ÄúZetelt‚Äù (seats) changed parties twice. First became independent (from NV&amp;amp;A), then created a new party ‚ÄúVuye&amp;amp;Wouters‚Äù.
Mr Hendrik Vuye tweets a lot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zetelt&amp;lt;- two_dates %&amp;gt;% 
  filter(first_word == &amp;quot;Zetelt&amp;quot;) 

zetelt$Opmerkingen&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Zetelt van 22 9 tot 27 10 2016 als onafhankelijke en vanaf 27 10 2016 in de Vuye&amp;amp;Wouters-fractie.&amp;quot;  
## [2] &amp;quot;Zetelt vanaf 22 9 tot 27 10 2016 als onafhankelijke en vanaf 27 10 2016 in de Vuye&amp;amp;Wouters-fractie.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nva &amp;lt;- zetelt %&amp;gt;% 
  mutate(Fractie = &amp;quot;NV&amp;amp;A&amp;quot;,
         end_date = ymd(date_1) - days(1))
onaf &amp;lt;- zetelt %&amp;gt;% 
  mutate(Fractie = &amp;quot;ONAFH&amp;quot;,
         start_date = date_1,
         end_date = date_2)
vuye &amp;lt;- zetelt %&amp;gt;% 
  mutate(Fractie = &amp;quot;Vuye&amp;amp;Wouters&amp;quot;,
         start_date = ymd(date_2) + days(1))

two_dates&amp;lt;- two_dates %&amp;gt;% 
  filter(first_word != &amp;quot;Zetelt&amp;quot;) %&amp;gt;% 
  rbind(nva) %&amp;gt;% 
  rbind(onaf) %&amp;gt;% 
  rbind(vuye)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to go back to the comments with one days. They indicate the end date of a number of people and in particular of mayors or members of the government.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_date %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;% 
  select(Opmerkingen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                                 Opmerkingen
## 1                     Vervangt vanaf 13 12 2017 Ann Vanheste, die voltijds burgemeester van De Panne wordt.
## 2                         Vervangt vanaf 9 11 2017 Willy Demeyer, die voltijds burgemeester van Luik wordt.
## 3         Vervangt vanaf 30 7 2014 C√©line Fremault, die minister in de Brusselse regering-Vervoort II wordt
## 4  Vervangt vanaf 6 12 2018 Sabien Lahaye-Battheu, die gedeputeerde van de provincie West-Vlaanderen wordt.
## 5                        Vervangt vanaf 23 4 2015 Melchior Wathelet, die actief wordt in het bedrijfsleven.
## 6           Vervangt vanaf 14 10 2014 Alexander De Croo, die minister in de federale regering-Michel I werd
## 7                Vervangt vanaf 24 8 2017 Denis Ducarme, die minister in de federale Regering-Michel I werd
## 8                                      Vervangt vanaf 20 9 2018 Isabelle Poncelet, die de politiek verlaat.
## 9          Vervangt vanaf 14 10 2014 Daniel Bacquelaine, die minister in de federale regering-Michel I werd
## 10                  Vervangt vanaf 24 5 2018 Eric Massin, die voltijds OCMW-voorzitter van Charleroi wordt.
## 11            Vervangt vanaf 14 10 2014 Maggie De Block, die minister in de federale regering-Michel I werd
## 12              Vervangt vanaf 12 1 2017 Johan Vande Lanotte, die voltijds burgemeester van Oostende wordt.
## 13    Vervangt vanaf 14 10 2014 Marie-Christine Marghem, die minister in de federale regering-Michel I werd
## 14                                 Vervangt vanaf 19 6 2014 Marijke Dillen, die beslist om niet te zetelen.
## 15    Vervangt vanaf 18 10 2018 Muriel Gerkens, die zich kandidaat stelt bij de provincieraadsverkiezingen.
## 16             Vervangt vanaf 14 10 2014 Charles Michel, die minister in de federale regering-Michel I werd
## 17                           Vervangt vanaf 28 5 2015 Zakia Khattabi, die partijvoorzitter van Ecolo wordt.
## 18                 Vervangt vanaf 14 10 2014 Koen Geens, die minister in de federale regering-Michel I werd
## 19                                 Vervangt vanaf 6 12 2018 Benoit Hellings, die schepen van Brussel wordt.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could use a regex to extract between the last digit and the ,
But regexps are always more difficult than they seem. So here it is just easier to use ‚Äòsubstr‚Äô.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_locate(one_date$Opmerkingen[10], &amp;quot;201&amp;quot;)[2]+3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 26&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_locate(one_date$Opmerkingen[10], &amp;quot;,&amp;quot;)[1]-1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 42&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substr(one_date$Opmerkingen[10], 26, 42)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Melchior Wathelet&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;end_dates &amp;lt;- one_date %&amp;gt;% 
  select(date_1, Opmerkingen, first_word) %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  mutate(fn_ln = substr(Opmerkingen,
                                str_locate(Opmerkingen, &amp;quot;201&amp;quot;)[,2]+3,
                                str_locate(Opmerkingen, &amp;quot;,&amp;quot;)[,1]-1)) %&amp;gt;% 
  select(-Opmerkingen, -first_word, )

end_dates$fn_ln&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Ann Vanheste&amp;quot;            &amp;quot;Willy Demeyer&amp;quot;          
##  [3] &amp;quot;C√©line Fremault&amp;quot;         &amp;quot;Sabien Lahaye-Battheu&amp;quot;  
##  [5] &amp;quot;Melchior Wathelet&amp;quot;       &amp;quot;Alexander De Croo&amp;quot;      
##  [7] &amp;quot;Denis Ducarme&amp;quot;           &amp;quot;Isabelle Poncelet&amp;quot;      
##  [9] &amp;quot;Daniel Bacquelaine&amp;quot;      &amp;quot;Eric Massin&amp;quot;            
## [11] &amp;quot;Maggie De Block&amp;quot;         &amp;quot;Johan Vande Lanotte&amp;quot;    
## [13] &amp;quot;Marie-Christine Marghem&amp;quot; &amp;quot;Marijke Dillen&amp;quot;         
## [15] &amp;quot;Muriel Gerkens&amp;quot;          &amp;quot;Charles Michel&amp;quot;         
## [17] &amp;quot;Zakia Khattabi&amp;quot;          &amp;quot;Koen Geens&amp;quot;             
## [19] &amp;quot;Benoit Hellings&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_end &amp;lt;- reps54 %&amp;gt;%
  filter(fn_ln %in% end_dates$fn_ln)

setdiff(end_dates$fn_ln,new_end$fn_ln)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Marijke Dillen&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we do not have &lt;a href=&#34;https://nl.wikipedia.org/wiki/Marijke_Dillen&#34;&gt;that&lt;/a&gt; nice young lady because she decided not to go to parliament and gave her seat to the fine young gentleman Jan Penris&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_replace &amp;lt;- new_end %&amp;gt;% 
  left_join(end_dates,  by = c(&amp;quot;fn_ln&amp;quot;)) %&amp;gt;% 
  mutate(end_date = date_1.y) %&amp;gt;% 
  select(-date_1.y) %&amp;gt;% 
  rename(&amp;quot;date_1&amp;quot; = &amp;quot;date_1.x&amp;quot;)

reps54&amp;lt;-  reps54 %&amp;gt;%
  filter(!fn_ln %in% end_dates$fn_ln) %&amp;gt;% 
  rbind(to_replace)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can do the same with the comments within ‚Äòtwo_dates‚Äô&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;two_dates %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  mutate(Opmerkingen = substr(Opmerkingen, 0, 100)) %&amp;gt;% 
  select(Opmerkingen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                            Opmerkingen
## 1 Vervangt vanaf 22 9 2015 Sophie Wilm√®s, die minister wordt in de federale regering-Michel I. Wilm√®s 
## 2 Vervangt vanaf 4 10 2018 St√©phane Crusni√®re, die financieel en administratief directeur van de R√©gie
## 3 Vervangt vanaf 10 11 2016 Sarah Claerhout, die uit CD&amp;amp;V stapt en haar zetel aan haar partij teruggee&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So here we have for instance Mrs Wilm√®s who is being replaced on 22/09/2015, but who replaced Mr Reynders on 11/10/2014.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;end_dates_two &amp;lt;- two_dates %&amp;gt;% 
  select(date_1, Opmerkingen, first_word) %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  mutate(fn_ln = substr(Opmerkingen,
                                str_locate(Opmerkingen, &amp;quot;201&amp;quot;)[,2]+3,
                                str_locate(Opmerkingen, &amp;quot;,&amp;quot;)[,1]-1)) %&amp;gt;% 
  select(-Opmerkingen, -first_word, )

end_dates_two$fn_ln&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Sophie Wilm√®s&amp;quot;      &amp;quot;St√©phane Crusni√®re&amp;quot; &amp;quot;Sarah Claerhout&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_replace_two &amp;lt;- reps54 %&amp;gt;%
  filter(fn_ln %in% end_dates_two$fn_ln) %&amp;gt;%
  left_join(end_dates_two,  by = c(&amp;quot;fn_ln&amp;quot;)) %&amp;gt;% 
  mutate(end_date = date_1.y) %&amp;gt;% 
  select(-date_1.y) %&amp;gt;% 
  rename(&amp;quot;date_1&amp;quot; = &amp;quot;date_1.x&amp;quot;)

reps54 &amp;lt;-  reps54 %&amp;gt;%
  filter(!fn_ln %in% end_dates_two$fn_ln) %&amp;gt;%
  rbind(to_replace_two)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then the last three replacements for the end dates of Mr De Crem, Reynders and Flahaut.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;end_dates_three &amp;lt;- two_dates %&amp;gt;% 
  select(date_2, Opmerkingen, first_word) %&amp;gt;% 
  filter(first_word == &amp;quot;Vervangt&amp;quot;) %&amp;gt;%
  mutate(Opmerkingen = substr(Opmerkingen,str_locate(Opmerkingen, &amp;quot;,&amp;quot;)[,1]+3, 100000))%&amp;gt;% 
  mutate(fn_ln = substr(Opmerkingen,
                                str_locate(Opmerkingen, &amp;quot;201&amp;quot;)[,2]+3,
                                str_locate(Opmerkingen, &amp;quot;,&amp;quot;)[,1]-1)) %&amp;gt;% 
  select(-Opmerkingen, -first_word, )

end_dates_three$fn_ln&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Didier Reynders&amp;quot; &amp;quot;Andr√© Flahaut&amp;quot;   &amp;quot;Pieter De Crem&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_replace_three &amp;lt;- reps54 %&amp;gt;%
  filter(fn_ln %in% end_dates_three$fn_ln) %&amp;gt;%
  left_join(end_dates_three,  by = c(&amp;quot;fn_ln&amp;quot;)) %&amp;gt;% 
  mutate(end_date = date_2.y) %&amp;gt;% 
  select(-date_2.y) %&amp;gt;% 
  rename(&amp;quot;date_2&amp;quot; = &amp;quot;date_2.x&amp;quot;)

reps54 &amp;lt;-  reps54 %&amp;gt;%
  filter(!fn_ln %in% end_dates_three$fn_ln) %&amp;gt;%
  rbind(to_replace_three)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Starting to see the end of the tunnel. Still need to arrange the case of Mrs Turtelboom and Mr Frank Wilrycx.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54 %&amp;gt;% 
  filter(fn_ln == &amp;quot;Frank Wilrycx&amp;quot;) %&amp;gt;% 
  select(Opmerkingen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                                                                                                                               Opmerkingen
## 1 Vervangt sinds 3 5 2018 Annemie Turtelboom, die lid wordt van de Europese Rekenkamer. Eerder verving hij van 30 7 2014 tot 29 4 2016 Turtelboom toen die minister was in de Vlaamse Regering-Bourgeois.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dates &amp;lt;- reps54 %&amp;gt;% 
  filter(fn_ln == &amp;quot;Frank Wilrycx&amp;quot;) %&amp;gt;% 
  select(date_1, date_2, date_3)
dates&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       date_1     date_2     date_3
## 1 2018-05-03 2014-07-30 2016-04-29&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;three_dates &amp;lt;- reps54 %&amp;gt;% 
  filter(fn_ln == &amp;quot;Frank Wilrycx&amp;quot;) %&amp;gt;% 
  mutate(start_date = dates$date_2) %&amp;gt;% 
  mutate(end_date = dates$date_3) %&amp;gt;% 
  rbind(reps54 %&amp;gt;% filter(fn_ln == &amp;quot;Frank Wilrycx&amp;quot;) %&amp;gt;% 
        mutate(start_date = dates$date_1)) %&amp;gt;% 
  rbind(reps54 %&amp;gt;% filter(fn_ln == &amp;quot;Annemie Turtelboom&amp;quot;) %&amp;gt;% 
          mutate(end_date = ymd(dates$date_2) - days(1))) %&amp;gt;% 
  rbind(reps54 %&amp;gt;% filter(fn_ln == &amp;quot;Annemie Turtelboom&amp;quot;) %&amp;gt;% 
          mutate(start_date = ymd(dates$date_3) + days(1)) %&amp;gt;% 
          mutate(end_date = ymd(dates$date_1) - days(1)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let‚Äôs bring them all together before tackling missing values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(one_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 26 19&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(two_dates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 18 19&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(three_dates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  4 19&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(reps54)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 182  19&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(unique(reps54$fn_ln))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clean names
one_date$fn_ln &amp;lt;-  trimws(one_date$fn_ln, c(&amp;quot;both&amp;quot;))
two_dates$fn_ln &amp;lt;-  trimws(two_dates$fn_ln, c(&amp;quot;both&amp;quot;))
three_dates$fn_ln &amp;lt;-  trimws(three_dates$fn_ln, c(&amp;quot;both&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54 &amp;lt;- reps54 %&amp;gt;% 
  filter(!fn_ln %in% one_date$fn_ln) %&amp;gt;% 
  filter(!fn_ln %in% two_dates$fn_ln) %&amp;gt;% 
  filter(!fn_ln %in% three_dates$fn_ln) %&amp;gt;% 
  rbind(one_date) %&amp;gt;% 
  rbind(two_dates) %&amp;gt;% 
  rbind(three_dates) %&amp;gt;% 
  mutate(fn_ln = trimws(fn_ln, c(&amp;quot;both&amp;quot;)))

length(unique(reps54$fn_ln))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(reps54$fn_ln)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 192&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some manual corrections&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- reps54

x[x$fn_ln == &amp;quot;Renate Hufkens&amp;quot;,]$start_date &amp;lt;- as.Date(&amp;quot;2014-10-14&amp;quot;)
x[x$fn_ln == &amp;quot;Johan Klaps&amp;quot;,]$start_date &amp;lt;- as.Date(&amp;quot;2014-10-14&amp;quot;)
x[x$fn_ln == &amp;quot;Wouter Raskin&amp;quot;,]$start_date &amp;lt;- as.Date(&amp;quot;2014-10-14&amp;quot;)
x[x$fn_ln == &amp;quot;Wim Van der Donckt&amp;quot;,]$start_date &amp;lt;- as.Date(&amp;quot;2017-09-03&amp;quot;)

x[x$fn_ln == &amp;quot;Renate Hufkens&amp;quot;,]$end_date &amp;lt;- as.Date(&amp;quot;2018-12-09&amp;quot;)
x[x$fn_ln == &amp;quot;Johan Klaps&amp;quot;,]$end_date &amp;lt;- as.Date(&amp;quot;2018-12-09&amp;quot;)
x[x$fn_ln == &amp;quot;Wouter Raskin&amp;quot;,]$end_date &amp;lt;- as.Date(&amp;quot;2018-11-12&amp;quot;)
x[x$fn_ln == &amp;quot;Wim Van der Donckt&amp;quot;,]$end_date &amp;lt;- as.Date(&amp;quot;2018-12-09&amp;quot;)

reps54 &amp;lt;- x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save before cleaning.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#saveRDS(reps54, &amp;quot;./data/20190503/reps54_before_cleaning.rds&amp;quot;)
#reps54 &amp;lt;- readRDS(&amp;quot;./data/20190503/reps54_before_cleaning.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hmm unfortunately the site dekamer.be is unstable or under transformation. It stopped listing the current members with their
party and lannguage. Probably because of the end of the legistlature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reps54 &amp;lt;- reps54 %&amp;gt;%
  mutate(language = Taalgroep,
         party =Fractie)

empty_spaces &amp;lt;- reps54 %&amp;gt;%
  filter(is.na(language)) %&amp;gt;% 
  arrange(fn_ln)

empty_spaces$ln_fn&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;De Croo Alexander&amp;quot;       &amp;quot;Flahaut Andr√©&amp;quot;          
##  [3] &amp;quot;Vanheste Ann&amp;quot;            &amp;quot;Turtelboom Annemie&amp;quot;     
##  [5] &amp;quot;Turtelboom Annemie&amp;quot;      &amp;quot;Hellings Benoit&amp;quot;        
##  [7] &amp;quot;Fremault C√©line&amp;quot;         &amp;quot;Michel Charles&amp;quot;         
##  [9] &amp;quot;Bacquelaine Daniel&amp;quot;      &amp;quot;Ducarme Denis&amp;quot;          
## [11] &amp;quot;Reynders Didier&amp;quot;         &amp;quot;Massin Eric&amp;quot;            
## [13] &amp;quot;Poncelet Isabelle&amp;quot;       &amp;quot;Klaps Johan&amp;quot;            
## [15] &amp;quot;Vande Lanotte Johan&amp;quot;     &amp;quot;Geens Koen&amp;quot;             
## [17] &amp;quot;De Block Maggie&amp;quot;         &amp;quot;Marghem Marie-Christine&amp;quot;
## [19] &amp;quot;Wathelet Melchior&amp;quot;       &amp;quot;Gerkens Muriel&amp;quot;         
## [21] &amp;quot;De Crem Pieter&amp;quot;          &amp;quot;Hufkens Renate&amp;quot;         
## [23] &amp;quot;Lahaye-Battheu Sabien&amp;quot;   &amp;quot;Claerhout Sarah&amp;quot;        
## [25] &amp;quot;Wilm√®s Sophie&amp;quot;           &amp;quot;Crusni√®re St√©phane&amp;quot;     
## [27] &amp;quot;Demeyer Willy&amp;quot;           &amp;quot;Van der Donckt Wim&amp;quot;     
## [29] &amp;quot;Raskin Wouter&amp;quot;           &amp;quot;Khattabi Zakia&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For now I leave some fields incomplete and see if we can have fun finding them with algorithms or with some other tools. But since we have a number of their tweets in ram, we kan have a shot at guessing their language ‚Äòrole‚Äô.&lt;/p&gt;
&lt;p&gt;On the other hand if you are familiar with Belgium, you could just make good guesses looking at their first names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;word(empty_spaces$ln_fn,-1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Alexander&amp;quot;       &amp;quot;Andr√©&amp;quot;           &amp;quot;Ann&amp;quot;            
##  [4] &amp;quot;Annemie&amp;quot;         &amp;quot;Annemie&amp;quot;         &amp;quot;Benoit&amp;quot;         
##  [7] &amp;quot;C√©line&amp;quot;          &amp;quot;Charles&amp;quot;         &amp;quot;Daniel&amp;quot;         
## [10] &amp;quot;Denis&amp;quot;           &amp;quot;Didier&amp;quot;          &amp;quot;Eric&amp;quot;           
## [13] &amp;quot;Isabelle&amp;quot;        &amp;quot;Johan&amp;quot;           &amp;quot;Johan&amp;quot;          
## [16] &amp;quot;Koen&amp;quot;            &amp;quot;Maggie&amp;quot;          &amp;quot;Marie-Christine&amp;quot;
## [19] &amp;quot;Melchior&amp;quot;        &amp;quot;Muriel&amp;quot;          &amp;quot;Pieter&amp;quot;         
## [22] &amp;quot;Renate&amp;quot;          &amp;quot;Sabien&amp;quot;          &amp;quot;Sarah&amp;quot;          
## [25] &amp;quot;Sophie&amp;quot;          &amp;quot;St√©phane&amp;quot;        &amp;quot;Willy&amp;quot;          
## [28] &amp;quot;Wim&amp;quot;             &amp;quot;Wouter&amp;quot;          &amp;quot;Zakia&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But looking at the tweets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets &amp;lt;- readRDS(&amp;quot;~/R/blogs/content/post/data/20190503/tweets.rds&amp;quot;)
lang &amp;lt;- tweets %&amp;gt;% 
  filter(ln_fn %in% empty_spaces$ln_fn) %&amp;gt;% 
  select(ln_fn, lang) %&amp;gt;% 
  group_by(ln_fn, lang) %&amp;gt;% 
  summarise(count = n())

# this code is sinfull, apologies to the tidyverse saints;
languages_used &amp;lt;- lang %&amp;gt;%
  group_by(ln_fn)%&amp;gt;%
  summarise(m = max(count))%&amp;gt;% 
  left_join(lang) %&amp;gt;% 
  filter(m == count) %&amp;gt;% 
  select(-m, -count) %&amp;gt;% 
  mutate(language = ifelse(lang == &amp;quot;nl&amp;quot;, &amp;quot;Nederlands&amp;quot;, &amp;quot;Frans&amp;quot;)) %&amp;gt;% 
  select(-lang)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;ln_fn&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get the language the members use the most.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;languages_used&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 27 x 2
##    ln_fn              language  
##    &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;     
##  1 Bacquelaine Daniel Frans     
##  2 Claerhout Sarah    Nederlands
##  3 Crusni√®re St√©phane Frans     
##  4 De Block Maggie    Nederlands
##  5 De Crem Pieter     Nederlands
##  6 De Croo Alexander  Nederlands
##  7 Demeyer Willy      Frans     
##  8 Ducarme Denis      Frans     
##  9 Flahaut Andr√©      Frans     
## 10 Fremault C√©line    Frans     
## # ... with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(empty_spaces$ln_fn, languages_used$ln_fn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Vande Lanotte Johan&amp;quot; &amp;quot;Gerkens Muriel&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let‚Äôs add them and end this for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_add &amp;lt;- data.frame(&amp;quot;ln_fn&amp;quot; = c(&amp;quot;Vande Lanotte Johan&amp;quot;,&amp;quot;Gerkens Muriel&amp;quot;), 
                     &amp;quot;language&amp;quot; = c(&amp;quot;Nederlands&amp;quot;, &amp;quot;Frans&amp;quot;)) 

languages_used &amp;lt;-languages_used %&amp;gt;% 
  rbind(to_add)

added_languages &amp;lt;- empty_spaces %&amp;gt;% 
  left_join(languages_used, by = c(&amp;quot;ln_fn&amp;quot;)) %&amp;gt;% 
  mutate(language = language.y) %&amp;gt;% 
  select(-language.x, -language.y)

reps54 &amp;lt;- reps54 %&amp;gt;% 
  filter(!is.na(language)) %&amp;gt;% 
  rbind(added_languages) %&amp;gt;% 
  arrange(fn_ln)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save after first cleaning.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#saveRDS(reps54, &amp;quot;./data/20190503/reps54_after_cleaning.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I‚Äôll pick up the tweets analysis soon, but first want to show you some cool stuff using Rekognition from AWS.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>Belgian parliamentarians Twitter accounts</title>
      <link>/post/belgian-parliamentarians-twitter-accounts/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/belgian-parliamentarians-twitter-accounts/</guid>
      <description></description>
      
      <content>


&lt;p&gt;Now that we can scrape the names of the parliamentarians of the 54th legislature, we can try to find their Twitter accounts too.&lt;/p&gt;
&lt;p&gt;Let‚Äôs start by reconstructing the list. Then we can search Twitter for their accounts handles. A bit of grunt work and no visuals in this post, but it is needed to harvest parlaimentarians‚Äô tweets soonish.&lt;/p&gt;
&lt;p&gt;Starting with attaching libraries, and in particular &lt;a href=&#34;https://rtweet.info/&#34;&gt;‚Äòrtweet‚Äô&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#libraries
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;rvest&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;rtweet&amp;quot;)
library(&amp;quot;purrr&amp;quot;)

# the ones seating currently, with their (current) party

url &amp;lt;- paste0(&amp;quot;http://www.dekamer.be/kvvcr/showpage.cfm?section=&amp;quot;,
              &amp;quot;/depute&amp;amp;language=nl&amp;amp;cfm=/site/wwwcfm/depute/cvlist54.cfm&amp;quot;)

table &amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_nodes(&amp;quot;#story &amp;gt; table&amp;quot;) %&amp;gt;% 
  html_table()

table &amp;lt;- table[[1]]

names(table) &amp;lt;- c(&amp;quot;ln_fn&amp;quot;, &amp;quot;party&amp;quot;, &amp;quot;d1&amp;quot;, &amp;quot;d2&amp;quot;) # ln_fn is last name, first name
table &amp;lt;- table %&amp;gt;% 
  select(ln_fn, party)

table &amp;lt;- table %&amp;gt;%
  mutate(ln_fn = str_replace_all(ln_fn,&amp;quot;  +&amp;quot;,&amp;quot; &amp;quot;))

# the ones that have left (without party)

url &amp;lt;- paste0(&amp;quot;https://www.dekamer.be/kvvcr/showpage.cfm?section&amp;quot;,
              &amp;quot;=/depute&amp;amp;language=nl&amp;amp;cfm=cvlist54.cfm?legis=54&amp;amp;today=n&amp;quot;)

table_54 &amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_nodes(&amp;quot;#story &amp;gt; table&amp;quot;) %&amp;gt;% 
  html_table()

table_54 &amp;lt;- table_54[[1]] # extracting the dataframe

names(table_54) &amp;lt;- c(&amp;quot;ln_fn&amp;quot;, &amp;quot;d1&amp;quot;, &amp;quot;d2&amp;quot;, &amp;quot;d3&amp;quot;)  
table_54 &amp;lt;- table_54 %&amp;gt;% 
  select(ln_fn) %&amp;gt;% 
  arrange(ln_fn)

table_54 &amp;lt;- table_54 %&amp;gt;%
  mutate(ln_fn = str_replace_all(ln_fn,&amp;quot;  +&amp;quot;,&amp;quot; &amp;quot;))

old_members &amp;lt;- table_54 %&amp;gt;% 
  anti_join(table) %&amp;gt;% 
  mutate(party = &amp;quot;tbd&amp;quot;)

table &amp;lt;- rbind(table, old_members)

saveRDS(table, &amp;quot;./data/20190502/table.rds&amp;quot;)

rm(old_members)
rm(table_54)
rm(url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many do we have?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, did not lose any along the way. Now we have a data frame with the last name and first name of the 179 persons who seated in the 54th legislature (by now there will be few or no changes, since we are so close to this month‚Äôs elections).&lt;/p&gt;
&lt;p&gt;Next the twitter API credentials are needed to use the rtweet package. Documentation can be found &lt;a href=&#34;https://rtweet.info/#api-authorization&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once authenticated, based on our parliamentarian‚Äôs name and using the ‚Äòsearch_users‚Äô function we can find their twitter accounts. I had some success using a for loop in the past, but will try to use the purrr package this time around.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# so tweak the function, because it tries to find by default 100 users
# and because we want to keep track of who we searched for in the results
# take only first result for now

search &amp;lt;- function(x){print (x)
  search_users(x, n=1) %&amp;gt;% # only return one line per name
    mutate(ln_fn = x)} # keep track of who we searched for&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the function ‚Äòpossibly‚Äô a data frame can be created without stopping or including errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- map_df(table$ln_fn,possibly(.f= search, otherwise = NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The nice thing about it is that a lot of information can be collected using the Twitter API. Have look yourself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(twitter_users)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;user_id&amp;quot;                 &amp;quot;status_id&amp;quot;              
##  [3] &amp;quot;created_at&amp;quot;              &amp;quot;screen_name&amp;quot;            
##  [5] &amp;quot;text&amp;quot;                    &amp;quot;source&amp;quot;                 
##  [7] &amp;quot;display_text_width&amp;quot;      &amp;quot;reply_to_status_id&amp;quot;     
##  [9] &amp;quot;reply_to_user_id&amp;quot;        &amp;quot;reply_to_screen_name&amp;quot;   
## [11] &amp;quot;is_quote&amp;quot;                &amp;quot;is_retweet&amp;quot;             
## [13] &amp;quot;favorite_count&amp;quot;          &amp;quot;retweet_count&amp;quot;          
## [15] &amp;quot;hashtags&amp;quot;                &amp;quot;symbols&amp;quot;                
## [17] &amp;quot;urls_url&amp;quot;                &amp;quot;urls_t.co&amp;quot;              
## [19] &amp;quot;urls_expanded_url&amp;quot;       &amp;quot;media_url&amp;quot;              
## [21] &amp;quot;media_t.co&amp;quot;              &amp;quot;media_expanded_url&amp;quot;     
## [23] &amp;quot;media_type&amp;quot;              &amp;quot;ext_media_url&amp;quot;          
## [25] &amp;quot;ext_media_t.co&amp;quot;          &amp;quot;ext_media_expanded_url&amp;quot; 
## [27] &amp;quot;ext_media_type&amp;quot;          &amp;quot;mentions_user_id&amp;quot;       
## [29] &amp;quot;mentions_screen_name&amp;quot;    &amp;quot;lang&amp;quot;                   
## [31] &amp;quot;quoted_status_id&amp;quot;        &amp;quot;quoted_text&amp;quot;            
## [33] &amp;quot;quoted_created_at&amp;quot;       &amp;quot;quoted_source&amp;quot;          
## [35] &amp;quot;quoted_favorite_count&amp;quot;   &amp;quot;quoted_retweet_count&amp;quot;   
## [37] &amp;quot;quoted_user_id&amp;quot;          &amp;quot;quoted_screen_name&amp;quot;     
## [39] &amp;quot;quoted_name&amp;quot;             &amp;quot;quoted_followers_count&amp;quot; 
## [41] &amp;quot;quoted_friends_count&amp;quot;    &amp;quot;quoted_statuses_count&amp;quot;  
## [43] &amp;quot;quoted_location&amp;quot;         &amp;quot;quoted_description&amp;quot;     
## [45] &amp;quot;quoted_verified&amp;quot;         &amp;quot;retweet_status_id&amp;quot;      
## [47] &amp;quot;retweet_text&amp;quot;            &amp;quot;retweet_created_at&amp;quot;     
## [49] &amp;quot;retweet_source&amp;quot;          &amp;quot;retweet_favorite_count&amp;quot; 
## [51] &amp;quot;retweet_retweet_count&amp;quot;   &amp;quot;retweet_user_id&amp;quot;        
## [53] &amp;quot;retweet_screen_name&amp;quot;     &amp;quot;retweet_name&amp;quot;           
## [55] &amp;quot;retweet_followers_count&amp;quot; &amp;quot;retweet_friends_count&amp;quot;  
## [57] &amp;quot;retweet_statuses_count&amp;quot;  &amp;quot;retweet_location&amp;quot;       
## [59] &amp;quot;retweet_description&amp;quot;     &amp;quot;retweet_verified&amp;quot;       
## [61] &amp;quot;place_url&amp;quot;               &amp;quot;place_name&amp;quot;             
## [63] &amp;quot;place_full_name&amp;quot;         &amp;quot;place_type&amp;quot;             
## [65] &amp;quot;country&amp;quot;                 &amp;quot;country_code&amp;quot;           
## [67] &amp;quot;geo_coords&amp;quot;              &amp;quot;coords_coords&amp;quot;          
## [69] &amp;quot;bbox_coords&amp;quot;             &amp;quot;status_url&amp;quot;             
## [71] &amp;quot;name&amp;quot;                    &amp;quot;location&amp;quot;               
## [73] &amp;quot;description&amp;quot;             &amp;quot;url&amp;quot;                    
## [75] &amp;quot;protected&amp;quot;               &amp;quot;followers_count&amp;quot;        
## [77] &amp;quot;friends_count&amp;quot;           &amp;quot;listed_count&amp;quot;           
## [79] &amp;quot;statuses_count&amp;quot;          &amp;quot;favourites_count&amp;quot;       
## [81] &amp;quot;account_created_at&amp;quot;      &amp;quot;verified&amp;quot;               
## [83] &amp;quot;profile_url&amp;quot;             &amp;quot;profile_expanded_url&amp;quot;   
## [85] &amp;quot;account_lang&amp;quot;            &amp;quot;profile_banner_url&amp;quot;     
## [87] &amp;quot;profile_background_url&amp;quot;  &amp;quot;profile_image_url&amp;quot;      
## [89] &amp;quot;ln_fn&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of the fields, like ‚Äúhashstags‚Äù contain lists.&lt;/p&gt;
&lt;p&gt;Arranging columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- twitter_users %&amp;gt;% 
  select(ln_fn, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These names return an error using the ‚Äútwitter_user‚Äù function. But these politicians do not tweet. We can skip them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_no_twitter &amp;lt;- c(&amp;quot;Deti√®ge Maya&amp;quot;, &amp;quot;Mathot Alain&amp;quot;, &amp;quot;Pivin Philippe&amp;quot;,
                     &amp;quot;Wilrycx Frank&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have a data frame with 152 users for our 175 politicians.&lt;/p&gt;
&lt;p&gt;We need to find the right user ids or twitter handles, by looking at key fields in the data frame returned by the ‚Äòsearch_user‚Äô function. (summarised in a smaller data frame)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspect &amp;lt;- twitter_users %&amp;gt;%
  select(ln_fn, name, screen_name, description, text)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily most often the first result is the correct one. Although there are also sometimes surprises. At least these do not seem like descriptions of Belgian parliamentarians.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;descriptions &amp;lt;- inspect %&amp;gt;% 
  filter(ln_fn == &amp;quot;Bracke Siegfried&amp;quot; 
         | ln_fn == &amp;quot;Fernandez Fernandez Julie&amp;quot;
         | ln_fn == &amp;quot;Top Alain&amp;quot;
         | ln_fn == &amp;quot;Bonte Hans&amp;quot;) %&amp;gt;% 
  select(description)

descriptions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 1
##   description                                                              
##   &amp;lt;chr&amp;gt;                                                                    
## 1 Levensgenieter                                                           
## 2 Als er niet kan worden gelachen, is het niet ernstig. Links of rechts is~
## 3 Trusted HR advisor for all things BPO, technology, global payroll and sh~
## 4 Legacy Miami Top 40 Under 40 | HACCOF Top 20 Under 40 | Caribbean-born C~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These seem obviously wrong.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find_again &amp;lt;- tibble(&amp;quot;ln_fn&amp;quot; = c(&amp;quot;Bonte Hans&amp;quot;,&amp;quot;Ceysens Patricia&amp;quot;,&amp;quot;Chabot Jacques&amp;quot;,
                                 &amp;quot;Fernandez Fernandez Julie&amp;quot;,&amp;quot;Geerts David&amp;quot;,
                                 &amp;quot;Henry Olivier&amp;quot;,&amp;quot;Janssen Werner&amp;quot;, &amp;quot;Janssens Dirk&amp;quot;,
                                 &amp;quot;Matz Vanessa&amp;quot;, &amp;quot;Metsu Koen&amp;quot;, &amp;quot;Miller Richard&amp;quot;,
                                 &amp;quot;Pehlivan Fatma&amp;quot;,&amp;quot;Smeyers Sarah&amp;quot;,&amp;quot;Top Alain&amp;quot;,
                                 &amp;quot;Van de Velde Robert&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Would they be first 10 of the search result?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search &amp;lt;- function(x){print (x)
  search_users(x, n=10) %&amp;gt;% 
    mutate(ln_fn = x)} # keep track of who we searched for

twitter_users_2 &amp;lt;- map_df(find_again$ln_fn,
                          possibly(.f= search, otherwise = NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Bonte Hans&amp;quot;
## [1] &amp;quot;Ceysens Patricia&amp;quot;
## [1] &amp;quot;Chabot Jacques&amp;quot;
## [1] &amp;quot;Fernandez Fernandez Julie&amp;quot;
## [1] &amp;quot;Geerts David&amp;quot;
## [1] &amp;quot;Henry Olivier&amp;quot;
## [1] &amp;quot;Janssen Werner&amp;quot;
## [1] &amp;quot;Janssens Dirk&amp;quot;
## [1] &amp;quot;Matz Vanessa&amp;quot;
## [1] &amp;quot;Metsu Koen&amp;quot;
## [1] &amp;quot;Miller Richard&amp;quot;
## [1] &amp;quot;Pehlivan Fatma&amp;quot;
## [1] &amp;quot;Smeyers Sarah&amp;quot;
## [1] &amp;quot;Top Alain&amp;quot;
## [1] &amp;quot;Van de Velde Robert&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspect &amp;lt;- twitter_users_2 %&amp;gt;%
  select(ln_fn, name, screen_name, description, text)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new batch can easily be identified and added to the first batch.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- twitter_users %&amp;gt;% 
  filter(!ln_fn %in% find_again$ln_fn) %&amp;gt;% 
  rbind(twitter_users_2 %&amp;gt;% 
  slice(13, 21, 30, 45, 51, 71, 76 , 99, 113))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are still missing these:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setdiff(setdiff(table$ln_fn, twitter_users$ln_fn), list_no_twitter)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Bonte Hans&amp;quot;                &amp;quot;Brotcorne Christian&amp;quot;      
##  [3] &amp;quot;Cassart-Mailleux Caroline&amp;quot; &amp;quot;Ceysens Patricia&amp;quot;         
##  [5] &amp;quot;Cheron Marcel&amp;quot;             &amp;quot;de Coster-Bauchau Sybille&amp;quot;
##  [7] &amp;quot;Delannois Paul-Olivier&amp;quot;    &amp;quot;Delp√©r√©e Francis&amp;quot;         
##  [9] &amp;quot;Devin Laurent&amp;quot;             &amp;quot;D&amp;#39;Haese Christoph&amp;quot;        
## [11] &amp;quot;Dierick Leen&amp;quot;              &amp;quot;Fr√©d√©ric Andr√©&amp;quot;           
## [13] &amp;quot;Galant Isabelle&amp;quot;           &amp;quot;Gerkens Muriel&amp;quot;           
## [15] &amp;quot;Goffinet Anne-Catherine&amp;quot;   &amp;quot;Gustin Luc&amp;quot;               
## [17] &amp;quot;Janssens Dirk&amp;quot;             &amp;quot;Marghem Marie-Christine&amp;quot;  
## [19] &amp;quot;Miller Richard&amp;quot;            &amp;quot;Muylle Nathalie&amp;quot;          
## [21] &amp;quot;Pehlivan Fatma&amp;quot;            &amp;quot;Pirlot S√©bastian&amp;quot;         
## [23] &amp;quot;Vande Lanotte Johan&amp;quot;       &amp;quot;Van den Bergh Jef&amp;quot;        
## [25] &amp;quot;Van de Velde Robert&amp;quot;       &amp;quot;Van Quickenborne Vincent&amp;quot; 
## [27] &amp;quot;Van Rompuy Eric&amp;quot;           &amp;quot;Vanvelthoven Peter&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of these surely have a twitter account. More searching is needed to find:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;@CarolineCassart&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@patriciaceysens&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@podelannois&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@leendierick&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@dirkjanssens19&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@millerrichardmr&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@nathaliemuylle&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@jefvandenbergh&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@VincentVQ&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@VvelthovenPeter&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@pehlivan_fatma&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@FrankWilrycx&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@McMarghem&lt;/span&gt;
&lt;span class=&#34;citation&#34;&gt;@robvandevelde&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;more &amp;lt;- tibble(handle = wrapr::qc(CarolineCassart, patriciaceysens, podelannois,
                                  leendierick,dirkjanssens19, millerrichardmr,
                                  nathaliemuylle, jefvandenbergh, VincentVQ,
                                  VvelthovenPeter, pehlivan_fatma, FrankWilrycx,
                                  McMarghem),
               ln_fn = c(&amp;quot;Cassart-Mailleux Caroline&amp;quot;, &amp;quot;Ceysens Patricia&amp;quot;,
                         &amp;quot;Delannois Paul-Olivier&amp;quot;, &amp;quot;Dierick Leen&amp;quot;, 
                         &amp;quot;Janssens Dirk&amp;quot;, &amp;quot;Miller Richard&amp;quot;, &amp;quot;Muylle Nathalie&amp;quot;, 
                         &amp;quot;Van den Bergh Jef&amp;quot;, &amp;quot;Van Quickenborne Vincent&amp;quot;, 
                         &amp;quot;Vanvelthoven Peter&amp;quot;, &amp;quot;Pehlivan Fatma&amp;quot; , 
                         &amp;quot;Wilrycx Frank&amp;quot;, &amp;quot;Marghem Marie-Christine&amp;quot;))

more_1 &amp;lt;- more %&amp;gt;% 
  filter(handle !=&amp;quot;pehlivan_fatma&amp;quot;,
         handle !=&amp;quot;FrankWilrycx&amp;quot;)

more_2 &amp;lt;- more %&amp;gt;% 
  filter(handle ==&amp;quot;pehlivan_fatma&amp;quot; |
         handle ==&amp;quot;FrankWilrycx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search &amp;lt;- function(x){print (x)
  search_users(x, n=1)} # keep track of who we searched for

twitter_users_3 &amp;lt;- map_df(more_1$handle,possibly(.f= search, otherwise = NULL)) %&amp;gt;% 
  cbind(more_1$ln_fn) %&amp;gt;%
  rename(&amp;quot;ln_fn&amp;quot; = &amp;quot;more_1$ln_fn&amp;quot;) %&amp;gt;% 
  select(ln_fn, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;CarolineCassart&amp;quot;
## [1] &amp;quot;patriciaceysens&amp;quot;
## [1] &amp;quot;podelannois&amp;quot;
## [1] &amp;quot;leendierick&amp;quot;
## [1] &amp;quot;dirkjanssens19&amp;quot;
## [1] &amp;quot;millerrichardmr&amp;quot;
## [1] &amp;quot;nathaliemuylle&amp;quot;
## [1] &amp;quot;jefvandenbergh&amp;quot;
## [1] &amp;quot;VincentVQ&amp;quot;
## [1] &amp;quot;VvelthovenPeter&amp;quot;
## [1] &amp;quot;McMarghem&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- rbind(twitter_users, twitter_users_3)

nrow(twitter_users)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 158&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Still problems with the last two. ‚ÄúFrankWilrycx‚Äù probably because he has not tweeted yet. And ‚Äúpehlivan_fatma‚Äù was a bit harder to find&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;more_2 &amp;lt;- more %&amp;gt;% 
  filter(handle ==&amp;quot;pehlivan_fatma&amp;quot;)

search &amp;lt;- function(x){print (x)
  search_users(x, n=11)} # keep track of who we searched for

twitter_users_4 &amp;lt;- map_df(more_2$handle,
                          possibly(.f= search, 
                                   otherwise = NULL)) %&amp;gt;% 
  cbind(more_2$ln_fn) %&amp;gt;%
  rename(&amp;quot;ln_fn&amp;quot; = &amp;quot;more_2$ln_fn&amp;quot;) %&amp;gt;% 
  select(ln_fn, everything()) %&amp;gt;% 
  slice(11)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;pehlivan_fatma&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twitter_users &amp;lt;- rbind(twitter_users, twitter_users_4)

nrow(twitter_users)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 159&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 159 Twitter handles, out of 179 parliamentarians.&lt;/p&gt;
&lt;p&gt;(if you want to have fun with the profile pics they are in &lt;a href=&#34;https://twitter.com/%7Bhandle%7D/photo&#34; class=&#34;uri&#34;&gt;https://twitter.com/{handle}/photo&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;We are now ready to extract a considerable amount of their tweets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(twitter_users, &amp;quot;./data/20190502/twitter_users.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
</content>
      
    </item>
    
    <item>
      <title>members of the chamber of representatives of Belgium, 54th legistlature</title>
      <link>/post/members-of-the-chamber-of-representatives-of-belgium-54th-legistlature/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/members-of-the-chamber-of-representatives-of-belgium-54th-legistlature/</guid>
      <description></description>
      
      <content>


&lt;p&gt;For a country as small as Belgium 6 governments is a lot. It‚Äôs maybe because we Belgians like to be governed and governed well. Why else would we want to pay for 6 governments, their administration and their parliaments?&lt;/p&gt;
&lt;p&gt;We also love politicians, so we want to have many. I also like politicians and decided to do some NLP on their tweets. But since there are a significant number of politicians in Belgium I searched for an objective criteria to define a subset. What better selection then the members of the national chamber of representatives? They were elected to represent us all at the national level and their tweets should somehow in some way be representative also.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.dekamer.be&#34; class=&#34;uri&#34;&gt;https://www.dekamer.be&lt;/a&gt; is the official website of the chamber. Two lists are interesting here. One has the current members, the other one the complete list of members that at one moment or another were part of the parliament during the 54th legislature following the 2014 elections.&lt;/p&gt;
&lt;p&gt;Let‚Äôs scrape them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;rvest&amp;quot;)
library(&amp;quot;XML&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;magick&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- paste0(&amp;quot;http://www.dekamer.be/kvvcr/showpage.cfm?section=/&amp;quot;,
&amp;quot;depute&amp;amp;language=nl&amp;amp;cfm=/site/wwwcfm/depute/cvlist54.cfm&amp;quot;)

table &amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_nodes(&amp;quot;#story &amp;gt; table&amp;quot;) %&amp;gt;% 
  html_table()

table &amp;lt;- table[[1]] # extracting the dataframe

names(table) &amp;lt;- c(&amp;quot;ln_fn&amp;quot;, &amp;quot;party&amp;quot;, &amp;quot;d1&amp;quot;, &amp;quot;d2&amp;quot;)
table &amp;lt;- table %&amp;gt;% 
  select(ln_fn, party) %&amp;gt;% 
  arrange(ln_fn)

head(table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                  ln_fn party
## 1                        Almaci Meyrem    NA
## 2                   Bacquelaine Daniel    NA
## 3                           Becq Sonja    NA
## 4 Beke                          Wouter    NA
## 5                         Bellens Rita    NA
## 6                      Ben Hamou Nawal    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The white spaces between the last name and first some of some, like Wouter Beke need to be cleaned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table &amp;lt;- table %&amp;gt;%
  mutate(ln_fn = str_replace_all(ln_fn,&amp;quot;  +&amp;quot;,&amp;quot; &amp;quot;))

nrow(table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;150 members today with their current political party. And the parties and number of seats are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table %&amp;gt;% 
  group_by(party) %&amp;gt;% 
  summarise(members=n()) %&amp;gt;% 
  arrange(desc(members))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   party members
##   &amp;lt;lgl&amp;gt;   &amp;lt;int&amp;gt;
## 1 NA        179&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hmm the page we used has been replaced. :dissapointed: And that is logical because the parliamenty legistlature ended on 25/04/2019.&lt;/p&gt;
&lt;p&gt;We can also scrape the complete list of members of the 54th legislature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- paste0(&amp;quot;https://www.dekamer.be/kvvcr/showpage.cfm?section&amp;quot;,
              &amp;quot;=/depute&amp;amp;language=nl&amp;amp;cfm=cvlist54.cfm?legis=54&amp;amp;today=n&amp;quot;)

table_54 &amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_nodes(&amp;quot;#story &amp;gt; table&amp;quot;) %&amp;gt;% 
  html_table()

table_54 &amp;lt;- table_54[[1]] # extracting the dataframe

names(table_54) &amp;lt;- c(&amp;quot;ln_fn&amp;quot;, &amp;quot;d1&amp;quot;, &amp;quot;d2&amp;quot;, &amp;quot;d3&amp;quot;)  
table_54 &amp;lt;- table_54 %&amp;gt;% 
  select(ln_fn) %&amp;gt;% 
  arrange(ln_fn)

table_54 &amp;lt;- table_54 %&amp;gt;%
  mutate(ln_fn = str_replace_all(ln_fn,&amp;quot;  +&amp;quot;,&amp;quot; &amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This table does not mention the party, which is a pity because some members have changed since 2014.&lt;/p&gt;
&lt;p&gt;Who has left ?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_54 %&amp;gt;% 
  anti_join(table) %&amp;gt;% 
  unlist() %&amp;gt;% 
  unname()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So indeed 29 representatives. But some left to work in the government and then came back when their party decided to leave government because of a city in northern Africa. Go figure.&lt;/p&gt;
&lt;p&gt;But it does make the identification of a tweet as a tweet being sent by a member of parliament a little bit more complicated because we need to match the exact date of the tweet to the periods the politician was seating. I have a feeling this will imply some stupid hard coding. üò©&lt;/p&gt;
&lt;p&gt;Let‚Äôs have some fun first.&lt;/p&gt;
&lt;p&gt;Looking at the page of the current members of parliament, and more specifically at the url leading to the members page, their identifier can be discovered. For instance Mrs Almaci has id 01189 for the website. So once the &lt;a href=&#34;https://www.w3schools.com/xml/xml_xpath.asp&#34;&gt;xpath&lt;/a&gt; is known it is relatively easy to extract the individual member‚Äôs webpage url.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- paste0(&amp;quot;http://www.dekamer.be/kvvcr/showpage.cfm?section&amp;quot;,
              &amp;quot;=/depute&amp;amp;language=nl&amp;amp;cfm=cvlist54.cfm?legis=54&amp;amp;today=n&amp;quot;)
page &amp;lt;- url %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_nodes(xpath=  &amp;#39;//*[@id=&amp;quot;story&amp;quot;]/table&amp;#39;) 

# loop to get urls
urls &amp;lt;- tibble()

for(i in 1:nrow(table_54)){
  url &amp;lt;- xml_attrs(xml_child(xml_child(xml_child(page[[1]], i), 1), 1))
  url &amp;lt;- unname(url)
  name &amp;lt;- table_54$ln_fn[i]
  url &amp;lt;- cbind(name, url)
  urls &amp;lt;- rbind(urls, url)
}

# constructing the url
table_ids &amp;lt;- urls %&amp;gt;%
  mutate(url = paste0(&amp;quot;http://www.dekamer.be/kvvcr/&amp;quot;, url))   
  
table_ids %&amp;gt;%
  mutate(id = gsub(&amp;#39;^.*key=*|\\s*&amp;amp;lact.*$&amp;#39;,&amp;#39;&amp;#39;, url)) %&amp;gt;%
  mutate(row = rownames(.)) %&amp;gt;% 
  select(row, name, id) %&amp;gt;% 
  slice(29:39) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   row               name    id
## 1  29  D&amp;#39;Haese Christoph 06731
## 2  30   Daerden Fr√©d√©ric 00951
## 3  31 Dallemagne Georges 00895
## 4  32    De Block Maggie 01183
## 5  33    De Coninck Inez 06842
## 6  34  De Coninck Monica 06286&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But there is a problem with matching the names and the ids.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- table_ids
names &amp;lt;- tibble()

for (i in (1:nrow(x))){
  url &amp;lt;- x$url[i]
  fn_ln &amp;lt;- url %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(xpath=  &amp;#39;//*[@id=&amp;quot;myform&amp;quot;]/center/h2&amp;#39;) %&amp;gt;% 
    html_text() %&amp;gt;% 
    as.data.frame()
  info &amp;lt;- cbind(fn_ln, url)
  names &amp;lt;- rbind(names, info)
}

names(names) &amp;lt;- c(&amp;quot;fn_ln&amp;quot;,&amp;quot;url&amp;quot;)

names &amp;lt;- names %&amp;gt;% 
  mutate(fn_ln =(str_replace_all(fn_ln,&amp;quot;  +&amp;quot;,&amp;quot; &amp;quot;)))

names %&amp;gt;%
  mutate(id = gsub(&amp;#39;^.*key=*|\\s*&amp;amp;lact.*$&amp;#39;,&amp;#39;&amp;#39;, url)) %&amp;gt;%
  mutate(row = rownames(.)) %&amp;gt;% 
  select(row, fn_ln, id) %&amp;gt;% 
  slice(57:65) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   row             fn_ln    id
## 1  57 Christoph D&amp;#39;Haese 06907
## 2  58      Leen Dierick 01201
## 3  59      Elio Di Rupo 00439
## 4  60      Beno√Æt Dispa 06435
## 5  61     Denis Ducarme 01056
## 6  62     Daphn√© Dumery 06086&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The tables are sorted differently so there are wrong ids attributed to some parliamentarians (like Christophe D‚ÄôHaese).&lt;/p&gt;
&lt;p&gt;We need to correct that. Since the fn_ln are correct, we can build a key based on the letters in the name of the person.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_sort &amp;lt;- function(x)
  sapply(lapply(strsplit(x, NULL), sort), paste, collapse=&amp;quot;&amp;quot;)

w_key &amp;lt;- table_ids %&amp;gt;% 
  mutate(key = tolower(str_replace_all(name,&amp;quot; &amp;quot;,&amp;quot;&amp;quot;))) %&amp;gt;% 
  mutate(key = str_sort(key)) %&amp;gt;% 
  select(-url)

names_w_key &amp;lt;- names %&amp;gt;% 
  mutate(key = tolower(str_replace_all(fn_ln,&amp;quot; &amp;quot;,&amp;quot;&amp;quot;))) %&amp;gt;% 
  mutate(key = str_sort(key))

names &amp;lt;- names_w_key %&amp;gt;% 
  left_join(w_key) %&amp;gt;% 
  rename(&amp;quot;ln_fn&amp;quot; = &amp;quot;name&amp;quot;)

names %&amp;gt;% 
  select(-url) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                fn_ln               key              ln_fn
## 1      Meyrem Almaci      aaceeilmmmry      Almaci Meyrem
## 2 Daniel Bacquelaine aaabcdeeeiillnnqu Bacquelaine Daniel
## 3         Sonja Becq         abcejnoqs         Becq Sonja
## 4       Wouter Beke         beeekortuw        Beke Wouter
## 5       Rita Bellens       abeeillnrst       Bellens Rita
## 6    Nawal Ben Hamou     aaabehlmnnouw    Ben Hamou Nawal&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seems to work. Names are clean. Now the id code is needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# correct id
# extract their id from the url
names &amp;lt;- names %&amp;gt;%
  mutate(id = gsub(&amp;#39;^.*key=*|\\s*&amp;amp;lact.*$&amp;#39;,&amp;#39;&amp;#39;, url))   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let‚Äôs join the party where we can&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names &amp;lt;- names %&amp;gt;% 
  mutate(ln_fn = as.character(ln_fn)) %&amp;gt;% # transform from factor
  left_join(table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;ln_fn&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have in ‚Äòurls‚Äô the name and links to the personal webpage of the representatives on the chamber‚Äôs website. Notice their id at the end of the url after ‚Äòcfm?key=‚Äô and before ‚Äò&amp;amp;lat‚Äô.&lt;/p&gt;
&lt;p&gt;On their personal space there is more information like their parliament email, their personal website and a short cv.&lt;/p&gt;
&lt;p&gt;Let‚Äôs only scrape their language for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_language &amp;lt;- function (url){
  as.character(url) %&amp;gt;% 
  read_html() %&amp;gt;% 
  html_node(&amp;quot;td &amp;gt; p &amp;quot;) %&amp;gt;% 
  html_text() %&amp;gt;% 
  str_extract(&amp;#39;(?&amp;lt;=Taal:\\s)\\w+&amp;#39;) 
 }

names &amp;lt;- map_chr(names$url, get_language) %&amp;gt;% 
  cbind(names) 

names &amp;lt;- rename(names, language = .)

saveRDS(names, &amp;quot;./data/190417/names.rds&amp;quot;)

head(names)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   language              fn_ln
## 1     &amp;lt;NA&amp;gt;      Meyrem Almaci
## 2     &amp;lt;NA&amp;gt; Daniel Bacquelaine
## 3     &amp;lt;NA&amp;gt;         Sonja Becq
## 4     &amp;lt;NA&amp;gt;       Wouter Beke 
## 5     &amp;lt;NA&amp;gt;       Rita Bellens
## 6     &amp;lt;NA&amp;gt;    Nawal Ben Hamou
##                                                                                                            url
## 1 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=01189&amp;amp;lactivity=54
## 2 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=00757&amp;amp;lactivity=54
## 3 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=01190&amp;amp;lactivity=54
## 4 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=01149&amp;amp;lactivity=54
## 5 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=06592&amp;amp;lactivity=54
## 6 http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&amp;amp;language=nl&amp;amp;cfm=cvview54.cfm?key=06647&amp;amp;lactivity=54
##                 key              ln_fn    id party
## 1      aaceeilmmmry      Almaci Meyrem 01189    NA
## 2 aaabcdeeeiillnnqu Bacquelaine Daniel 00757    NA
## 3         abcejnoqs         Becq Sonja 01190    NA
## 4        beeekortuw        Beke Wouter 01149    NA
## 5       abeeillnrst       Bellens Rita 06592    NA
## 6     aaabehlmnnouw    Ben Hamou Nawal 06647    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs get their mugshots.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190417/inspect.png&#34; alt=&#34;Inspecting the code of the webpage&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;The images are in folder: &lt;a href=&#34;http://www.dekamer.be/site/wwwroot/images/cv/&#34; class=&#34;uri&#34;&gt;http://www.dekamer.be/site/wwwroot/images/cv/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# let&amp;#39;s try purrr again

download_gifs &amp;lt;- function (name, id){
  url_pic &amp;lt;- glue(&amp;quot;http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif&amp;quot;)
  download.file(url_pic, destfile = glue(&amp;quot;./data/190417/{name}.gif&amp;quot;), 
                mode = &amp;quot;wb&amp;quot;)
}

#download_gifs(&amp;quot;test&amp;quot;,&amp;quot;01203&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That seems to work. Unfortunately while scraping it is not infrequent to encounter coding inconsistencies. For instance member ‚Äú00902‚Äù does not have a ‚Äú00902.gif‚Äù his is ‚Äú902.gif‚Äù. Dirty data alert üö®, shame on you webmaster üòâ.&lt;/p&gt;
&lt;p&gt;So sometimes the 0 is used and sometimes it is just the value without leading 0. One possible solution is to split the download_gifs function in two.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;download_gifs_with_0 &amp;lt;- function (name, id){
  url_pic &amp;lt;- glue(&amp;quot;http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif&amp;quot;)
  download.file(url_pic, destfile = glue(&amp;quot;./data/190417/down_1/{name}.gif&amp;quot;), 
                mode = &amp;quot;wb&amp;quot;)
}

download_gifs_no_0 &amp;lt;- function (name, id){
  id &amp;lt;- as.numeric(id)
  url_pic &amp;lt;- glue(&amp;quot;http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif&amp;quot;)
  download.file(url_pic, destfile = glue(&amp;quot;./data/190417/down_2/{name}.gif&amp;quot;), 
                mode = &amp;quot;wb&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trying to simplify the use of the purrr function ‚Äòsafely‚Äô, by Lionel Henry who I thank for his work &amp;amp; &lt;a href=&#34;https://www.youtube.com/watch?v=-v1tp41kizk&#34;&gt;presentation&lt;/a&gt; at the UseR2018 conference in Budapest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir.create(&amp;quot;./data/190417/down_1&amp;quot;)
map2(.x = names$ln_fn, .y = names$id, safely(.f = download_gifs_with_0, otherwise = NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So using ‚Äòsafely‚Äô the error are being skipped and we managed to download how many files?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(list.files(&amp;quot;./data/190417/down_1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 160&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;160&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Only few missing. Let‚Äôs use the other function.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir.create(&amp;quot;./data/190417/down_2&amp;quot;)
map2(.x = names$ln_fn, .y = names$id, safely(.f = download_gifs_no_0, otherwise = NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(list.files(&amp;quot;./data/190417/down_2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 96&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;96&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Hmm so now we have too many pictures (and the ones with no leading 0 seem older). See the aging of Mr Calvo:
&lt;center&gt;
&lt;img src=&#34;/img/20190417/Calvo%20Kristof_young.gif&#34; alt=&#34;Young Mr Calvo&#34; /&gt; &lt;img src=&#34;/img/20190417/Calvo%20Kristof_06128_old.gif&#34; alt=&#34;Old Mr Calvo&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/center&gt;
&lt;p&gt;Whose pics were additionally obtained?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new &amp;lt;- list.files(&amp;quot;./data/190417/down_1&amp;quot;)
old &amp;lt;- list.files(&amp;quot;./data/190417/down_2&amp;quot;)
new_pics &amp;lt;- setdiff(old, new)
new_pics&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Chabot Jacques.gif&amp;quot;       &amp;quot;Claerhout Sarah.gif&amp;quot;     
##  [3] &amp;quot;Crusni√®re St√©phane.gif&amp;quot;   &amp;quot;Dallemagne Georges.gif&amp;quot;  
##  [5] &amp;quot;Devin Laurent.gif&amp;quot;        &amp;quot;Gabri√´ls Katja.gif&amp;quot;      
##  [7] &amp;quot;Galant Isabelle.gif&amp;quot;      &amp;quot;Gustin Luc.gif&amp;quot;          
##  [9] &amp;quot;Hufkens Renate.gif&amp;quot;       &amp;quot;Janssens Dirk.gif&amp;quot;       
## [11] &amp;quot;Klaps Johan.gif&amp;quot;          &amp;quot;Miller Richard.gif&amp;quot;      
## [13] &amp;quot;Raskin Wouter.gif&amp;quot;        &amp;quot;Scourneau Vincent.gif&amp;quot;   
## [15] &amp;quot;Van Hoof Els.gif&amp;quot;         &amp;quot;Van Peteghem Vincent.gif&amp;quot;
## [17] &amp;quot;Vanden Burre Gilles.gif&amp;quot;  &amp;quot;Vuye Hendrik.gif&amp;quot;        
## [19] &amp;quot;Wilm√®s Sophie.gif&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice guy, Georges. Recently became grandfather again.&lt;/p&gt;
&lt;p&gt;So are we missing some?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fileslist &amp;lt;- list.files(&amp;quot;./data/190417/&amp;quot;, pattern = &amp;quot;*.gif&amp;quot;)
names_list &amp;lt;- gsub(&amp;quot;.gif&amp;quot;,&amp;quot;&amp;quot;,fileslist)
setdiff(names_list, names$ln_fn)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have a picture of all of them. üòé&lt;/p&gt;
&lt;p&gt;A collage of their pictures will give us a nice overview.&lt;/p&gt;
&lt;p&gt;Need to rename them for the magick package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setwd(&amp;quot;./data/190417/patch_rep&amp;quot;)
file.rename(list.files(), 
            paste0(&amp;quot;g_&amp;quot;, 1:179,&amp;quot;.gif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs resize them for good measure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resize_player &amp;lt;- function(x){
  img &amp;lt;- image_scale(image_read(x), &amp;quot;145x190!&amp;quot;)
  image_write(img, x)        
}

player_pics &amp;lt;- list.files(&amp;quot;./data/190417/patch_rep/&amp;quot;, full.names = TRUE)

map(player_pics, resize_player)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create columns&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir.create(&amp;quot;./data/190417/cols_rep&amp;quot;)

getwd()
files &amp;lt;- dir(&amp;quot;data/190417/patch_rep&amp;quot;, full.names = TRUE)
set.seed(1)
files &amp;lt;- sample(files, length(files)-2) # 176 will make a nice patch
gmp::factorize(length(files)-2)

no_rows &amp;lt;- 11
no_cols &amp;lt;- 16


fun &amp;lt;- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %&amp;gt;%
  image_append(stack = TRUE) %&amp;gt;%
    image_write(paste0(&amp;quot;./data/190417/cols_rep/&amp;quot;, i, &amp;quot;.jpg&amp;quot;))
}

 for(i in (0:(no_cols-1))) {
 fun(i, files, no_rows)
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have the columns. Still need to bind them together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getwd()

img &amp;lt;- image_read(dir(&amp;quot;data/190417/cols_rep/&amp;quot;, full.names = TRUE)) %&amp;gt;%
image_append(stack = FALSE) 

setwd(&amp;quot;./files/20190417&amp;quot;)
getwd()
image_write(img,&amp;quot;2019-04-17-faces_of_54.jpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190417/2019-04-17-faces_of_54.jpg&#34; alt=&#34;reps 54&#34; width=&#34;800&#34; height=&#34;800&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Looking at the picture I will let you judge how diverse the picture looks. Less diverse than our national soccer team, that is for sure. But those two groups are indeed two very small and different samples of Belgians.&lt;/p&gt;
&lt;p&gt;Wondering what the 55 legislature will look like. Will keep you posted.&lt;/p&gt;
&lt;p&gt;But wait a minute. Did I say Belgian national soccer teams? Hold my beer.&lt;/p&gt;
&lt;p&gt;Analyzing the Red Devil‚Äôs website code, it appears the pictures are to be found in an aws bucket s3 folder.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190417/Eden.png&#34; alt=&#34;Inspecting the code of the webpage&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Downloading the pictures of the men:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in (1:7000)){
  
  url_pic &amp;lt;-glue(&amp;quot;https://belgianfootball.s3.eu-central-1.amazonaws.com/&amp;quot;,
                 &amp;quot;s3fs-public/rbfa/img/players/internationals/football/men/{i}.jpg&amp;quot;)
  
  res &amp;lt;- try(download.file(url_pic, 
                           destfile = glue(&amp;quot;./content/post/data/190417down_m/{i}.jpg&amp;quot;), 
                           mode = &amp;quot;wb&amp;quot;))
  if(inherits(res, &amp;quot;try-error&amp;quot;))
  {
    next
  }
  download.file(url_pic, destfile = glue(&amp;quot;./content/post/data/190417down_m/{i}.jpg&amp;quot;), 
                mode = &amp;quot;wb&amp;quot;)
  }


# clean the folder of empty files:

all_files &amp;lt;- dir(&amp;quot;./content/post/data/190417down_m/&amp;quot;, 
                 recursive = TRUE, full.names = TRUE)
erase &amp;lt;- all_files[file.info(all_files)[[&amp;quot;size&amp;quot;]]&amp;lt; 4200]

## Remove empty files
unlink(erase, recursive=TRUE, force=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next is downloading the pictures of the women:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in (1:7000)){
  
  url_pic &amp;lt;-glue(&amp;quot;https://belgianfootball.s3.eu-central-1.amazonaws.com/&amp;quot;,
                 &amp;quot;s3fs-public/rbfa/img/players/internationals/football/women/{i}.jpg&amp;quot;)
  
  res &amp;lt;- try(download.file(url_pic, destfile = glue(&amp;quot;./content/post/data/190417down_w/{i}.jpg&amp;quot;), 
                           mode = &amp;quot;wb&amp;quot;))
  if(inherits(res, &amp;quot;try-error&amp;quot;))
  {
    next
  }
  download.file(url_pic, destfile = glue(&amp;quot;./content/post/data/190417down_w/{i}.jpg&amp;quot;), 
                mode = &amp;quot;wb&amp;quot;)
  }

# clean the folder of smaller files:

all_files &amp;lt;- dir(&amp;quot;./content/post/data/190417down_w/&amp;quot;, recursive = TRUE, full.names = TRUE)
erase &amp;lt;- all_files[file.info(all_files)[[&amp;quot;size&amp;quot;]]&amp;lt; 4200]
## Remove empty files
unlink(erase, recursive=TRUE, force=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are now 687 pictures of national soccer players; 418 men and 269 women. Most of these pictures seem to be recent, but there is no date tag or something similar. Overall, they seem fairly recent.&lt;/p&gt;
&lt;p&gt;Sampling 176 of them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# renaming files, so we do not have the same file names between men and women

setwd(&amp;quot;./data/190417down_m/&amp;quot;)
length(list.files())
file.rename(list.files(), paste0(&amp;quot;m_&amp;quot;, 1:418,&amp;quot;.jpg&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Merging men and women.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;men_files &amp;lt;- list.files(&amp;quot;./data/190417down_m/&amp;quot;, recursive = TRUE, full.names = TRUE)
women_files &amp;lt;- list.files(&amp;quot;./data/190417down_w/&amp;quot;, recursive = TRUE, full.names = TRUE)

player_files &amp;lt;- c(men_files, women_files)
set.seed(42)
sampled_files &amp;lt;- sample(player_files, 176)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Making the same patchwork&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir.create(&amp;quot;./data/190417/patch&amp;quot;)

lapply(sampled_files, function(x) file.copy(x,
                                        paste(&amp;quot;./data/190417/patch&amp;quot;,basename(x), 
                                              sep = &amp;quot;/&amp;quot;), 
                                        recursive = FALSE,  copy.mode = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the pictures need to have the same size (170x250 pixel)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resize_player &amp;lt;- function(x){
  img &amp;lt;- image_scale(image_read(x), &amp;quot;170x250!&amp;quot;)
  image_write(img, x)        
}

player_pics &amp;lt;- list.files(&amp;quot;./data/190417/patch/&amp;quot;, full.names = TRUE)

map(player_pics, resize_player)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create the columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir.create(&amp;quot;./data/190417/cols&amp;quot;)

getwd()
files &amp;lt;- dir(&amp;quot;data/190417/patch&amp;quot;, full.names = TRUE)
set.seed(1)
files &amp;lt;- sample(files, length(files))
gmp::factorize(length(files))

no_rows &amp;lt;- 11
no_cols &amp;lt;- 16


fun &amp;lt;- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %&amp;gt;%
  image_append(stack = TRUE) %&amp;gt;%
    image_write(paste0(&amp;quot;./data/190417/cols/&amp;quot;, i, &amp;quot;.jpg&amp;quot;))
}

for(i in (0:(no_cols-1))) {
fun(i, files, no_rows)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;img &amp;lt;- image_read(dir(&amp;quot;data/190417/cols/&amp;quot;, full.names = TRUE)) %&amp;gt;%
image_append(stack = FALSE) 

setwd(&amp;quot;./files/20190417&amp;quot;)
getwd()
image_write(img,&amp;quot;2019-04-17-faces_of_devils.jpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So here is the patchwork of the national soccer players.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/img/20190417/2019-04-17-faces_of_devils.jpg&#34; alt=&#34;devils&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;So give me my tepid beer back. Here‚Äôs a sample of our national soccer players. To contrast with our parliamentarian representatives. They are obviously younger, more diverse and fitter (let‚Äôs hope). They also do not wear glasses (on the picture). And yes, I found an Easter egg. :-)&lt;/p&gt;
&lt;p&gt;Let‚Äôs get back to the parliamentarians tweets in the next post.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>am I getting slower going to work?</title>
      <link>/post/am-i-getting-slower-going-to-work/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/am-i-getting-slower-going-to-work/</guid>
      <description></description>
      
      <content>


&lt;p&gt;I got a bit distracted writing the last post. What I want to find out is, based on my Google location history, how fast I bike to work and if this has changed over time.&lt;/p&gt;
&lt;p&gt;Attaching libraries&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;lubridate&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;purrr&amp;quot;)
library(&amp;quot;ggmap&amp;quot;)
library(&amp;quot;ggplot2&amp;quot;); theme_set(theme_minimal())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And loading the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the code to convert your location data to a data frame:
# see last post too
# data &amp;lt;- fromJSON(&amp;quot;./data/Location History.json&amp;quot;) # extracts a list
# locations &amp;lt;- data$locations # and the list contains a dataframe

location &amp;lt;- readRDS(&amp;quot;./data/location.rds&amp;quot;)

df &amp;lt;- location %&amp;gt;% 
  mutate(datetime = as.POSIXct(as.numeric(timestampMs)/1000, origin = &amp;quot;1970-01-01&amp;quot;)) 

df &amp;lt;- df %&amp;gt;% 
  mutate(lat   = latitudeE7/1e7,
         lon   = longitudeE7/1e7,
         time  = strftime(datetime, format = &amp;quot;%H:%M:%S&amp;quot;),
         date  = date(datetime),
         year  = year(datetime),
         month = month(datetime),
         wday  = wday(datetime))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So what do we have here?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nrow(df)                   # rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 522770&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(unique(df$date))    # days&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1249&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;min(unique(df$date))       # first day&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2014-01-14&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(unique(df$date))       # last day&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2018-10-15&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plotted:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = df, aes(x = datetime, y = lat))+
 geom_line()+
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
    labs(title=&amp;quot;commuting slower?&amp;quot;,
       subtitle = &amp;quot;latitude tracking 2014 - 2018&amp;quot;,
       x = &amp;quot;days&amp;quot;,
       y = &amp;quot;latitude&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I changed jobs in September 2014, my first working day at my current job was 15/09/2014.&lt;/p&gt;
&lt;p&gt;Let‚Äôs see which days I was working there. The dataframe ‚Äúwork‚Äù, then contains all the data points from where I am at work.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;work &amp;lt;- df %&amp;gt;% 
  filter(date &amp;gt; &amp;quot;2014-09-14&amp;quot;) %&amp;gt;%
  filter(round(lat,3) == 50.557) %&amp;gt;% 
  filter(round(lon,2) == 5.18) %&amp;gt;% # a little less accuracy on the longitude
  mutate(homework = &amp;quot;work&amp;quot;) %&amp;gt;% 
  mutate(am_pm = case_when(am(datetime) ~ &amp;quot;am&amp;quot;,
                           TRUE ~ &amp;quot;pm&amp;quot;))

length(unique(work$date)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 406&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = work, aes(x = datetime, y = lat))+
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())+
  labs(y = &amp;quot;latitude&amp;quot;, 
    title = &amp;quot;lattitude between home and work by day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So that would mean that in my data set I have 406 working days and the data that comes along with it.
Since at this point I am not interested in the data from days I was not working, these can be filtered out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;home &amp;lt;- df %&amp;gt;%
  filter(round(lat,3) != 50.557) %&amp;gt;% 
  filter(round(lon,2) != 5.18) %&amp;gt;%
  mutate(homework = &amp;quot;not_work&amp;quot;) %&amp;gt;% 
  filter(date %in%(unique(work$date))) %&amp;gt;% 
  mutate(am_pm = case_when(am(datetime) ~ &amp;quot;am&amp;quot;,
                           TRUE ~ &amp;quot;pm&amp;quot;))

home_work &amp;lt;- rbind(home, work) %&amp;gt;% 
  arrange(datetime)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What days at work got tracked?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(unique(home_work$date)) # workdays&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 406&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;min(unique(home_work$date))    # first day&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2014-09-15&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(unique(home_work$date))    # last day&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2018-07-03&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To calculate the time of my daily commute I have to find the time between I last was at home and the time I arrived at work.&lt;/p&gt;
&lt;p&gt;The latitude changes during a typical working day look like this (although this one is particularly boring üòí).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day &amp;lt;- df %&amp;gt;% 
  filter(date == &amp;quot;2014-12-23&amp;quot;) 

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = &amp;quot;latitude&amp;quot;, 
    title = &amp;quot;23/12/2014 - another day at the office&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And if we look at the first hours of the day and arriving at work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day &amp;lt;- df %&amp;gt;% 
  filter(date == &amp;quot;2014-12-23&amp;quot;) %&amp;gt;% 
  filter(time &amp;gt; &amp;quot;07:00:00&amp;quot;,
         time &amp;lt; &amp;quot;09:30:00&amp;quot;)

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;23/12/2014 - zooming in on arriving at work&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the time spent in the commute is the time first at around 50.560 latitude (itw) minus the last time at around 50.580 latitude (oth), and that for the time period of let‚Äôs say between 7am and 9.30am.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;oth &amp;lt;- day %&amp;gt;% 
  filter(lat &amp;lt; 50.5756) %&amp;gt;% 
  filter(time == min(time)) %&amp;gt;% 
  select(time) %&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))

itw &amp;lt;- day %&amp;gt;% 
  filter(lat &amp;lt; 50.558) %&amp;gt;% 
  filter(time == min(time)) %&amp;gt;% 
  select(time)%&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))

commute_time &amp;lt;- difftime(itw$time,oth$time, units = c(&amp;quot;mins&amp;quot;)) #9.93 minutes
class(commute_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;difftime&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(commute_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.083333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2 minutes is a bit too fast. The problem is that the first time out of the house, on that particular date, is recorded pretty late. So the last time in the house (ith) is the one that is needed. Also because starting around 30/01/2016 a strange pattern is emerging&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day &amp;lt;- home_work %&amp;gt;%
  filter(date == &amp;quot;2018-07-03&amp;quot;) %&amp;gt;% 
  filter(time &amp;gt; &amp;quot;08:00:00&amp;quot;,
         time &amp;lt; &amp;quot;09:30:00&amp;quot;)

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = &amp;quot;latitude&amp;quot;, 
    title = &amp;quot;&amp;#39;bilocation&amp;#39; pattern&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And that pattern did not happen before February 2016. For instance ‚Äú2016-01-08‚Äù gives.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day &amp;lt;- home_work %&amp;gt;%
  filter(date == &amp;quot;2016-01-08&amp;quot;) %&amp;gt;% 
  filter(time &amp;gt; &amp;quot;07:30:00&amp;quot;,
         time &amp;lt; &amp;quot;09:30:00&amp;quot;)

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line()+
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = &amp;quot;latitude&amp;quot;, 
    title = &amp;quot;before February 2016&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A collegue came up with the hypothesis that it was my computer at home that was messing up my phone location data, which was a great idea, but in fact it was my tablet.&lt;/p&gt;
&lt;p&gt;I bought it on 30/01/2016, and both it‚Äôs location data and my phone location data are merged ever since. Which is kind of surprising or rather dissapointing.&lt;/p&gt;
&lt;p&gt;Google is serving us dirty data in the location history. I cannot imagine it does not distinguish between my devises.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;oth &amp;lt;- day %&amp;gt;% 
  filter(lat &amp;lt; 50.5756) %&amp;gt;% 
  filter(time == min(time)) %&amp;gt;% 
  select(time) %&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))

# the last time in the house
ith &amp;lt;- day %&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;)) %&amp;gt;% 
  filter(time &amp;lt; oth$time) %&amp;gt;% 
  filter(time == max(time))%&amp;gt;% 
  select(time) %&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))


itw &amp;lt;- day %&amp;gt;% 
  filter(lat &amp;lt; 50.557) %&amp;gt;% 
  filter(time == min(time)) %&amp;gt;% 
  select(time)%&amp;gt;% 
  mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))

commute_time &amp;lt;- difftime(itw$time,ith$time, units = c(&amp;quot;mins&amp;quot;)) #9.93 minutes
class(commute_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;difftime&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(commute_time)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 44.48333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;44 minutes on the other hand seems like a lot. But the data and calculations look correct to me. One explanation could be that sometimes there is a big delay in reporting the arrival time. Like on April 17 2015, where arrival was recorded after 12am.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;day &amp;lt;- df %&amp;gt;% 
  filter(date == &amp;quot;2015-04-17&amp;quot;) 

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() + 
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = &amp;quot;latitude&amp;quot;, 
    title = &amp;quot;April 17 2015&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So it‚Äôs time to do some more data cleaning, and select dates that have data from both work and home between 7 and 9:30am.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;keep_dates &amp;lt;- home_work %&amp;gt;% 
  filter(time &amp;gt; &amp;quot;07:00:00&amp;quot;,
         time &amp;lt; &amp;quot;09:30:00&amp;quot;) %&amp;gt;%
  plyr::count(c(&amp;#39;date&amp;#39;, &amp;#39;homework&amp;#39;)) %&amp;gt;% 
  spread(homework, freq) %&amp;gt;% 
  filter(work &amp;gt; 0) %&amp;gt;% 
  select(date)
glue(&amp;quot;so there are now {nrow(keep_dates)} days to be analysed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## so there are now 336 days to be analysed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs define a function to do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# building the function
get_time &amp;lt;- function(x_date){
  day &amp;lt;- home_work %&amp;gt;%
    filter(date ==  x_date) %&amp;gt;% 
    filter(time &amp;gt; &amp;quot;07:30:00&amp;quot;,
           time &amp;lt; &amp;quot;09:30:00&amp;quot;)
  oth &amp;lt;- day %&amp;gt;% 
    filter(lat &amp;lt; 50.5756) %&amp;gt;% 
    filter(time == min(time)) %&amp;gt;% 
    select(time) %&amp;gt;% 
    mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;)) %&amp;gt;% 
    slice(1) # making sure one value is returned
  
  ith &amp;lt;- day %&amp;gt;% 
    mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;)) %&amp;gt;% 
    filter(time &amp;lt; oth$time) %&amp;gt;% 
    filter(time == max(time))%&amp;gt;% 
    select(time) %&amp;gt;% 
    mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))
  
  if(nrow(ith) == 0) {ith &amp;lt;- oth} 
  
  itw &amp;lt;- day %&amp;gt;% 
    filter(lat &amp;lt; 50.558) %&amp;gt;% 
    filter(time == min(time)) %&amp;gt;% 
    select(time)%&amp;gt;% 
    mutate(time = as.POSIXct(time, format = &amp;quot;%H:%M:%S&amp;quot;))%&amp;gt;% 
    slice(1) # making sure one value is returned
  
  x &amp;lt;- difftime(itw$time,ith$time, units = c(&amp;quot;mins&amp;quot;))
  x &amp;lt;- round(as.numeric(x),2)
  return(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I had a struggle with purrr‚Äôs map_df() , but map_dbl() also does the trick&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- map_dbl(keep_dates$date, get_time) %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  rename(&amp;quot;minutes&amp;quot; = &amp;quot;.&amp;quot;) %&amp;gt;% 
  cbind(keep_dates) %&amp;gt;% 
  select(date, minutes)

head(result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date minutes
## 1 2014-09-16   18.53
## 2 2014-09-18   10.45
## 3 2014-09-24   28.02
## 4 2014-09-26   32.77
## 5 2014-09-30    9.30
## 6 2014-10-01   20.92&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(result$minutes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 100.95&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;min(result$minutes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.13&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(result, aes(x = date, y = minutes)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;)+ 
  scale_y_continuous(limits = c(0, 65)) +
  labs(y = &amp;quot;minutes to work&amp;quot;, 
    title = &amp;quot;2015 - 2018&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;2018 seems to have the cleanest data at this point. I sometimes walk to work or take the bus or the car. All of these take me more time than biking to work. There are five trafic lights on the way and I tend to stop for trafic lights when they are red. So the trafic ligths might explain much of the variance.&lt;/p&gt;
&lt;p&gt;A bike ride would not take more than twenty minutes, and surely not less than 5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_2018 &amp;lt;- result %&amp;gt;% 
  filter(year(date) == 2018) %&amp;gt;% 
  filter(minutes &amp;lt; 20,
         minutes &amp;gt; 5)

ggplot(r_2018, aes(x = date, y = minutes)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;) +
  labs(y = &amp;quot;minutes to work&amp;quot;, 
    title = &amp;quot;2018&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;round(mean(r_2018$minutes),2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12.18&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that would then be around 12 minutes. I still need to time my current commutes for a while to see if I got slower.&lt;/p&gt;
&lt;p&gt;I hoped for a bit cleaner data and the possibility to easyly compare the evolution of the time spent commuting over several years. But I‚Äôll take the 12.18 minutes for now.&lt;/p&gt;
&lt;p&gt;Finally I wanted to share the ‚Äúpat√©s‚Äù with you. Not often enough part of the team takes a break and walks around the office block, and those we call doing a ‚Äúpat√©‚Äù (= block). They say walking meetings are in these days.&lt;/p&gt;
&lt;p&gt;I was looking to see how many of them we are doing, but as you will see below the datapoints are mostly centered on our office building itself. And I cannot see how I can construct a pattern around it representing the ‚Äúpat√©s‚Äù.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;secrets &amp;lt;- readRDS(&amp;quot;~/R/geo/secret/secrets.rds&amp;quot;)
key &amp;lt;- secrets$key[1]
register_google(key = key)

zoom &amp;lt;- get_map(location = c(lon = 4.306, lat = 50.8545), zoom = 19, maptype = &amp;quot;satellite&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : https://maps.googleapis.com/maps/api/staticmap?center=50.8545,4.306&amp;amp;zoom=19&amp;amp;size=640x640&amp;amp;scale=2&amp;amp;maptype=satellite&amp;amp;language=en-EN&amp;amp;key=xxx&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- readRDS(&amp;quot;./data/location_509.rds&amp;quot;) %&amp;gt;% 
  filter(year != 2017)

ggmap(zoom) + 
  geom_point(data = df, aes(x = lon, y = lat),
             alpha = 0.7, color = &amp;quot;#FC4E07&amp;quot;, size = .8) + 
  facet_wrap(~year) +
  theme(legend.position = &amp;quot;right&amp;quot;) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;always happy @work&amp;quot;,
    caption = &amp;quot;\n removed 2017 because there were few data points.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-13-am-i-getting-slower-going-to-work_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It seems to me all the data is a bit off. 2014 to 2016 a bit or a lot shifted to the left, and 2018 just a tad too much to the right.&lt;/p&gt;
&lt;p&gt;But still. Welcome to the panopticon.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>google location tracking</title>
      <link>/post/google-location-tracking/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      <author>William Bourgeois</author>
      <guid>/post/google-location-tracking/</guid>
      <description></description>
      
      <content>


&lt;p&gt;Biking to work this week I was wondering if I had not gotten slower and if my commute was not taking longer than before. Not being a regular user of Strava or a similar app, I wondered if I could find an answer to that question using my Google location history.&lt;/p&gt;
&lt;p&gt;So I downloaded the data, that comes in json format, and had a go at it. You can &lt;a href=&#34;https://takeout.google.com/settings/takeout&#34;&gt;download&lt;/a&gt; your Google location data from your Google account.&lt;/p&gt;
&lt;p&gt;Let‚Äôs load the data and attach the libraries that are needed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;jsonlite&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;lubridate&amp;quot;)
library(&amp;quot;ggplot2&amp;quot;)
library(&amp;quot;ggmap&amp;quot;)      # devtools::install_github(&amp;quot;dkahle/ggmap&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;emo&amp;quot;)        # devtools::install_github(&amp;quot;hadley/emo&amp;quot;)
library(&amp;quot;viridis&amp;quot;)    # install.packages(&amp;quot;viridis&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getwd()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;C:/Users/William/Documents/R/blogs/content/post&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- fromJSON(&amp;quot;./data/20190330/Location History.json&amp;quot;) # extracts a list
locations &amp;lt;- data$locations # and the list contains a dataframe
rm(data)  # no need for this anymore&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;a href=&#34;https://shiring.github.io/maps/2016/12/30/Standortverlauf_post&#34;&gt;blogpost&lt;/a&gt; from Shirin Glander was super useful and I am shamelessly stealing some of her great ideas. The time stamp needs to be converted to be readable.
The field heading seems to be in degrees, is velocity in mph? And I don‚Äôt know where the altitude reading comes from (maybe not a pressure sensor but gps triangulation?, ground elevation?).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- locations %&amp;gt;% 
  mutate(datetime = as.POSIXct(as.numeric(timestampMs)/1000, origin = &amp;quot;1970-01-01&amp;quot;)) 

sort(unique(df$heading)) #naught to 360&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1]   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16
##  [18]  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
##  [35]  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50
##  [52]  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67
##  [69]  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84
##  [86]  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101
## [103] 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
## [120] 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
## [137] 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
## [154] 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
## [171] 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
## [188] 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
## [205] 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
## [222] 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
## [239] 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
## [256] 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
## [273] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
## [290] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
## [307] 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
## [324] 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339
## [341] 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
## [358] 357 358 359&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Is the velocity in miles per hour ?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(df$velocity)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] NA  0  1  3  5 14 28  2  4  7  8 25 29 15 16 19 10  6  9 11 13 12 21
## [24] 24 20 17 26 27 30 23 22 18 31 33 32 34 35 36 82 83 77 74 67 37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Does that mean that I ever broke the speed limit? We‚Äôre not supposed to drive faster than 120 km/h in Belgium üöì!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fine &amp;lt;- paste(round(max(unique(df$velocity), na.rm = TRUE)*1.609344,0),&amp;quot;km!&amp;quot;)

glue(&amp;quot;{fine} üò± üò± üò±&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 134 km! üò± üò± üò±&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Could this information get me fined? Or will this type information be used in the future to determine guilt?
Are the police allowed to access this type of Google data to for instance find perps of hit &amp;amp; runs?&lt;/p&gt;
&lt;p&gt;The data frame also contains lists with times stamps and estimations of activity at that time stamp.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(df$activity[80])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ :&amp;#39;data.frame&amp;#39;:    1 obs. of  2 variables:
##   ..$ timestampMs: chr &amp;quot;1395248054966&amp;quot;
##   ..$ activity   :List of 1
##   .. ..$ :&amp;#39;data.frame&amp;#39;:  5 obs. of  2 variables:
##   .. .. ..$ type      : chr [1:5] &amp;quot;ON_FOOT&amp;quot; &amp;quot;STILL&amp;quot; &amp;quot;IN_VEHICLE&amp;quot; &amp;quot;UNKNOWN&amp;quot; ...
##   .. .. ..$ confidence: int [1:5] 49 20 16 10 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So if I read this correctly this object is a list of one, containing a dataframe with another two objects, a timestamp and another list of one, that contains a dataframe with 5 observations and two variables: the type of activity and the probability calculated for it. So on timestamp ‚Äú1395248054966‚Äù (= 2014-03-19 17:54:14 CET) I had a 49% probability to be on foot.&lt;/p&gt;
&lt;p&gt;And then there is also a measure of altitude. Is it in feet or meters, and where do the negative numbers come from? Maybe these data points should be analysed a bit later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(unique(df$altitude)) # ? what sensor does it use?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  int [1:633] NA 27 41 38 42 60 16 57 63 49 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(unique(df$altitude))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&amp;#39;s 
## -1299.0   108.8   266.5   274.0   435.2  2983.0       1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs plot some data on maps.&lt;/p&gt;
&lt;p&gt;First some additional date prep.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% 
  mutate(lat   = latitudeE7/1e7,
         lon   = longitudeE7/1e7,
         time  = strftime(datetime, format = &amp;quot;%H:%M:%S&amp;quot;),
         date  = date(datetime),
         year  = year(datetime),
         month = month(datetime),
         wday  = wday(datetime))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Working with ggmap is pretty straightforward, but you need to obtain an api key from google and enable billing. More info &lt;a href=&#34;https://developers.google.com/maps/documentation/embed/get-api-key&#34;&gt;here&lt;/a&gt;. For obvious reasons you need to keep your key secret and safe, but additionally you can restrict the calls to your &lt;a href=&#34;https://console.developers.google.com/apis/credentials?project=grounded-block-178714&amp;amp;folder&amp;amp;organizationId&#34;&gt;IP&lt;/a&gt;. Will have a go at OSM in a future post, promised.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;secrets &amp;lt;- readRDS(&amp;quot;~/R/geo/secret/secrets.rds&amp;quot;)
key &amp;lt;- secrets$key[1]
register_google(key = key)

belgium &amp;lt;- get_map(location = &amp;#39;Belgium&amp;#39;, zoom = 8, maptype = &amp;quot;terrain-lines&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The map coverage is called the bounding box of the map and it is an attribute of the ggmap object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bb &amp;lt;- attr(belgium, &amp;quot;bb&amp;quot;)
bb&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          ll.lat  ll.lon ur.lat   ur.lon
## bottom 49.37082 2.71487 51.607 6.230495&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- df %&amp;gt;% 
  filter(lat &amp;lt; 51.607 &amp;amp; lat &amp;gt; 49.37082,
         lon &amp;gt; 2.71487 &amp;amp; lon &amp;lt; 6.20495)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(belgium, maptype = &amp;quot;terrain-lines&amp;quot;) + 
  geom_point(data = x, aes(x = lon, y = lat),
             alpha = 0.1, color = &amp;quot;#FC4E07&amp;quot;, size = .65) + 
  theme(legend.position = &amp;quot;right&amp;quot;) + 
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;Location history data points in Belgium&amp;quot;,
    caption = &amp;quot;\nA simple point plot shows recorded positions.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Orange lines are my movements. A rock festival to the east of Antwerp, some visits to the coast, to my home city Ghent, a marriage in the west, biking and text mining in Leuven, and hikes in the woods of the south. Looks about right. And yes, I live and work in Brussels.&lt;/p&gt;
&lt;p&gt;So let‚Äôs take a closer look at Brussels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brussels &amp;lt;- get_map(location = &amp;#39;Brussels&amp;#39;, zoom = 12, maptype = &amp;quot;terrain-lines&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bb &amp;lt;- attr(brussels, &amp;quot;bb&amp;quot;)
bb&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          ll.lat   ll.lon   ur.lat   ur.lon
## bottom 50.78082 4.242029 50.91955 4.461756&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# just keeping data from brussels

x &amp;lt;- df %&amp;gt;% 
  filter(lat &amp;lt; bb$ur.lat &amp;amp; lat &amp;gt; bb$ll.lat,
         lon &amp;gt; bb$ll.lon &amp;amp; lon &amp;lt; bb$ur.lon)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(brussels) + 
  geom_point(data = x, aes(x = lon, y = lat),
             alpha = 0.5, color = &amp;quot;#FC4E07&amp;quot;, size = .65) + 
  theme(legend.position = &amp;quot;right&amp;quot;) + 
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;Location history data points in Brussels&amp;quot;,
    caption = &amp;quot;\nA simple point plot shows recorded positions.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let‚Äôs see how much we can zoom in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zoom &amp;lt;- get_map(location = c(lon = 4.349078, lat = 50.850586), zoom = 16, maptype = &amp;quot;satellite&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bb &amp;lt;- attr(zoom, &amp;quot;bb&amp;quot;)
x &amp;lt;- df %&amp;gt;% 
  filter(lat &amp;lt; bb$ur.lat &amp;amp; lat &amp;gt; bb$ll.lat,
         lon &amp;gt; bb$ll.lon &amp;amp; lon &amp;lt; bb$ur.lon)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(zoom) + 
 geom_point(data = x, aes(x = lon, y = lat),
             alpha = 0.7, color = &amp;quot;#FC4E07&amp;quot;, size = .85) + 
  theme(legend.position = &amp;quot;right&amp;quot;) + 
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;Location history data points in central Brussels&amp;quot;,
    caption = &amp;quot;\n favorite haunts.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So that is pretty consistent with my favorite downtown haunts. Let‚Äôs pan out and add the number of seconds from 6 am in the day to the dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;period_to_seconds(hms(&amp;quot;06:00:00&amp;quot;)) # seconds at 6am&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 21600&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;period_to_seconds(hms(&amp;quot;23:59:59&amp;quot;)) # seconds just before midnight&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 86399&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% 
  mutate(from_dawn = 
           case_when((period_to_seconds(hms(time)) &amp;gt; 21600) ~ 
                       (period_to_seconds(hms(time))-21600),
                     TRUE ~ (period_to_seconds(hms(time))+64799)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now there is a value (from_dawn) that is equal to 0 at six am and continues to increase until just before six. Easy to convert to hours starting from six am. Values seem higher in the center of the city. ‚ÄúIt‚Äôs six o‚Äôclock in the morning, do you know where your parents are?‚Äù üåî&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(stringsAsFactors = T)

bb &amp;lt;- attr(brussels, &amp;quot;bb&amp;quot;)
x &amp;lt;- df %&amp;gt;% 
  filter(lat &amp;lt; bb$ur.lat &amp;amp; lat &amp;gt; bb$ll.lat,
         lon &amp;gt; bb$ll.lon &amp;amp; lon &amp;lt; bb$ur.lon) %&amp;gt;% 
  mutate(hours = from_dawn/3600)

ggmap(brussels) + 
  stat_summary_2d(geom = &amp;quot;tile&amp;quot;, bins = 100, data = x, 
                  aes(x = lon, y = lat, z = hours), alpha = 0.7) + 
  scale_fill_gradientn(colors  =  viridis(4), 
                       guide = guide_legend(title = &amp;quot;hours since 6am&amp;quot;)) +
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;Location history data points around Brussels&amp;quot;,
    subtitle = &amp;quot;Color scale shows accuracy (low: blue, high: red)&amp;quot;,
    caption = &amp;quot;\nThis bin plot shows recorded positions 
    and their time of day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looking at it by year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bb &amp;lt;- attr(brussels, &amp;quot;bb&amp;quot;)
x &amp;lt;- df %&amp;gt;%
  filter(lat &amp;lt; bb$ur.lat &amp;amp; lat &amp;gt; bb$ll.lat,
         lon &amp;gt; bb$ll.lon &amp;amp; lon &amp;lt; bb$ur.lon,
         year &amp;gt; 2014)

ggmap(brussels) + facet_wrap(~year) +
geom_point(data = x, aes(x = lon, y = lat), alpha = 0.5, color = &amp;quot;#FC4E07&amp;quot;, size = .8) + 
  theme(legend.position = &amp;quot;right&amp;quot;) + 
  labs(
    x = &amp;quot;Longitude&amp;quot;, 
    y = &amp;quot;Latitude&amp;quot;, 
    title = &amp;quot;Location history data points in Brussels - by year &amp;quot;,
    caption = &amp;quot;\nA simple point plot shows recorded positions.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It would seem that I moved a lot in 2016 compared to the other years, but to that extent it does not look right. Let‚Äôs dig a little deeper in the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = x, aes(x = datetime, y = lat))+
  geom_line()+
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-30-google-location-tracking_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;960&#34; /&gt;
So clearly 2015 and 2017 have much less data. In 2017 it looks like I only used location services to three or four specific places in Brussels, but it is intriguing that there seems to be data throughout the year. And this in contrast with the end of 2018 when I switched the location tracking off.&lt;/p&gt;
&lt;p&gt;Whether Google still keeps track of my whereabouts is of course another matter.&lt;/p&gt;
&lt;p&gt;I still don‚Äôt know if my commute has gotten longer. I will try to find out in a next blog post.&lt;/p&gt;
</content>
      
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      <author>William Bourgeois</author>
      <guid>/about/</guid>
      <description></description>
      
      <content>&lt;p&gt;This is a &amp;ldquo;hello world&amp;rdquo; example website for the &lt;a href=&#34;https://github.com/rstudio/blogdown&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;blogdown&lt;/strong&gt;&lt;/a&gt; package. The theme was forked from &lt;a href=&#34;https://github.com/jrutheiser/hugo-lithium-theme&#34; target=&#34;_blank&#34;&gt;@jrutheiser/hugo-lithium-theme&lt;/a&gt; and modified by &lt;a href=&#34;https://github.com/yihui/hugo-lithium&#34; target=&#34;_blank&#34;&gt;Yihui Xie&lt;/a&gt;.&lt;/p&gt;
</content>
      
    </item>
    
  </channel>
</rss>