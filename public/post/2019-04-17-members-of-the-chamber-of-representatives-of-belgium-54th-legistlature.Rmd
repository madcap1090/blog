---
title: members of the chamber of representatives of Belgium, 54th legistlature
author: William Bourgeois
date: '2019-04-17'
slug: members-of-the-chamber-of-representatives-of-belgium-54th-legistlature
categories: []
tags:
  - Scraping
  - Belgian Politics
  - magick
  - purrr
---

For a country as small as Belgium 6 governments is a lot. Its maybe because we Belgians like to be governed and governed well. Why else would we pay for all of them, their administration and their parliaments? 

We also love our politicians, so we want to have lots of them. I also like them so I decided to do some NLP on their tweets. But there are so many of them that I searched for an objective criteria to subset them. What better selection then the members of the national chamber of representatives? We elected them to represent us all at the national level after all.

https://www.dekamer.be is the official website of the chamber. Two lists are interesting here. One has the current membres, the other one the complete list of members that at one moment or another were part of the parlaiment during the 54th legistlature following the 2014 elections. 

Let's scrape them.

```{r message=FALSE}
library("tidyverse")
library("rvest")
library("XML")
library("glue")
library("magick")
```

```{r}
url <- "http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&language=nl&cfm=/site/wwwcfm/depute/cvlist54.cfm"

table <- url %>% 
  read_html() %>% 
  html_nodes("#story > table") %>% 
  html_table()

table <- table[[1]] # extracting the dataframe

names(table) <- c("ln_fn", "party", "d1", "d2")
table <- table %>% 
  select(ln_fn, party) %>% 
  arrange(ln_fn)

head(table)

```

Funny that all the white spaces between "Beke" and "Wouter" cannot be seen. But they need to be cleaned.

```{r}

table <- table %>%
  mutate(ln_fn = (str_replace_all(ln_fn,"  +"," ")),
         ln_fn = trimws(table$ln_fn, which = "both"))

table$ln_fn <- str_replace_all(table$ln_fn,"  +"," ")
table$ln_fn <- trimws(table$ln_fn, which = "both") # for good measure
nrow(table)
```

150 members today with their current polical party. I'm goin to save that data, because after the elections of next month it will not be available for a long time.

```{r}
saveRDS(table, "~/R/blog/content/post/data/190417/reps_54_190417.rds")
```

And the parties are:

```{r}
table %>% 
  group_by(party) %>% 
  summarise(members=n()) %>% 
  arrange(desc(members))

```

We can also scrape the complete list of members of the 54th legistlature. 

```{r}
url <- "https://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&language=nl&cfm=cvlist54.cfm?legis=54&today=n"

table_54 <- url %>% 
  read_html() %>% 
  html_nodes("#story > table") %>% 
  html_table()

table_54 <- table_54[[1]] # extracting the dataframe

names(table_54) <- c("ln_fn", "d1", "d2", "d3")  
table_54 <- table_54 %>% 
  select(ln_fn) %>% 
  arrange(ln_fn)

table_54 <- table_54 %>%
  mutate(ln_fn = (str_replace_all(ln_fn,"  +"," ")),
         ln_fn = trimws(ln_fn, which = "both"))

table$ln_fn <- str_replace_all(table$ln_fn,"  +"," ")
table$ln_fn <- trimws(table$ln_fn, which = "both") # for good measure

```

This table does not mention the party, which is a pity because some members have changed since 2014.

Who has left ?

```{r message=FALSE}

table_54 %>% 
  anti_join(table) %>% 
  unlist() %>% 
  unname()

```

So indeed 29 representatives. But some left to work in the government and then came back when their party decided to leave government because of a city in northen Africa. Go figure. 

But it does make the identification of a tweet as a tweet being sent by a member of parlaiment a little bit more complicated because we need to match the exact date of the tweet to the periods the politician was seating. I have a feeling this will imply some stupid hardcoding also.

Let's have some fun first. Looking at the page of the current members of parlaiment, and more specifically at the url leading to the members page, their identifier can be discovered. For instance Mrs Almaci has id 01189 for the website. So once the xpath is known its is relatively easy to extract the indivdual member's webpage url. 

```{r}
url <- "http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&language=nl&cfm=/site/wwwcfm/depute/cvlist54.cfm"
url <- "http://www.dekamer.be/kvvcr/showpage.cfm?section=/depute&language=nl&cfm=cvlist54.cfm?legis=54&today=n"
page <- url %>% 
  read_html() %>% 
  html_nodes(xpath=  '//*[@id="story"]/table') 

# loop to get urls
urls <- tibble()

for(i in 1:nrow(table_54)){
  url <- xml_attrs(xml_child(xml_child(xml_child(page[[1]], i), 1), 1))
  url <- unname(url)
  name <- table_54$ln_fn[i]
  url <- cbind(name, url)
  urls <- rbind(urls, url)
}

table_ids <- urls %>%
  mutate(url = paste0("http://www.dekamer.be/kvvcr/", url))   # constructing the url
  
head(table_ids)

```

But there is a problem with matching the names and the ids.

```{r}

x <- table_ids

names <- tibble()

for (i in (1:nrow(x))){
  url <- x$url[i]
  fn_ln <- url %>%
    read_html() %>%
    html_nodes(xpath=  '//*[@id="myform"]/center/h2') %>% 
    html_text() %>% 
    as.data.frame()
  info <- cbind(fn_ln, url)
  names <- rbind(names, info)
}

names(names) <- c("fn_ln","url")

names <- names %>% 
  mutate(fn_ln =(str_replace_all(fn_ln,"  +"," ")))

head(names)

```


So we need to correct that the ids and fn_ln are correct so? so build a key based on the letters in the name of the person

```{r message=FALSE}

str_sort <- function(x)
  sapply(lapply(strsplit(x, NULL), sort), paste, collapse="")

w_key <- table_ids %>% 
  mutate(key = tolower(str_replace_all(name," ",""))) %>% 
  mutate(key = str_sort(key)) %>% 
  select(-url)

names_w_key <- names %>% 
  mutate(key = tolower(str_replace_all(fn_ln," ",""))) %>% 
  mutate(key = str_sort(key))

names <- names_w_key %>% 
  left_join(w_key) %>% 
  rename("ln_fn" = "name")

names %>% 
  select(-url) %>% 
  head()

```

Seems to work. Names are clean. Now the id code is needed. 

```{r}
# correct id

names <- names %>%
  mutate(id = gsub('^.*key=*|\\s*&lact.*$','', url))               # extract their id from the url
  #mutate(id = gsub('O','0',id))      # some of them have O instead of 0 but we need to keep them

```


So now we have in 'urls' the name and links to the personal webpage of the representatives on the chamber's website. Notice their id at the end of the url after 'cfm?key=' and before '&lat'. 

Let's get their mugshots. 


![Inspecting the code of the webpage](/img/20190417/inspect.png)


So the images are in http://www.dekamer.be/site/wwwroot/images/cv/


```{r}
# let's try purrr again

download_gifs <- function (name, id){
  url_pic <- glue("http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif")
  download.file(url_pic, destfile = glue("./data/190417/{name}.gif"), mode = "wb")
}

#download_gifs("test","01203")
```

So that seems to work. Unfortunately while scraping it is not infrequent to encounter coding inconsistencies. For instance member "00902" does not have a "00902.gif" his is "902.gif". Dirty data :rotating lights:, shame on you webmaster :wink:. 


```{r}
#table_ids %>% 
#  map2(.x = name, .y = id, .f = download_gifs)

# 
# table_ids$id[table_ids$id == "00902"] <- 902
# table_ids$id[table_ids$id == "06918"] <- 6918
# table_ids$id[table_ids$id == "06536"] <- 6536
# table_ids$id[table_ids$id == "00951"] <- 951
# table_ids$id[table_ids$id == "06325"] <- 6325
# table_ids$id[table_ids$id == "06885"] <- 6885
# table_ids$id[table_ids$id == "06665"] <- 6665
# table_ids$id[table_ids$id == "01123"] <- 1123
# table_ids$id[table_ids$id == "06843"] <- 6843

map2(.x = table_ids$name, .y = table_ids$id, .f = download_gifs)



```

So sometimes the 0 is used and sometimes it is just the value withhout leading 0. One possible solution is to enhance the 'download_gifs' function.

```{r}
download_gifs_with_0 <- function (name, id){
  url_pic <- glue("http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif")
  download.file(url_pic, destfile = glue("./data/190417/down_1/{name}.gif"), mode = "wb")
}

download_gifs_no_0 <- function (name, id){
  id <- as.numeric(id)
  url_pic <- glue("http://www.dekamer.be/site/wwwroot/images/cv/{id}.gif")
  download.file(url_pic, destfile = glue("./data/190417/down_2/{name}.gif"), mode = "wb")
}

```

Trying to simplify the use of the purrr function safely, by Lionel Henry who I thank for his work & presentation at the RUser2018 conference in Budapest.

```{r message=FALSE, warning=FALSE, include=FALSE}
dir.create("./data/190417/down_1")
map2(.x = names$ln_fn, .y = names$id, safely(.f = download_gifs_with_0, otherwise = NULL))
```

So using 'safely' the error are being skipped and we managed to download how many files?

```{r}
length(list.files("./data/190417/down_1"))
```

Only few missing. Let's use the other function.

```{r include=FALSE}
dir.create("./data/190417/down_2")
map2(.x = names$ln_fn, .y = names$id, safely(.f = download_gifs_no_0, otherwise = NULL))
```

```{r}
length(list.files("./data/190417/down_2"))
```

Hmm so now we have too many pictures (and the ones with no leading 0 seem older). See the aging of Mr Calvo: 
<center>
![Young Mr Calvo](/img/20190417/Calvo Kristof_young.gif) ![Old Mr Calvo](/img/20190417/Calvo Kristof_06128_old.gif)

</center>


And it seems some are still missing :unamused:.

Whose pics did were additionally obtained?

```{r}
new <- list.files("./data/190417/down_1")
old <- list.files("./data/190417/down_2")
new_pics <- setdiff(old, new)
new_pics

```

Nice guy, Georges. 

```{r message=FALSE, warning=FALSE, include=FALSE}
# copy the old and new to 'permanent' folder

lapply(new, function(x) file.copy(paste ("./data/190417/down_1", x , sep = "/"),  
                                        paste ("./data/190417",x, sep = "/"), recursive = FALSE,  copy.mode = TRUE))

lapply(new_pics, function(x) file.copy(paste ("./data/190417/down_2", x , sep = "/"),  
                                        paste ("./data/190417",x, sep = "/"), recursive = FALSE,  copy.mode = TRUE))

unlink("./data/190417/down_1", recursive = TRUE) # don't need those anymore
unlink("./data/190417/down_2", recursive = TRUE) # don't need those anymore

```

So are we missing some?

```{r}

fileslist <- list.files("./data/190417")
fileslist <-grep(".gif",fileslist,value=TRUE)
length(fileslist)

```

Looks promising. But double checking can not harm.

```{r}
names_list <- gsub(".gif","",fileslist)
setdiff(names_list, names$ln_fn)
```

:cool:


```{r include=FALSE}
# code for a patch work
# https://masalmon.eu/2017/03/19/facesofr/

dir.create("./data/190417/patch")

lapply(fileslist, function(x) file.copy(paste ("./data/190417", x , sep = "/"),
                                        paste("./data/190417/patch",x, sep = "/"), 
                                        recursive = FALSE,  copy.mode = TRUE))
```


```{r include=FALSE}
getwd()
setwd("./data/190417/patch")
length(list.files())
file.rename(list.files(), 
            paste0("g_", 1:179,".gif"))
```



```{r}
dir.create("./data/190417/cols")

getwd()
files <- dir("data/190417/patch", full.names = TRUE)
set.seed(1)
files <- sample(files, length(files))
gmp::factorize(length(files))

no_rows <- 11
no_cols <- 16

make_column <- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %>%
  image_append(stack = TRUE) %>%
    image_write(paste0("cols/", i, ".jpg"))
}


fun <- function(i, files, no_rows){
  image_read(files[(i*no_rows+1):((i+1)*no_rows)]) %>%
  image_append(stack = TRUE) %>%
    image_write(paste0("./data/190417/cols/", i, ".jpg"))
}

# could not really make wal function ;-(

for(i in (0:(no_cols-1))) {
fun(i, files, no_rows)
}

```

So we have the columns. Still need to bind them together.

```{r}
getwd()

x <- image_read(dir(".data/190417/cols/", full.names = TRUE))

img <- image_read(dir("data/190417/cols/", full.names = TRUE)) %>%
image_append(stack = FALSE) 

setwd("./files/20190417")
getwd()
image_write(img,"2019-04-17-faces_of_54.jpg")

```
```{r}
unlink("./data/190417/patch", recursive = TRUE) # don't need those anymore
```

<center>
![Old Mr Calvo](/img/20190417/2019-04-17-faces_of_54.jpg){width=500px height=900px} 

</center>


![Old Mr Calvo](img/20190417/2019-04-17-faces_of_54.jpg){width=300px height=900px} 

ghhh


So looking at the picture I will let you judge how diverse the picture looks. Less diverse than our national soccer team, that is for sure. But that is indeed a very small sample of Belgians. 

What I can says is that given my age, gender and skin color, I would fit right in. 

Wondering what the 55 legislature will look like. Will keep you posted.

Wait a minute. Did I say belgian national soccer teams? Hold my beer.

```{r}

# for(i in (1:10000)){
# print(i)
# url_pic <- glue("https://belgianfootball.s3.eu-central-1.amazonaws.com/s3fs-public/rbfa/img/players/internationals/football/men/{i}.jpg")
# safely(download.file(url_pic, destfile = glue("./content/post/data/190417/{i}.jpeg", mode = "wb")),otherwise = NULL)
# }

```

