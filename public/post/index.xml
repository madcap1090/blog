<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on bad to the code</title>
    <link>/post/</link>
    <description>Recent content in Posts on bad to the code</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/madcap1090&#34;&gt;William Bourgeois&lt;/a&gt; 2019</copyright>
    <lastBuildDate>Fri, 17 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RAMMSTEIN By Rammstein</title>
      <link>/post/rammstein-by-rammstein/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/rammstein-by-rammstein/</guid>
      <description>Today Rammstein released ‘RAMMSTEIN’, first studio album since 10 years.
Jetzt geht es mir gut, ja!album cover - RAMMSTEIN
I love it. Gave me a lot of pleasure today.
Time for a small analysis. I got the code from Peer. And from plzbeemyfriend who is a cool dude, and made some insightful graphs based on Spotify data.
library(spotifyr) # install.packages(&amp;quot;spotifyr&amp;quot;)library(tidyverse)Spotify also has an API and some interesting information can be downloaded from it.</description>
    </item>
    
    <item>
      <title>happy faces in a bucket</title>
      <link>/post/happy-faces-in-a-bucket/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/happy-faces-in-a-bucket/</guid>
      <description>Remember we downloaded the pictures of our parliamentarians and made a patchwork with them? I looked for a while how to analyse them for gender, age and skin color. One obvious candidate was Rekognition from AWS if only because the instances at my workplace decided to use AWS services. Getting a little bit more familiar with using these seemed therefore like a good choice.
I searched for R packages to use Rekognition with, but did not find any.</description>
    </item>
    
    <item>
      <title>Belgian parliamentarians tweets</title>
      <link>/post/belgian-parliamentarians-tweets/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/belgian-parliamentarians-tweets/</guid>
      <description>In the last post we were pretty successful in getting our parliamentarians Twitter handles. We can now use these to download their tweets.
The twitter API allows to download 3200 tweets per handle. This means that we will not be able to download all tweets of all parliamentarians from the last five years, because some of them tweeted more than 3200 during that time period. But there will be a fair amount.</description>
    </item>
    
    <item>
      <title>Belgian parliamentarians Twitter accounts</title>
      <link>/post/belgian-parliamentarians-twitter-accounts/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/belgian-parliamentarians-twitter-accounts/</guid>
      <description>Now that we can scrape the names of the parliamentarians of the 54th legislature, we can try to find their Twitter accounts too.
Let’s start by reconstructing the list. Then we can search Twitter for their accounts handles. A bit of grunt work and no visuals in this post, but it is needed to harvest parlaimentarians’ tweets soonish.
Starting with attaching libraries, and in particular ‘rtweet’.
#librarieslibrary(&amp;quot;tidyverse&amp;quot;)library(&amp;quot;rvest&amp;quot;)library(&amp;quot;glue&amp;quot;)library(&amp;quot;rtweet&amp;quot;)library(&amp;quot;purrr&amp;quot;)# the ones seating currently, with their (current) partyurl &amp;lt;- paste0(&amp;quot;http://www.</description>
    </item>
    
    <item>
      <title>members of the chamber of representatives of Belgium, 54th legistlature</title>
      <link>/post/members-of-the-chamber-of-representatives-of-belgium-54th-legistlature/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/members-of-the-chamber-of-representatives-of-belgium-54th-legistlature/</guid>
      <description>For a country as small as Belgium 6 governments is a lot. It’s maybe because we Belgians like to be governed and governed well. Why else would we want to pay for 6 governments, their administration and their parliaments?
We also love politicians, so we want to have many. I also like politicians and decided to do some NLP on their tweets. But since there are a significant number of politicians in Belgium I searched for an objective criteria to define a subset.</description>
    </item>
    
    <item>
      <title>am I getting slower going to work?</title>
      <link>/post/am-i-getting-slower-going-to-work/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/am-i-getting-slower-going-to-work/</guid>
      <description>I got a bit distracted writing the last post. What I want to find out is, based on my Google location history, how fast I bike to work and if this has changed over time.
Attaching libraries
library(&amp;quot;tidyverse&amp;quot;)library(&amp;quot;lubridate&amp;quot;)library(&amp;quot;glue&amp;quot;)library(&amp;quot;purrr&amp;quot;)library(&amp;quot;ggmap&amp;quot;)library(&amp;quot;ggplot2&amp;quot;); theme_set(theme_minimal())And loading the data
# the code to convert your location data to a data frame:# see last post too# data &amp;lt;- fromJSON(&amp;quot;./data/Location History.</description>
    </item>
    
    <item>
      <title>google location tracking</title>
      <link>/post/google-location-tracking/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/google-location-tracking/</guid>
      <description>Biking to work this week I was wondering if I had not gotten slower and if my commute was not taking longer than before. Not being a regular user of Strava or a similar app, I wondered if I could find an answer to that question using my Google location history.
So I downloaded the data, that comes in json format, and had a go at it. You can download your Google location data from your Google account.</description>
    </item>
    
  </channel>
</rss>