---
title: am I getting slower going to work?
author: William Bourgeois
date: '2019-04-13'
slug: am-i-getting-slower-going-to-work
categories: 
  - geocoding
tags:
  - Geocoding
  - Google
---

I got a bit distracted writing the last post. What I want to find out is, based on my Google location history, how fast I bike to work and if this has changed over time.

Attaching libraries

```{r message=FALSE}
library("tidyverse")
library("lubridate")
library("glue")
library("purrr")
library("ggmap")
library("ggplot2"); theme_set(theme_minimal())
```

And loading the data

```{r}
# the code to convert your location data to a data frame:
# see last post too
# data <- fromJSON("./data/Location History.json") # extracts a list
# locations <- data$locations # and the list contains a dataframe

location <- readRDS("~/R/blog/content/post/data/location.rds")

df <- location %>% 
  mutate(datetime = as.POSIXct(as.numeric(timestampMs)/1000, origin = "1970-01-01")) 

df <- df %>% 
  mutate(lat   = latitudeE7/1e7,
         lon   = longitudeE7/1e7,
         time  = strftime(datetime, format = "%H:%M:%S"),
         date  = date(datetime),
         year  = year(datetime),
         month = month(datetime),
         wday  = wday(datetime))
```

So what do we have here?

```{r}
nrow(df)                   # rows
length(unique(df$date))    # days
min(unique(df$date))       # first day
max(unique(df$date))       # last day

```

Plotted:

```{r}
ggplot(data = df, aes(x = datetime, y = lat))+
 geom_line()+
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
    labs(title="commuting slower?",
       subtitle = "latitude tracking 2014 - 2018",
       x = "days",
       y = "latitude")
```


I changed jobs in September 2014, my first working day at my current job was 15/09/2014.

Let's see which days I was working there. The dataframe "work", then contains all the data points from where I am at work.

```{r}
work <- df %>% 
  filter(date > "2014-09-14") %>%
  filter(round(lat,3) == 50.557) %>% 
  filter(round(lon,2) == 5.18) %>% # a little less accuracy on the longitude
  mutate(homework = "work") %>% 
  mutate(am_pm = case_when(am(datetime) ~ "am",
                           TRUE ~ "pm"))

length(unique(work$date)) 
```

```{r}
ggplot(data = work, aes(x = datetime, y = lat))+
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())+
  labs(y = "latitude", 
    title = "lattitude between home and work by day")
```

So that would mean that in my data set I have 406 working days and the data that comes along with it. 
Since at this point I am not interested in the data from days I was not working, these can be filtered out. 

```{r}
home <- df %>%
  filter(round(lat,3) != 50.557) %>% 
  filter(round(lon,2) != 5.18) %>%
  mutate(homework = "not_work") %>% 
  filter(date %in%(unique(work$date))) %>% 
  mutate(am_pm = case_when(am(datetime) ~ "am",
                           TRUE ~ "pm"))

home_work <- rbind(home, work) %>% 
  arrange(datetime)
```

What days at work got tracked? 

```{r}
length(unique(home_work$date)) # workdays
min(unique(home_work$date))    # first day
max(unique(home_work$date))    # last day
```

To calculate the time of my daily commute I have to find the time between I last was at home and the time I arrived at work. 

The latitude changes during a typical working day look like this (although this one is particularly boring :unamused:).

```{r}
day <- df %>% 
  filter(date == "2014-12-23") 

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = "latitude", 
    title = "23/12/2014 - another day at the office")

```

And if we look at the first hours of the day and arriving at work:

```{r}
day <- df %>% 
  filter(date == "2014-12-23") %>% 
  filter(time > "07:00:00",
         time < "09:30:00")

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = "Latitude", 
    title = "23/12/2014 - zooming in on arriving at work")

```

So the time spent in the commute is the time first at around 50.560 latitude (itw) minus the last time at around 50.580 latitude (oth), and that for the time period of let's say between 7am and 9.30am.

```{r}
oth <- day %>% 
  filter(lat < 50.5756) %>% 
  filter(time == min(time)) %>% 
  select(time) %>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"))

itw <- day %>% 
  filter(lat < 50.558) %>% 
  filter(time == min(time)) %>% 
  select(time)%>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"))

commute_time <- difftime(itw$time,oth$time, units = c("mins")) #9.93 minutes
class(commute_time)
as.numeric(commute_time)
```

2 minutes is a bit too fast. The problem is that the first time out of the house, on that particular date, is recorded pretty late. So the last time in the house (ith) is the one that is needed. Also because starting around 30/01/2016 a strange pattern is emerging

```{r}
day <- home_work %>%
  filter(date == "2018-07-03") %>% 
  filter(time > "08:00:00",
         time < "09:30:00")

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = "latitude", 
    title = "'bilocation' pattern")
```

And that pattern did not happen before February 2016. For instance "2016-01-08" gives.

```{r}
day <- home_work %>%
  filter(date == "2016-01-08") %>% 
  filter(time > "07:30:00",
         time < "09:30:00")

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line()+
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = "latitude", 
    title = "before February 2016")
```

A collegue came up with the hypothesis that it was my computer at home that was messing up my phone location data, which was a great idea, but in fact it was my tablet. 

I bought it on 30/01/2016, and both it's location data and my phone location data are merged ever since. Which is kind of surprising or rather dissapointing. 

Google is serving us dirty data in the location history. I cannot imagine it does not distinguish between my devises.

```{r}
oth <- day %>% 
  filter(lat < 50.5756) %>% 
  filter(time == min(time)) %>% 
  select(time) %>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"))

# the last time in the house
ith <- day %>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S")) %>% 
  filter(time < oth$time) %>% 
  filter(time == max(time))%>% 
  select(time) %>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"))


itw <- day %>% 
  filter(lat < 50.557) %>% 
  filter(time == min(time)) %>% 
  select(time)%>% 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"))

commute_time <- difftime(itw$time,ith$time, units = c("mins")) #9.93 minutes
class(commute_time)
as.numeric(commute_time)
```

17 minutes on the other hand seems a lot. But the data and calculations look correct to me. One explanation could be that sometimes there is a big delay in reporting the arrival time. Like on April 17 2015, where arrival was recorded after 12am.

```{r}
day <- df %>% 
  filter(date == "2015-04-17") 

ggplot(data = day, aes(x = datetime, y = lat)) +
  geom_line() + 
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(y = "latitude", 
    title = "April 17 2015")

```

So it's time to do some more data cleaning, and select dates that have data from both work and home between 7 and 9:30am.

```{r}
keep_dates <- home_work %>% 
  filter(time > "07:00:00",
         time < "09:30:00") %>%
  plyr::count(c('date', 'homework')) %>% 
  spread(homework, freq) %>% 
  filter(work > 0) %>% 
  select(date)
glue("so there are now {nrow(keep_dates)} days to be analysed")
```

Let's define a function to do it.

```{r}
# building the function
get_time <- function(x_date){
  day <- home_work %>%
    filter(date ==  x_date) %>% 
    filter(time > "07:30:00",
           time < "09:30:00")
  oth <- day %>% 
    filter(lat < 50.5756) %>% 
    filter(time == min(time)) %>% 
    select(time) %>% 
    mutate(time = as.POSIXct(time, format = "%H:%M:%S")) %>% 
    slice(1) # making sure one value is returned
  
  ith <- day %>% 
    mutate(time = as.POSIXct(time, format = "%H:%M:%S")) %>% 
    filter(time < oth$time) %>% 
    filter(time == max(time))%>% 
    select(time) %>% 
    mutate(time = as.POSIXct(time, format = "%H:%M:%S"))
  
  if(nrow(ith) == 0) {ith <- oth} 
  
  itw <- day %>% 
    filter(lat < 50.558) %>% 
    filter(time == min(time)) %>% 
    select(time)%>% 
    mutate(time = as.POSIXct(time, format = "%H:%M:%S"))%>% 
    slice(1) # making sure one value is returned
  
  x <- difftime(itw$time,ith$time, units = c("mins"))
  x <- round(as.numeric(x),2)
  return(x)
}
```

I had a struggle with purrr's map_df() , but map_dbl() also does the trick

```{r}
result <- map_dbl(keep_dates$date, get_time) %>% 
  as.data.frame() %>% 
  rename("minutes" = ".") %>% 
  cbind(keep_dates) %>% 
  select(date, minutes)

head(result)
```

```{r}
max(result$minutes)
min(result$minutes)
```

```{r message=FALSE, warning=FALSE}
ggplot(result, aes(x = date, y = minutes)) +
  geom_bar(stat = "identity")+ 
  scale_y_continuous(limits = c(0, 65)) +
  labs(y = "minutes to work", 
    title = "2015 - 2018")
```

2018 seems to have the cleanest data at this point. I sometimes walk to work or take the bus or the car. All of these take me more time than biking to work. There are five trafic lights on the way and I tend to stop for trafic lights when they are red. So the trafic ligths might explain much of the variance.  

A bike ride would not take more than twenty minutes, and surely not less than 5.

```{r}
r_2018 <- result %>% 
  filter(year(date) == 2018) %>% 
  filter(minutes < 20,
         minutes > 5)

ggplot(r_2018, aes(x = date, y = minutes)) +
  geom_bar(stat = "identity") +
  labs(y = "minutes to work", 
    title = "2018")
``` 

```{r}
round(mean(r_2018$minutes),2)
```

So that would then be around 12 minutes. I still need to time my current commutes for a while to see if I got slower. 

I hoped for a bit cleaner data and the possibility to easyly compare the evolution of the time spent commuting over several years. But I'll take the 12.18 minutes for now. 

Finally I wanted to share the "patés" with you. Not often enough part of the team takes a break and walks around the office block, and those we call doing a "paté" (= block). They say walking meetings are in these days.

I was looking to see how many of them we are doing, but as you will see below the datapoints are mostly centered on our office building itself. And I cannot see how I can construct a pattern around it representing the "patés". 

```{r}
secrets <- readRDS("~/R/geo/secret/secrets.rds")
key <- secrets$key[1]
register_google(key = key)

zoom <- get_map(location = c(lon = 4.306, lat = 50.8545), zoom = 19, maptype = "satellite")
```



```{r fig.height=10, fig.width=10}
df <- readRDS("~/R/blog/content/post/data/location_509.rds") %>% 
  filter(year != 2017)

ggmap(zoom) + 
  geom_point(data = df, aes(x = lon, y = lat),
             alpha = 0.7, color = "#FC4E07", size = .8) + 
  facet_wrap(~year) +
  theme(legend.position = "right") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(
    x = "Longitude", 
    y = "Latitude", 
    title = "always happy @work",
    caption = "\n removed 2017 because there were few data points.")

```

It seems to me all the data is a bit off. 2014 to 2016 a bit or a lot shifted to the left, and 2018 just a tad too much to the left. 

But still. Welcome to the panopticon. 