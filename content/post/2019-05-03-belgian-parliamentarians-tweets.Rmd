---
title: Belgian parliamentarians tweets
author: William Bourgeois
date: '2019-05-03'
slug: belgian-parliamentarians-tweets
categories: []
tags:
  - Belgian politics
  - Twitter
---

In the last post we were pretty successful in getting our parliamentarians Twitter handles. We can now use these to download their tweets. 

The twitter API allows to download 3200 tweets per handle. This means that we will not be able to download all tweets of all parliamentarians from the last five years, because some of them tweeted more than 3200 during that time period. But there will be a fair amount. 

These tweets will also have to be 'cleaned' of special characters like emojis and links in order to analyse them further without the different packages choking on them. 

As usually first the libraries and options:

```{r message=FALSE, warning=TRUE, results=FALSE}
library("tidyverse")
library("gmp")
library("glue")
library("rtweet")
library("cld2") 
library("textcat")
library("qdapRegex")
library("xml2")
library("rvest")
library("lubridate")

# options 

options(scipen=999)
stringAsFactors = FALSE
```
And here is the function to get the tweets (for now just 1 for testing, because 3200 tweets takes a while):

```{r}
get_handle_tweets <- function(handle) {
  tweets_handle <<- get_timeline(handle, n=1)
  n <- nrow(tweets_handle)
    print(glue("{handle} {n} tweets added"))
}

```

And a function to clean the tweets:

```{r}
to_byte <- function (x) {
  Encoding(x) <- "latin1"
  iconv(x, "latin1", "ASCII", "byte")
}

```

Here are the handles:

```{r}

twitter_users <- readRDS("~/R/blogs/content/post/data/20190502/twitter_users.rds")

```
A test

```{r}
twitter_users$screen_name[3]
```

It's not stictly needed since we already know the correspondence between name and handle ('screen_name'), but it's fun to try map2_df. A test with two tweets:

```{r message=FALSE, warning=FALSE}
get_handle_tweets <- function(screen_name, ln_fn) {
  get_timeline(screen_name, n=2) %>% 
    mutate(ln_fn = ln_fn)
}

tweets <- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL))
dim(tweets)
```

Now might be a good time to talk about rate limits. We are limited to go 3200 tweets in the past per handle, but we have also temporary limits to the calls we can do with the API. 

```{r}
limits <- rate_limits()
head(limits)
```

In total there are 149 limits, we can access, amongst other things, how much remains and when the limit will be reset. Here are some of the limits:

```{r}
head(limits$query, 20)

```

At this point we need to keep an eye on limits tweets (#49) and limits queries (#11).

```{r}
limits %>% select(limit, query, remaining, reset) %>% 
  filter(query ==  "application/rate_limit_status"|
          query ==  "statuses/user_timeline") %>% 
  mutate(reset = round(reset, 2))

```

We are searching 160 users and the rate limit for searching user timelines is 900, so we should be fine. But be aware that your limit searches are limited also (180 searches counted by individual limit in batches of 15 minutes). 

At a certain point in time it might be useful to periodically query certain limits and to then pause the code in order not to produce interuptions.

How well did our test go? Did we get tweets from everyone?

```{r}
setdiff(twitter_users$ln_fn, tweets$ln_fn)
```
Nice. The results look ok too. Will now launch the bigger batch (3200) while out playing some :badminton: 


```{r}
twitter_users <- twitter_users %>% 
  arrange(screen_name) %>% 
  distinct(screen_name, .keep_all = TRUE) # removing doubles if present

get_handle_tweets <- function(screen_name, ln_fn) {
  # print(screen_name) this can be used to see the advancement
  get_timeline(screen_name, n=3200) %>% 
    mutate(ln_fn = ln_fn)
}

system.time(tweets <- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL)))
dim(tweets)

```

```{r}
saveRDS(tweets, "./data/20190503/tweets.rds")
```

Cool, so about 260K tweets. 

But as already mentioned these are some of the tweets from people who at some time were in the 54th legistlature. They are not always a tweet from a person actually seating in parliament.

This wikipedia page https://nl.wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019) has a good overview of the changes that occured since May 2014.  



A few have also changed party or became independent. The table that was used to obtain the list of parliamentariens's names, language and party, can be transformed into a reference table that we can join to the tweets for further analysis. 

```{r}
names <- readRDS("./data/190417/names.rds")
party_less <- names %>% 
  filter(is.na(party))
```

The text on the wikipedia page contains the information that is needed, but I wonder how easy it will be to use. We can try, let's see what we get.

```{r}
url <- "https://nl.wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019)" 

wiki_table_source<- url %>% 
  read_html() %>%
  html_node(xpath = '//*[@id="mw-content-text"]/div/table[4]')  %>%
  html_table(fill = TRUE)

head(wiki_table_source)

```

The nice thing is that additional information like the voting disctrict was obtained. Using the comments ("Opmerkingen"), will probaly be more time consuming than hardcoding the changes, but I think it will be more fun ;-)

```{r}
#print(wiki_table$Opmerkingen, na.print = "")

wiki_table_source %>% 
  filter(!is.na(Opmerkingen)) %>% 
  select(Opmerkingen)

```


'Vervangt' means 'replaces', so these are members that replaced someone who took on another mandate. 'Werd' means 'was', so these were replaced.

```{r}
wiki_table <- wiki_table_source %>% 
  filter(!is.na(Opmerkingen)) %>% 
  mutate(first_word = str_extract(Opmerkingen,"(\\w+)"))
```

In the comments (Opmerkingen) there are up to three dates that we need. A first step would be to change the month names in numbers. And then extract all the numbers into a list.

```{r}
wiki_table <- wiki_table %>% 
  mutate(Opmerkingen = gsub("januari", 1, Opmerkingen),
         Opmerkingen = gsub("februari", 2, Opmerkingen),
         Opmerkingen = gsub("maart", 3, Opmerkingen),
         Opmerkingen = gsub("april", 4, Opmerkingen),
         Opmerkingen = gsub("mei", 5, Opmerkingen),
         Opmerkingen = gsub("juni", 6, Opmerkingen),
         Opmerkingen = gsub("juli", 7, Opmerkingen),
         Opmerkingen = gsub("augustus", 8, Opmerkingen),
         Opmerkingen = gsub("september", 9, Opmerkingen),
         Opmerkingen = gsub("oktober", 10, Opmerkingen),
         Opmerkingen = gsub("november", 11, Opmerkingen),
         Opmerkingen = gsub("december", 12, Opmerkingen)) %>%
    mutate(digits = str_extract_all(Opmerkingen,"([0-9]+)")) %>% #'+' keeps them together
  filter(first_word != "De") # this one has no date 



inspect <-wiki_table$digits
inspect[[20]]

```
It will be more difficult to handle the digits if days and months smaller than 10 do not have a leading 0. So one needs to be added, before concatenating all the numbers

```{r}
for (i in (1:length(inspect))){
  for (j in (1:length(inspect[[i]]))){
    if (nchar(inspect[[i]][j]) == 1) {inspect[[i]][j] <- paste0("0",inspect[[i]][j])}
  }
  inspect[[i]] <- paste0(inspect[[i]], collapse = "")
  print(inspect[[i]])
}
# pure poetry if you ask me

con_dates <- data.frame("condate" = unlist(inspect))
wiki_table <- wiki_table %>% 
  cbind(con_dates) %>% 
  select(-digits)
```

Now we can extrat the dates, but one problem still remains, on wikipedia some years are not repeated for certain time periods:

```{r}
wiki_table$Opmerkingen[28]
as.character(wiki_table$condate[28])
```

A little bit more work is needed.

```{r}
wiki_table <- wiki_table %>% 
  mutate(date_1 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,1,8),
                  paste0(substr(condate,1,4),
                    substr(condate,str_locate(condate, "201"),
                            str_locate(condate, "201") + 3))
                  )
         ) %>% 
   mutate(date_2 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,9,16),
                  paste0(
                    substr(condate,str_locate(condate, "201")-4,
                            str_locate(condate, "201") + 3))
                  )
         ) %>% 
   mutate(date_3 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,17,24),
                  "")
         ) %>% 
  select(-condate)


wiki_table <- wiki_table %>% 
  mutate(date_1 = dmy(as.numeric(date_1)),
         date_2 = dmy(as.numeric(date_2)),
         date_3 = dmy(as.numeric(date_3)),
                )

```

There are other possibilities, but here we will use a table with one line per period a person seated for a party. To later use in the analysis of the tweets collected. In that table there will be one start date and one end date. A good start is assuming everyone started at "2014-06-19" and ended at "2019-05-31", and then making corrections afterwards. 

We can start by consolidating our tables.

```{r}
setdiff(names(wiki_table),names(wiki_table_source))
```
```{r}
wiki_table <- wiki_table %>% 
  rbind(wiki_table_source %>% 
          filter(is.na(Opmerkingen) 
                 | Volksvertegenwoordiger == "Jadin, Kattrin Kattrin Jadin") %>%
          mutate(first_word = "",
                 date_1 = as.Date("2001-01-01"),
                 date_2 = as.Date("2001-01-01"),
                 date_3 = as.Date("2001-01-01"))
                              )

```


Aw, shoot did not see the names are funky.

```{r}
head(wiki_table$Volksvertegenwoordiger)
```

Maybe we can join on the concatenation of letters.

```{r}
x <- wiki_table %>% 
  mutate(join = str_remove_all(Volksvertegenwoordiger," "),
         join = str_remove_all(join,","),
         join = substr(join,1, nchar(join)/2))

y <- names %>% 
  mutate(join = str_remove_all(ln_fn," "))

z <- y %>% 
  left_join(x)

```
```{r}

test <- z %>% 
  filter(!is.na(Volksvertegenwoordiger)) %>% 
  mutate(test = "test")
  
missing <- wiki_table %>% 
  left_join(test %>% 
              select(Volksvertegenwoordiger, test)) %>% 
  filter(is.na(test))

missing$Volksvertegenwoordiger

```

Yes I've got myself in a pickle again. Three missing. The join field for them should be VandeVeldeRobert, JirofléeKarin and, FernandezFernandezJulie. Instead of VandeVeldeRob, JirofléeKarine and Fernandez-FernandezJulie.

We can follow how they are spelled on dekamer.be: Robert Van de Velde, Karin Jiroflée, Julie Fernandez Fernandez

```{r}

x[x$join == "VandeVeldeRob",]$join <- "VandeVeldeRobert"
x[x$join == "JirofléeKarine",]$join <- "JirofléeKarin"
x[x$join == "Fernandez-FernandezJulie",]$join <- "FernandezFernandezJulie"

y <- names %>% 
  mutate(join = str_remove_all(ln_fn," "))

z <- y %>% 
  left_join(x)


test <- z %>% 
  filter(!is.na(Volksvertegenwoordiger)) %>% 
  mutate(test = "test")
  
missing <- wiki_table %>% 
  left_join(test %>% 
              select(Volksvertegenwoordiger, test)) %>% 
  filter(is.na(test))

missing$Volksvertegenwoordiger


```

Yeah! So now we have em all we can give em a default start date and a default end date.

```{r}
reps54 <- z %>% 
  mutate(start_date = as.Date("2014-06-19"),
         end_date = as.Date("2019-05-31"))
```

Maybe we can start with those who only have one 'date_1'? Let's have a look.

```{r}
one_date <- reps54 %>% 
  filter(!is.na(date_1) &
           is.na(date_2))

unique(one_date$first_word)
```

"Voorzitter" is the president of the chamber. Not interested in this for now, so no change to be made. "Vanaf" seems to indicate a change of party and/or party name. What happened to the [FDF](https://en.wikipedia.org/wiki/D%C3%A9FI)? Seems to have been a name change. 

In the data that come from the official website these members are already 'Défi' in the field 'Party'. We can work on the field 'fractie' (party) but I doubt it will be needed. 

```{r}

fdf <- one_date %>% 
  filter(first_word == "Vanaf") %>% 
  mutate(end_date = ymd(date_1) -days(1)) %>% 
  rbind(one_date %>% 
          filter(first_word == "Vanaf") %>% 
          mutate(start_date = date_1,
                 Fractie = "Défi"))

one_date <- one_date %>% 
  filter(first_word != "Vanaf") %>% 
  rbind(fdf)

```

So that takes care of 'Vanaf', now for "Vervangt" (replaces). Which looks pretty straightforward. The date_1 just needs to replace the start date.
```{r}
replaces <- one_date %>% 
  filter(first_word == "Vervangt") %>% 
  mutate(start_date = date_1)

one_date <- one_date %>% 
  filter(first_word != "Vervangt") %>% 
  rbind(replaces)

```
In this case 'Zetelt' means the person became independent. I doubt it will make a big difference to make the change for one person, but for the sake of precision, here is the correction.

```{r}
zetelt <- one_date %>% 
  filter(first_word == "Zetelt") %>% 
  mutate(end_date = ymd(date_1) -days(1)) %>% 
  rbind(one_date %>% 
          filter(first_word == "Zetelt") %>% 
          mutate(start_date = date_1,
                 Fractie = "ONAFH"))

one_date <- one_date %>% 
  filter(first_word != "Zetelt") %>% 
  rbind(zetelt)
```

Now just need to bind them and go to the next batch.

```{r}

reps54 <- reps54 %>% 
  filter(is.na(date_1) | date_1 == "2001-01-01"
         | (date_1 != "2001-01-01" & date_2 != "2001-01-01"))%>% 
  rbind(one_date)

```

two_dates 

```{r}
two_dates <- reps54 %>% 
  filter(!is.na(date_1) &
           !is.na(date_2) &
           is.na(date_3))

unique(two_dates$first_word)
```

There are now three replacements (Vervangt) with two dates in the comment phrase. It is getting complicated, but fortunately they seem to be structured the same way. 
```{r}
two_dates %>% filter(first_word == "Vervangt") %>% 
  select(Opmerkingen)

```

So we are looking at these parliamantarians:

```{r}
two_dates %>% filter(first_word == "Vervangt") %>% 
  select(fn_ln)
```

They just enter the parliament at date_1, that is easy, but there is more information in the remarks. Easy part first (EPF), low hanging fruits, quick impacts and what have you.
```{r}
vervangt <- two_dates %>% 
  filter(first_word == "Vervangt") %>% 
  mutate(start_date = date_1)

x <- two_dates %>% 
  filter(first_word != "Vervangt") %>%
  rbind(vervangt)

```

