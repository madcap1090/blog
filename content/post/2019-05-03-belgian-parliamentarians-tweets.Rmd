---
title: Belgian parliamentarians tweets
author: William Bourgeois
date: '2019-05-03'
slug: belgian-parliamentarians-tweets
categories: []
tags:
  - Belgian politics
  - Twitter
---

In the last post we were pretty successful in getting our parliamentarians Twitter handles. We can now use these to download their tweets. 

The twitter API allows to download 3200 tweets per handle. This means that we will not be able to download all tweets of all parliamentarians from the last five years, because some of them tweeted more than 3200 during that time period. But there will be a fair amount. 

These tweets will also have to be 'cleaned' of special characters like emojis and links in order to analyse them further without the different packages choking on them. 

As usually first the libraries and options:

```{r message=FALSE, warning=TRUE, results=FALSE}
library("tidyverse")
library("gmp")
library("glue")
library("rtweet")
library("cld2") 
library("textcat")
library("qdapRegex")
library("xml2")
library("rvest")
library("lubridate")

# options 

options(scipen=999)
stringAsFactors = FALSE
```
And here is the function to get the tweets (for now just 1 for testing, because 3200 tweets takes a while):

```{r}
get_handle_tweets <- function(handle) {
  tweets_handle <<- get_timeline(handle, n=1)
  n <- nrow(tweets_handle)
    print(glue("{handle} {n} tweets added"))
}

```

And a function to clean the tweets:

```{r}
to_byte <- function (x) {
  Encoding(x) <- "latin1"
  iconv(x, "latin1", "ASCII", "byte")
}

```

Here are the handles:

```{r}

twitter_users <- readRDS("~/R/blogs/content/post/data/20190502/twitter_users.rds")

```
A test

```{r}
twitter_users$screen_name[3]
```

It's not stictly needed since we already know the correspondence between name and handle ('screen_name'), but it's fun to try map2_df. A test with two tweets:

```{r message=FALSE, warning=FALSE}
get_handle_tweets <- function(screen_name, ln_fn) {
  get_timeline(screen_name, n=2) %>% 
    mutate(ln_fn = ln_fn)
}

tweets <- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL))
dim(tweets)
```

Now might be a good time to talk about rate limits. We are limited to go 3200 tweets in the past per handle, but we have also temporary limits to the calls we can do with the API. 

```{r}
limits <- rate_limits()
head(limits)
```

In total there are 149 limits, we can access, amongst other things, how much remains and when the limit will be reset. Here are some of the limits:

```{r}
head(limits$query, 20)

```

At this point we need to keep an eye on limits tweets (#49) and limits queries (#11).

```{r}
limits %>% select(limit, query, remaining, reset) %>% 
  filter(query ==  "application/rate_limit_status"|
          query ==  "statuses/user_timeline") %>% 
  mutate(reset = round(reset, 2))

```

We are searching 160 users and the rate limit for searching user timelines is 900, so we should be fine. But be aware that your limit searches are limited also (180 searches counted by individual limit in batches of 15 minutes). 

At a certain point in time it might be useful to periodically query certain limits and to then pause the code in order not to produce interuptions.

How well did our test go? Did we get tweets from everyone?

```{r}
setdiff(twitter_users$ln_fn, tweets$ln_fn)
```
Nice. The results look ok too. Will now launch the bigger batch (3200) while out playing some :badminton: 


```{r}
twitter_users <- twitter_users %>% 
  arrange(screen_name) %>% 
  distinct(screen_name, .keep_all = TRUE) # removing doubles if present

get_handle_tweets <- function(screen_name, ln_fn) {
  # print(screen_name) this can be used to see the advancement
  get_timeline(screen_name, n=3200) %>% 
    mutate(ln_fn = ln_fn)
}

system.time(tweets <- map2_df(twitter_users$screen_name,twitter_users$ln_fn, 
             possibly(get_handle_tweets, otherwise = NULL)))
dim(tweets)

```

```{r}
saveRDS(tweets, "./data/20190503/tweets.rds")
```

Cool, so about 260K tweets. 

But as already mentioned these are some of the tweets from people who at some time were in the 54th legistlature. They are not always a tweet from a person actually seating in parliament.

This wikipedia page https://nl.wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019) has a good overview of the changes that occured since May 2014.  



A few have also changed party or became independent. The table that was used to obtain the list of parliamentariens's names, language and party, can be transformed into a reference table that we can join to the tweets for further analysis. 

```{r}
names <- readRDS("./data/190417/names.rds")
party_less <- names %>% 
  filter(is.na(party))
```

The text on the wikipedia page contains the information that is needed, but I wonder how easy it will be to use. We can try, let's see what we get.

```{r}
url <- "https://nl.wikipedia.org/wiki/Kamer_van_volksvertegenwoordigers_(samenstelling_2014-2019)" 

wiki_table_source<- url %>% 
  read_html() %>%
  html_node(xpath = '//*[@id="mw-content-text"]/div/table[4]')  %>%
  html_table(fill = TRUE)

head(wiki_table_source)

```

The nice thing is that additional information like the voting disctrict was obtained. Using the comments ("Opmerkingen"), will probaly be more time consuming than hardcoding the changes, but I think it will be more fun ;-)

```{r}
#print(wiki_table$Opmerkingen, na.print = "")

wiki_table_source %>% 
  filter(!is.na(Opmerkingen)) %>% 
  select(Opmerkingen)

```


'Vervangt' means 'replaces', so these are members that replaced someone who took on another mandate. 'Werd' means 'was', so these were replaced.

```{r}
wiki_table <- wiki_table_source %>% 
  filter(!is.na(Opmerkingen)) %>% 
  mutate(first_word = str_extract(Opmerkingen,"(\\w+)"))
```

In the comments (Opmerkingen) there are up to three dates that we need. A first step would be to change the month names in numbers. And then extract all the numbers into a list.

```{r}
wiki_table <- wiki_table %>% 
  mutate(Opmerkingen = gsub("januari", 1, Opmerkingen),
         Opmerkingen = gsub("februari", 2, Opmerkingen),
         Opmerkingen = gsub("maart", 3, Opmerkingen),
         Opmerkingen = gsub("april", 4, Opmerkingen),
         Opmerkingen = gsub("mei", 5, Opmerkingen),
         Opmerkingen = gsub("juni", 6, Opmerkingen),
         Opmerkingen = gsub("juli", 7, Opmerkingen),
         Opmerkingen = gsub("augustus", 8, Opmerkingen),
         Opmerkingen = gsub("september", 9, Opmerkingen),
         Opmerkingen = gsub("oktober", 10, Opmerkingen),
         Opmerkingen = gsub("november", 11, Opmerkingen),
         Opmerkingen = gsub("december", 12, Opmerkingen)) %>%
    mutate(digits = str_extract_all(Opmerkingen,"([0-9]+)")) %>% #'+' keeps them together
  filter(first_word != "De") # this one has no date 



inspect <-wiki_table$digits
inspect[[20]]

```
It will be more difficult to handle the digits if days and months smaller than 10 do not have a leading 0. So one needs to be added, before concatenating all the numbers

```{r}
for (i in (1:length(inspect))){
  for (j in (1:length(inspect[[i]]))){
    if (nchar(inspect[[i]][j]) == 1) {inspect[[i]][j] <- paste0("0",inspect[[i]][j])}
  }
  inspect[[i]] <- paste0(inspect[[i]], collapse = "")
  print(inspect[[i]])
}
# pure poetry if you ask me

con_dates <- data.frame("condate" = unlist(inspect))
wiki_table <- wiki_table %>% 
  cbind(con_dates) %>% 
  select(-digits)
```

Now we can extrat the dates, but one problem still remains, on wikipedia some years are not repeated for certain time periods (so there are only 4 digits for a date):

```{r}
wiki_table$Opmerkingen[28]
as.character(wiki_table$condate[28])
```

A little bit more work is needed.

```{r}
wiki_table <- wiki_table %>% 
  mutate(date_1 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,1,8),
                  paste0(substr(condate,1,4),
                    substr(condate,str_locate(condate, "201"),
                            str_locate(condate, "201") + 3))
                  )
         ) %>% 
   mutate(date_2 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,9,16),
                  paste0(
                    substr(condate,str_locate(condate, "201")-4,
                            str_locate(condate, "201") + 3))
                  )
         ) %>% 
   mutate(date_3 = 
           ifelse(substr(condate,5,6) == "20",
                  substr(condate,17,24),
                  "")
         ) %>% 
  select(-condate)


wiki_table <- wiki_table %>% 
  mutate(date_1 = dmy(as.numeric(date_1)),
         date_2 = dmy(as.numeric(date_2)),
         date_3 = dmy(as.numeric(date_3)),
                )

```

Ok that looks fine now.

There are other possibilities, but here we will use a table with one line per period a person seated for a party. To later use in the analysis of the tweets collected. In that table there will be one start date and one end date. A good start is assuming everyone started at "2014-06-19" and ended at "2019-05-31", and then making corrections afterwards. 

We can start by consolidating our tables.

```{r}
setdiff(names(wiki_table),names(wiki_table_source))
```
```{r}
wiki_table <- wiki_table %>% 
  rbind(wiki_table_source %>% 
          filter(is.na(Opmerkingen) 
                 | Volksvertegenwoordiger == "Jadin, Kattrin Kattrin Jadin") %>%
          mutate(first_word = "",
                 date_1 = as.Date("2001-01-01"),
                 date_2 = as.Date("2001-01-01"),
                 date_3 = as.Date("2001-01-01"))
                              )

```


Aw, shoot did not see the names are funky.

```{r}
head(wiki_table$Volksvertegenwoordiger)
```

Maybe we can join on the concatenation of letters.

```{r}
x <- wiki_table %>% 
  mutate(join = str_remove_all(Volksvertegenwoordiger," "),
         join = str_remove_all(join,","),
         join = substr(join,1, nchar(join)/2))

y <- names %>% 
  mutate(join = str_remove_all(ln_fn," "))

z <- y %>% 
  left_join(x)

```
```{r}

test <- z %>% 
  filter(!is.na(Volksvertegenwoordiger)) %>% 
  mutate(test = "test")
  
missing <- wiki_table %>% 
  left_join(test %>% 
              select(Volksvertegenwoordiger, test)) %>% 
  filter(is.na(test))

missing$Volksvertegenwoordiger

```

Yes I've got myself in a pickle again. Three missing. The join field for them should be VandeVeldeRobert, FernandezFernandezJulie and JirofléeKarin

instead of VandeVeldeRob 	JirofléeKarine and Fernandez-FernandezJulie

We can follow how they are spelled on dekamer.be: Robert Van de Velde, Karin Jiroflée, Julie Fernandez Fernandez

And use a case_when for a change

```{r}

xx <- x %>% 
  mutate(join = case_when(join == "VandeVeldeRob" ~ "VandeVeldeRobert",
                          join == "JirofléeKarine" ~ "JirofléeKarin",
                          join == "FernandezFernandezJulie" ~ "Fernandez-FernandezJulie",
                          TRUE ~ join))

```
There are 150 persons on the Wikipedia list and 179 parliamentarians in the legistlature. We would need to find the dates these 29 left. For instance, when did Ann Vanheste leave?


```{r}
xx %>% 
  filter(str_detect(Opmerkingen, "Ann Vanheste")) %>% 
  select(date_1) %>% 
  print()


```

